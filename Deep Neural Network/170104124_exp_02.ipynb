{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "170104124_exp_02.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/siamislam1603/Soft-Computing-Lab/blob/master/Deep%20Neural%20Network/170104124_exp_02.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WsxEwLHzoBOh",
        "outputId": "024546e6-f46d-4aa0-8ff7-9a372f3c8369"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1YkNIhrkny06"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import os\n",
        "import cv2\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N6uOqQLJvrsC"
      },
      "source": [
        "### Loading preprocessed training and test set from drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nmzLONZtvysK",
        "outputId": "f7f71fd0-078b-414a-e7f5-a7739b041bf3"
      },
      "source": [
        "train_set_ds1=torch.load('/content/drive/MyDrive/Soft Computing Lab/training_set_a.pt')\n",
        "test_set_ds1=torch.load('/content/drive/MyDrive/Soft Computing Lab/testing_set_a.pt')\n",
        "train_set_ds1[0][0].shape,test_set_ds1[0][0].shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([1, 28, 28]), torch.Size([1, 28, 28]))"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oiRr2XtVwS9Y"
      },
      "source": [
        "### Hyperparameters for DNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JYdiRLt3FPLy"
      },
      "source": [
        "### Six Layer FNN with ReLU Activation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T0jY7KZ0E50C"
      },
      "source": [
        "class DeepNeuralNetworkModel(nn.Module):\n",
        "    def __init__(self, input_size, num_classes, num_hidden):\n",
        "        super().__init__()\n",
        "        self.linear_1 = nn.Linear(input_size, num_hidden)\n",
        "        self.act_1 = nn.Tanh()\n",
        "        self.linear_2 = nn.Linear(num_hidden, num_hidden)\n",
        "        self.act_2 = nn.Tanh()\n",
        "        self.linear_3 = nn.Linear(num_hidden, num_hidden)\n",
        "        self.act_3 = nn.Tanh()\n",
        "        self.linear_4 = nn.Linear(num_hidden, num_hidden)\n",
        "        self.act_4 = nn.Tanh()\n",
        "        self.linear_5 = nn.Linear(num_hidden, num_hidden)\n",
        "        self.act_5 = nn.Tanh()\n",
        "        self.linear_6 = nn.Linear(num_hidden, num_hidden)\n",
        "        self.act_6 = nn.Tanh()\n",
        "        self.linear_out = nn.Linear(num_hidden, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out  = self.linear_1(x)\n",
        "        out = self.act_1(out)\n",
        "        out  = self.linear_2(out)\n",
        "        out = self.act_2(out)\n",
        "        out  = self.linear_3(out)\n",
        "        out = self.act_3(out)\n",
        "        out  = self.linear_4(out)\n",
        "        out = self.act_4(out)\n",
        "        out  = self.linear_5(out)\n",
        "        out = self.act_5(out)\n",
        "        out  = self.linear_6(out)\n",
        "        out = self.act_6(out)\n",
        "        out  = self.linear_out(out)\n",
        "        return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XI0OvGSRTmA0"
      },
      "source": [
        "def cal_accuracy(applied_model,ds_test_loader):\n",
        "  correct = 0\n",
        "  total = 0\n",
        "  for images, labels in ds_test_loader:\n",
        "    images = images.view(-1, 28*28).to(device)\n",
        "    outputs = applied_model(images)\n",
        "    _, predicted = torch.max(outputs, 1)\n",
        "    total += labels.size(0)\n",
        "    if torch.cuda.is_available():\n",
        "        correct += (predicted.cpu() == labels.cpu()).sum() \n",
        "    else:\n",
        "        correct += (predicted == labels).sum()\n",
        "\n",
        "  accuracy = 100 * correct.item() / total\n",
        "  return accuracy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tzs8CJQaad7Z"
      },
      "source": [
        "def evaluate_model(applied_model,ds_train_loader,ds_test_loader,num_epochs):\n",
        "  iter_loss=[]\n",
        "  iter=0\n",
        "  for epoch in range(num_epochs):\n",
        "    print(f\"Epoch {epoch+1}\\n-------------------------------\")\n",
        "    for i, (images, labels) in enumerate(ds_train_loader):\n",
        "      images = images.view(-1, 28*28).to(device)\n",
        "      labels = labels.to(device)\n",
        "      optimizer.zero_grad()\n",
        "      outputs = applied_model(images) \n",
        "      loss = criterion(outputs, labels)\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      if iter % 100 == 0:\n",
        "        accuracy=cal_accuracy(applied_model,ds_test_loader)\n",
        "        print('Iteration: {}. Loss: {}. Accuracy: {}'.format(iter, loss.item(), accuracy))\n",
        "        iter_loss.append(loss.item())\n",
        "      iter=iter+1\n",
        "  return iter_loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gELCrYBlclfr"
      },
      "source": [
        "### Model Evaluation on `Dataset 1`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f-YClC3PjwGf"
      },
      "source": [
        "batch_size = 32\n",
        "num_iters = 95000\n",
        "input_dim = 28*28\n",
        "num_hidden = 200\n",
        "output_dim = 10\n",
        "\n",
        "learning_rate = 1e-4\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5RP6BV4LjwDM",
        "outputId": "a228841c-3a87-4d6e-fdb6-98ded419b419"
      },
      "source": [
        "g = torch.Generator()\n",
        "g.manual_seed(42)\n",
        "model_ds1 = DeepNeuralNetworkModel(input_size = input_dim,\n",
        "                               num_classes = output_dim,\n",
        "                               num_hidden = num_hidden)\n",
        "model_ds1.to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model_ds1.parameters(), lr=learning_rate)\n",
        "\n",
        "train_loader_ds1 = torch.utils.data.DataLoader(dataset=train_set_ds1, \n",
        "                                           batch_size=batch_size, \n",
        "                                           shuffle=True,\n",
        "                                           generator=g)\n",
        "\n",
        "test_loader_ds1 = torch.utils.data.DataLoader(dataset=test_set_ds1, \n",
        "                                          batch_size=batch_size, \n",
        "                                          shuffle=False)\n",
        "\n",
        "num_epochs_ds1 = num_iters / (len(train_set_ds1) / batch_size)\n",
        "num_epochs_ds1 = int(num_epochs_ds1)\n",
        "iter_loss_ds1=evaluate_model(model_ds1,train_loader_ds1,test_loader_ds1,num_epochs_ds1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "-------------------------------\n",
            "Iteration: 0. Loss: 2.300987720489502. Accuracy: 10.504947982745495\n",
            "Iteration: 100. Loss: 2.294668674468994. Accuracy: 10.504947982745495\n",
            "Iteration: 200. Loss: 2.314276695251465. Accuracy: 10.022836843440752\n",
            "Iteration: 300. Loss: 2.2950570583343506. Accuracy: 10.707942146663283\n",
            "Iteration: 400. Loss: 2.2990798950195312. Accuracy: 10.022836843440752\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "Iteration: 500. Loss: 2.3045878410339355. Accuracy: 9.109363105810708\n",
            "Iteration: 600. Loss: 2.3104491233825684. Accuracy: 10.022836843440752\n",
            "Iteration: 700. Loss: 2.314751625061035. Accuracy: 9.769094138543517\n",
            "Iteration: 800. Loss: 2.2944839000701904. Accuracy: 10.428825171276326\n",
            "Iteration: 900. Loss: 2.270723819732666. Accuracy: 11.139304744988582\n",
            "Epoch 3\n",
            "-------------------------------\n",
            "Iteration: 1000. Loss: 2.3079416751861572. Accuracy: 9.261608728749048\n",
            "Iteration: 1100. Loss: 2.271897554397583. Accuracy: 10.733316417153008\n",
            "Iteration: 1200. Loss: 2.248671054840088. Accuracy: 12.890129408779497\n",
            "Iteration: 1300. Loss: 2.29394268989563. Accuracy: 15.630550621669627\n",
            "Iteration: 1400. Loss: 2.1012816429138184. Accuracy: 27.251966505962955\n",
            "Epoch 4\n",
            "-------------------------------\n",
            "Iteration: 1500. Loss: 2.2671210765838623. Accuracy: 16.264907383912714\n",
            "Iteration: 1600. Loss: 2.500195026397705. Accuracy: 14.184217203755392\n",
            "Iteration: 1700. Loss: 2.0521113872528076. Accuracy: 29.81476782542502\n",
            "Iteration: 1800. Loss: 1.9352186918258667. Accuracy: 26.135498604415123\n",
            "Iteration: 1900. Loss: 2.109841823577881. Accuracy: 32.80893174321238\n",
            "Epoch 5\n",
            "-------------------------------\n",
            "Iteration: 2000. Loss: 1.9925616979599. Accuracy: 28.444557218979956\n",
            "Iteration: 2100. Loss: 1.8764047622680664. Accuracy: 27.81020045673687\n",
            "Iteration: 2200. Loss: 1.970064640045166. Accuracy: 39.0002537427049\n",
            "Iteration: 2300. Loss: 1.6306483745574951. Accuracy: 33.59553412839381\n",
            "Iteration: 2400. Loss: 1.569101333618164. Accuracy: 44.709464602892666\n",
            "Epoch 6\n",
            "-------------------------------\n",
            "Iteration: 2500. Loss: 2.082819700241089. Accuracy: 42.755645775183964\n",
            "Iteration: 2600. Loss: 1.994332194328308. Accuracy: 40.57345851306775\n",
            "Iteration: 2700. Loss: 1.566640853881836. Accuracy: 39.58386196396854\n",
            "Iteration: 2800. Loss: 1.6478484869003296. Accuracy: 42.01979193098198\n",
            "Iteration: 2900. Loss: 1.636261224746704. Accuracy: 41.41080943922862\n",
            "Epoch 7\n",
            "-------------------------------\n",
            "Iteration: 3000. Loss: 1.616842269897461. Accuracy: 49.657447348388736\n",
            "Iteration: 3100. Loss: 1.3687443733215332. Accuracy: 29.840142095914743\n",
            "Iteration: 3200. Loss: 2.1512794494628906. Accuracy: 37.95990865262624\n",
            "Iteration: 3300. Loss: 2.0842642784118652. Accuracy: 40.47196143110886\n",
            "Iteration: 3400. Loss: 1.34812593460083. Accuracy: 36.46282669373255\n",
            "Epoch 8\n",
            "-------------------------------\n",
            "Iteration: 3500. Loss: 1.1986390352249146. Accuracy: 49.32758183202233\n",
            "Iteration: 3600. Loss: 1.2589564323425293. Accuracy: 55.87414361837097\n",
            "Iteration: 3700. Loss: 1.1874403953552246. Accuracy: 52.49936564323776\n",
            "Iteration: 3800. Loss: 1.1599655151367188. Accuracy: 49.45445318447095\n",
            "Iteration: 3900. Loss: 1.1258114576339722. Accuracy: 47.4498858157828\n",
            "Epoch 9\n",
            "-------------------------------\n",
            "Iteration: 4000. Loss: 1.6943180561065674. Accuracy: 59.0459274295864\n",
            "Iteration: 4100. Loss: 1.33956778049469. Accuracy: 49.96193859426541\n",
            "Iteration: 4200. Loss: 0.738842248916626. Accuracy: 56.43237756914489\n",
            "Iteration: 4300. Loss: 1.460813045501709. Accuracy: 48.05886830753616\n",
            "Iteration: 4400. Loss: 1.47828209400177. Accuracy: 57.80258817558995\n",
            "Epoch 10\n",
            "-------------------------------\n",
            "Iteration: 4500. Loss: 1.3796799182891846. Accuracy: 61.98934280639432\n",
            "Iteration: 4600. Loss: 1.216254711151123. Accuracy: 54.174067495559505\n",
            "Iteration: 4700. Loss: 0.9626502394676208. Accuracy: 55.39203247906622\n",
            "Iteration: 4800. Loss: 1.1265218257904053. Accuracy: 58.259325044404974\n",
            "Iteration: 4900. Loss: 0.9117482900619507. Accuracy: 60.39076376554174\n",
            "Epoch 11\n",
            "-------------------------------\n",
            "Iteration: 5000. Loss: 1.4592301845550537. Accuracy: 51.89038315148439\n",
            "Iteration: 5100. Loss: 1.3318772315979004. Accuracy: 55.3666582085765\n",
            "Iteration: 5200. Loss: 1.3866934776306152. Accuracy: 42.172037553920326\n",
            "Iteration: 5300. Loss: 1.0285886526107788. Accuracy: 48.2111139304745\n",
            "Iteration: 5400. Loss: 1.0760061740875244. Accuracy: 61.96396853590459\n",
            "Epoch 12\n",
            "-------------------------------\n",
            "Iteration: 5500. Loss: 1.2849907875061035. Accuracy: 59.19817305252474\n",
            "Iteration: 5600. Loss: 1.4933713674545288. Accuracy: 62.34458259325044\n",
            "Iteration: 5700. Loss: 1.1014236211776733. Accuracy: 64.88200964222278\n",
            "Iteration: 5800. Loss: 1.329864263534546. Accuracy: 55.56965237249429\n",
            "Iteration: 5900. Loss: 1.242621660232544. Accuracy: 58.13245369195636\n",
            "Epoch 13\n",
            "-------------------------------\n",
            "Iteration: 6000. Loss: 1.380782961845398. Accuracy: 61.5326059375793\n",
            "Iteration: 6100. Loss: 1.243457317352295. Accuracy: 60.41613803603146\n",
            "Iteration: 6200. Loss: 1.2547842264175415. Accuracy: 54.07257041360061\n",
            "Iteration: 6300. Loss: 1.254468560218811. Accuracy: 61.5326059375793\n",
            "Iteration: 6400. Loss: 1.1429791450500488. Accuracy: 61.228114691702615\n",
            "Epoch 14\n",
            "-------------------------------\n",
            "Iteration: 6500. Loss: 1.0278451442718506. Accuracy: 64.19690433900026\n",
            "Iteration: 6600. Loss: 1.1683279275894165. Accuracy: 50.67241816797767\n",
            "Iteration: 6700. Loss: 1.451323390007019. Accuracy: 52.245622938340524\n",
            "Iteration: 6800. Loss: 1.1606323719024658. Accuracy: 52.347120020299414\n",
            "Iteration: 6900. Loss: 0.9995529651641846. Accuracy: 62.725196650596295\n",
            "Epoch 15\n",
            "-------------------------------\n",
            "Iteration: 7000. Loss: 1.122573733329773. Accuracy: 51.89038315148439\n",
            "Iteration: 7100. Loss: 1.4923174381256104. Accuracy: 57.777213905100226\n",
            "Iteration: 7200. Loss: 0.8233073949813843. Accuracy: 60.44151230652119\n",
            "Iteration: 7300. Loss: 1.0643093585968018. Accuracy: 62.725196650596295\n",
            "Epoch 16\n",
            "-------------------------------\n",
            "Iteration: 7400. Loss: 1.5382378101348877. Accuracy: 64.72976401928445\n",
            "Iteration: 7500. Loss: 0.9662814736366272. Accuracy: 64.32377569144887\n",
            "Iteration: 7600. Loss: 1.4754494428634644. Accuracy: 46.81552905353971\n",
            "Iteration: 7700. Loss: 0.7344883680343628. Accuracy: 59.3757929459528\n",
            "Iteration: 7800. Loss: 1.2454639673233032. Accuracy: 66.02385181426034\n",
            "Epoch 17\n",
            "-------------------------------\n",
            "Iteration: 7900. Loss: 0.9917327165603638. Accuracy: 48.6424765287998\n",
            "Iteration: 8000. Loss: 1.1354485750198364. Accuracy: 60.54300938848008\n",
            "Iteration: 8100. Loss: 0.9338600635528564. Accuracy: 62.59832529814768\n",
            "Iteration: 8200. Loss: 1.44742751121521. Accuracy: 63.3849276833291\n",
            "Iteration: 8300. Loss: 1.220587968826294. Accuracy: 60.87287490484648\n",
            "Epoch 18\n",
            "-------------------------------\n",
            "Iteration: 8400. Loss: 0.903532087802887. Accuracy: 54.757675716823144\n",
            "Iteration: 8500. Loss: 1.273061990737915. Accuracy: 58.56381629028166\n",
            "Iteration: 8600. Loss: 1.0306297540664673. Accuracy: 63.08043643745242\n",
            "Iteration: 8700. Loss: 0.8564267754554749. Accuracy: 57.98020806901802\n",
            "Iteration: 8800. Loss: 1.1427104473114014. Accuracy: 60.263892413093124\n",
            "Epoch 19\n",
            "-------------------------------\n",
            "Iteration: 8900. Loss: 0.834691047668457. Accuracy: 63.18193351941132\n",
            "Iteration: 9000. Loss: 1.2150297164916992. Accuracy: 56.10251205277848\n",
            "Iteration: 9100. Loss: 1.1411786079406738. Accuracy: 58.66531337224055\n",
            "Iteration: 9200. Loss: 0.8403943181037903. Accuracy: 61.20274042121289\n",
            "Iteration: 9300. Loss: 0.7475838661193848. Accuracy: 64.93275818320224\n",
            "Epoch 20\n",
            "-------------------------------\n",
            "Iteration: 9400. Loss: 1.1207035779953003. Accuracy: 62.95356508500381\n",
            "Iteration: 9500. Loss: 0.497202605009079. Accuracy: 66.93732555189038\n",
            "Iteration: 9600. Loss: 1.0535091161727905. Accuracy: 61.88784572443542\n",
            "Iteration: 9700. Loss: 1.511367917060852. Accuracy: 64.679015478305\n",
            "Iteration: 9800. Loss: 0.8239278197288513. Accuracy: 63.91778736361329\n",
            "Epoch 21\n",
            "-------------------------------\n",
            "Iteration: 9900. Loss: 1.7507939338684082. Accuracy: 51.3575234712002\n",
            "Iteration: 10000. Loss: 0.7301389575004578. Accuracy: 66.81045419944176\n",
            "Iteration: 10100. Loss: 1.1692590713500977. Accuracy: 56.711494544531845\n",
            "Iteration: 10200. Loss: 1.20962655544281. Accuracy: 49.200710479573715\n",
            "Iteration: 10300. Loss: 0.8977103233337402. Accuracy: 59.02055315909668\n",
            "Epoch 22\n",
            "-------------------------------\n",
            "Iteration: 10400. Loss: 0.7664333581924438. Accuracy: 52.39786856127886\n",
            "Iteration: 10500. Loss: 1.0996094942092896. Accuracy: 62.39533113422989\n",
            "Iteration: 10600. Loss: 0.9438462853431702. Accuracy: 66.83582846993149\n",
            "Iteration: 10700. Loss: 0.6717057228088379. Accuracy: 67.87617356001014\n",
            "Iteration: 10800. Loss: 1.3506890535354614. Accuracy: 59.57878710987059\n",
            "Epoch 23\n",
            "-------------------------------\n",
            "Iteration: 10900. Loss: 0.9966818690299988. Accuracy: 64.12078152753108\n",
            "Iteration: 11000. Loss: 1.3228224515914917. Accuracy: 61.228114691702615\n",
            "Iteration: 11100. Loss: 1.2966196537017822. Accuracy: 69.93148946967774\n",
            "Iteration: 11200. Loss: 1.2120451927185059. Accuracy: 64.0192844455722\n",
            "Iteration: 11300. Loss: 1.3091973066329956. Accuracy: 68.10454199441766\n",
            "Epoch 24\n",
            "-------------------------------\n",
            "Iteration: 11400. Loss: 0.9094152450561523. Accuracy: 67.11494544531844\n",
            "Iteration: 11500. Loss: 1.187569499015808. Accuracy: 60.46688657701091\n",
            "Iteration: 11600. Loss: 0.8233721256256104. Accuracy: 67.03882263384928\n",
            "Iteration: 11700. Loss: 1.3215198516845703. Accuracy: 68.10454199441766\n",
            "Iteration: 11800. Loss: 1.3548870086669922. Accuracy: 62.801319462065464\n",
            "Epoch 25\n",
            "-------------------------------\n",
            "Iteration: 11900. Loss: 0.817707896232605. Accuracy: 63.10581070794215\n",
            "Iteration: 12000. Loss: 1.2909369468688965. Accuracy: 68.15529053539711\n",
            "Iteration: 12100. Loss: 0.7473316788673401. Accuracy: 59.62953565085004\n",
            "Iteration: 12200. Loss: 1.058708667755127. Accuracy: 69.14488708449632\n",
            "Iteration: 12300. Loss: 0.9971829056739807. Accuracy: 65.13575234712002\n",
            "Epoch 26\n",
            "-------------------------------\n",
            "Iteration: 12400. Loss: 1.2678881883621216. Accuracy: 61.101243339254\n",
            "Iteration: 12500. Loss: 0.628928542137146. Accuracy: 68.48515605176351\n",
            "Iteration: 12600. Loss: 1.400215983390808. Accuracy: 67.8254250190307\n",
            "Iteration: 12700. Loss: 1.015824556350708. Accuracy: 60.365389495052014\n",
            "Iteration: 12800. Loss: 0.8671044111251831. Accuracy: 68.76427302715047\n",
            "Epoch 27\n",
            "-------------------------------\n",
            "Iteration: 12900. Loss: 0.6462918519973755. Accuracy: 62.217711240801826\n",
            "Iteration: 13000. Loss: 0.7576241493225098. Accuracy: 69.52550114184217\n",
            "Iteration: 13100. Loss: 0.8696944713592529. Accuracy: 60.289266683582845\n",
            "Iteration: 13200. Loss: 0.7933378219604492. Accuracy: 64.65364120781527\n",
            "Iteration: 13300. Loss: 0.7823501229286194. Accuracy: 68.28216188784573\n",
            "Epoch 28\n",
            "-------------------------------\n",
            "Iteration: 13400. Loss: 0.5775317549705505. Accuracy: 66.91195128140066\n",
            "Iteration: 13500. Loss: 1.0722535848617554. Accuracy: 60.01014970819589\n",
            "Iteration: 13600. Loss: 0.7773270010948181. Accuracy: 58.15782796244608\n",
            "Iteration: 13700. Loss: 0.9156946539878845. Accuracy: 69.06876427302716\n",
            "Iteration: 13800. Loss: 0.7477861046791077. Accuracy: 70.13448363359554\n",
            "Epoch 29\n",
            "-------------------------------\n",
            "Iteration: 13900. Loss: 1.0846147537231445. Accuracy: 61.837097183455974\n",
            "Iteration: 14000. Loss: 0.9695934057235718. Accuracy: 68.61202740421213\n",
            "Iteration: 14100. Loss: 1.0818307399749756. Accuracy: 71.50469424004059\n",
            "Iteration: 14200. Loss: 0.9083230495452881. Accuracy: 65.16112661760974\n",
            "Epoch 30\n",
            "-------------------------------\n",
            "Iteration: 14300. Loss: 0.6000843644142151. Accuracy: 56.60999746257295\n",
            "Iteration: 14400. Loss: 1.2134740352630615. Accuracy: 63.02968789647298\n",
            "Iteration: 14500. Loss: 0.8554809093475342. Accuracy: 61.5326059375793\n",
            "Iteration: 14600. Loss: 1.1162642240524292. Accuracy: 64.83126110124334\n",
            "Iteration: 14700. Loss: 1.1663689613342285. Accuracy: 57.54884547069272\n",
            "Epoch 31\n",
            "-------------------------------\n",
            "Iteration: 14800. Loss: 0.9112982749938965. Accuracy: 67.44481096168485\n",
            "Iteration: 14900. Loss: 0.8776389360427856. Accuracy: 67.62243085511291\n",
            "Iteration: 15000. Loss: 0.7959604859352112. Accuracy: 71.80918548591728\n",
            "Iteration: 15100. Loss: 0.6925631165504456. Accuracy: 71.09870591220502\n",
            "Iteration: 15200. Loss: 1.115583062171936. Accuracy: 55.315909667597055\n",
            "Epoch 32\n",
            "-------------------------------\n",
            "Iteration: 15300. Loss: 0.8570311665534973. Accuracy: 70.00761228114692\n",
            "Iteration: 15400. Loss: 0.5323634743690491. Accuracy: 70.2106064450647\n",
            "Iteration: 15500. Loss: 0.8841935992240906. Accuracy: 60.59375792945953\n",
            "Iteration: 15600. Loss: 0.8489696383476257. Accuracy: 71.60619132199949\n",
            "Iteration: 15700. Loss: 0.9528322219848633. Accuracy: 63.740167470185234\n",
            "Epoch 33\n",
            "-------------------------------\n",
            "Iteration: 15800. Loss: 0.861323356628418. Accuracy: 72.31667089571175\n",
            "Iteration: 15900. Loss: 0.6852995157241821. Accuracy: 62.725196650596295\n",
            "Iteration: 16000. Loss: 0.7138274312019348. Accuracy: 71.68231413346867\n",
            "Iteration: 16100. Loss: 0.5478548407554626. Accuracy: 66.45521441258563\n",
            "Iteration: 16200. Loss: 0.8125144839286804. Accuracy: 72.59578787109871\n",
            "Epoch 34\n",
            "-------------------------------\n",
            "Iteration: 16300. Loss: 0.6380001902580261. Accuracy: 61.329611773661505\n",
            "Iteration: 16400. Loss: 0.9764073491096497. Accuracy: 63.91778736361329\n",
            "Iteration: 16500. Loss: 0.5962556004524231. Accuracy: 64.27302715046942\n",
            "Iteration: 16600. Loss: 0.9055494070053101. Accuracy: 73.33164171530069\n",
            "Iteration: 16700. Loss: 1.523409366607666. Accuracy: 44.2019791930982\n",
            "Epoch 35\n",
            "-------------------------------\n",
            "Iteration: 16800. Loss: 0.5329582095146179. Accuracy: 73.07789901040346\n",
            "Iteration: 16900. Loss: 1.0501092672348022. Accuracy: 67.54630804364375\n",
            "Iteration: 17000. Loss: 0.8984144926071167. Accuracy: 69.57624968282163\n",
            "Iteration: 17100. Loss: 0.7721929550170898. Accuracy: 55.772646536412076\n",
            "Iteration: 17200. Loss: 1.0078833103179932. Accuracy: 72.21517381375286\n",
            "Epoch 36\n",
            "-------------------------------\n",
            "Iteration: 17300. Loss: 0.9080964922904968. Accuracy: 67.7239279370718\n",
            "Iteration: 17400. Loss: 0.7566868662834167. Accuracy: 67.11494544531844\n",
            "Iteration: 17500. Loss: 0.8932787179946899. Accuracy: 61.253488962192336\n",
            "Iteration: 17600. Loss: 0.7618693113327026. Accuracy: 70.84496320730779\n",
            "Iteration: 17700. Loss: 0.7536247968673706. Accuracy: 70.87033747779752\n",
            "Epoch 37\n",
            "-------------------------------\n",
            "Iteration: 17800. Loss: 0.9180479049682617. Accuracy: 70.89571174828724\n",
            "Iteration: 17900. Loss: 0.7234531044960022. Accuracy: 72.21517381375286\n",
            "Iteration: 18000. Loss: 0.8156922459602356. Accuracy: 65.66861202740421\n",
            "Iteration: 18100. Loss: 0.8040756583213806. Accuracy: 69.55087541233189\n",
            "Iteration: 18200. Loss: 0.8195396661758423. Accuracy: 74.16899264146156\n",
            "Epoch 38\n",
            "-------------------------------\n",
            "Iteration: 18300. Loss: 1.2306983470916748. Accuracy: 68.78964729764019\n",
            "Iteration: 18400. Loss: 0.9033498167991638. Accuracy: 70.05836082212636\n",
            "Iteration: 18500. Loss: 1.1213088035583496. Accuracy: 67.03882263384928\n",
            "Iteration: 18600. Loss: 0.8856610059738159. Accuracy: 63.89241309312357\n",
            "Iteration: 18700. Loss: 1.0637452602386475. Accuracy: 63.765541740674955\n",
            "Epoch 39\n",
            "-------------------------------\n",
            "Iteration: 18800. Loss: 0.9993026852607727. Accuracy: 68.58665313372241\n",
            "Iteration: 18900. Loss: 0.813825249671936. Accuracy: 74.01674701852322\n",
            "Iteration: 19000. Loss: 0.7981802821159363. Accuracy: 63.689418929205786\n",
            "Iteration: 19100. Loss: 0.793459415435791. Accuracy: 70.64196904339\n",
            "Iteration: 19200. Loss: 1.0601837635040283. Accuracy: 70.64196904339\n",
            "Epoch 40\n",
            "-------------------------------\n",
            "Iteration: 19300. Loss: 0.7069425582885742. Accuracy: 67.90154783049988\n",
            "Iteration: 19400. Loss: 0.9995659589767456. Accuracy: 66.12534889621924\n",
            "Iteration: 19500. Loss: 0.7541595101356506. Accuracy: 71.70768840395839\n",
            "Iteration: 19600. Loss: 0.5528925061225891. Accuracy: 66.40446587160619\n",
            "Iteration: 19700. Loss: 0.9149379134178162. Accuracy: 57.87871098705912\n",
            "Epoch 41\n",
            "-------------------------------\n",
            "Iteration: 19800. Loss: 1.2000092267990112. Accuracy: 72.95102765795484\n",
            "Iteration: 19900. Loss: 0.8213027119636536. Accuracy: 62.47145394569906\n",
            "Iteration: 20000. Loss: 0.8295803070068359. Accuracy: 69.24638416645521\n",
            "Iteration: 20100. Loss: 0.4697590172290802. Accuracy: 73.10327328089318\n",
            "Iteration: 20200. Loss: 0.6669928431510925. Accuracy: 72.90027911697538\n",
            "Epoch 42\n",
            "-------------------------------\n",
            "Iteration: 20300. Loss: 0.859259307384491. Accuracy: 64.29840142095915\n",
            "Iteration: 20400. Loss: 0.6306197643280029. Accuracy: 71.50469424004059\n",
            "Iteration: 20500. Loss: 0.5873525142669678. Accuracy: 66.17609743719868\n",
            "Iteration: 20600. Loss: 1.1473058462142944. Accuracy: 55.56965237249429\n",
            "Iteration: 20700. Loss: 0.689134418964386. Accuracy: 70.89571174828724\n",
            "Epoch 43\n",
            "-------------------------------\n",
            "Iteration: 20800. Loss: 1.0447818040847778. Accuracy: 70.64196904339\n",
            "Iteration: 20900. Loss: 0.8788167834281921. Accuracy: 66.07460035523978\n",
            "Iteration: 21000. Loss: 0.6640738844871521. Accuracy: 69.90611519918802\n",
            "Iteration: 21100. Loss: 0.7275903820991516. Accuracy: 73.76300431362598\n",
            "Epoch 44\n",
            "-------------------------------\n",
            "Iteration: 21200. Loss: 0.6908001899719238. Accuracy: 60.44151230652119\n",
            "Iteration: 21300. Loss: 0.9819657206535339. Accuracy: 73.30626744481096\n",
            "Iteration: 21400. Loss: 0.5792597532272339. Accuracy: 45.52144125856382\n",
            "Iteration: 21500. Loss: 0.6082165837287903. Accuracy: 73.07789901040346\n",
            "Iteration: 21600. Loss: 1.3420484066009521. Accuracy: 67.19106825678762\n",
            "Epoch 45\n",
            "-------------------------------\n",
            "Iteration: 21700. Loss: 0.8710850477218628. Accuracy: 65.41486932250697\n",
            "Iteration: 21800. Loss: 0.8283477425575256. Accuracy: 65.69398629789393\n",
            "Iteration: 21900. Loss: 1.4935457706451416. Accuracy: 63.00431362598325\n",
            "Iteration: 22000. Loss: 1.0105870962142944. Accuracy: 65.79548337985283\n",
            "Iteration: 22100. Loss: 0.8806204795837402. Accuracy: 62.801319462065464\n",
            "Epoch 46\n",
            "-------------------------------\n",
            "Iteration: 22200. Loss: 0.7252658009529114. Accuracy: 62.369956863740164\n",
            "Iteration: 22300. Loss: 0.7929685711860657. Accuracy: 71.50469424004059\n",
            "Iteration: 22400. Loss: 0.8868861198425293. Accuracy: 63.20730778990104\n",
            "Iteration: 22500. Loss: 0.9166511297225952. Accuracy: 69.90611519918802\n",
            "Iteration: 22600. Loss: 0.8596593141555786. Accuracy: 59.35041867546308\n",
            "Epoch 47\n",
            "-------------------------------\n",
            "Iteration: 22700. Loss: 0.901749312877655. Accuracy: 59.17279878203502\n",
            "Iteration: 22800. Loss: 0.9418986439704895. Accuracy: 72.72265922354732\n",
            "Iteration: 22900. Loss: 0.8681655526161194. Accuracy: 75.33620908398883\n",
            "Iteration: 23000. Loss: 0.9206991195678711. Accuracy: 66.88657701091094\n",
            "Iteration: 23100. Loss: 0.977483332157135. Accuracy: 69.47475260086273\n",
            "Epoch 48\n",
            "-------------------------------\n",
            "Iteration: 23200. Loss: 1.0270072221755981. Accuracy: 73.53463587921847\n",
            "Iteration: 23300. Loss: 0.836723804473877. Accuracy: 63.18193351941132\n",
            "Iteration: 23400. Loss: 0.9391197562217712. Accuracy: 71.53006851053033\n",
            "Iteration: 23500. Loss: 0.7515818476676941. Accuracy: 65.1103780766303\n",
            "Iteration: 23600. Loss: 1.3115274906158447. Accuracy: 72.01217964983506\n",
            "Epoch 49\n",
            "-------------------------------\n",
            "Iteration: 23700. Loss: 0.8019223809242249. Accuracy: 70.69271758436945\n",
            "Iteration: 23800. Loss: 0.8446466326713562. Accuracy: 73.20477036285207\n",
            "Iteration: 23900. Loss: 0.8511420488357544. Accuracy: 61.71022583100736\n",
            "Iteration: 24000. Loss: 0.44142594933509827. Accuracy: 72.6972849530576\n",
            "Iteration: 24100. Loss: 0.8998119235038757. Accuracy: 71.70768840395839\n",
            "Epoch 50\n",
            "-------------------------------\n",
            "Iteration: 24200. Loss: 0.8392041325569153. Accuracy: 58.33544785587414\n",
            "Iteration: 24300. Loss: 0.8623048067092896. Accuracy: 72.95102765795484\n",
            "Iteration: 24400. Loss: 1.1534734964370728. Accuracy: 69.50012687135245\n",
            "Iteration: 24500. Loss: 0.6805039048194885. Accuracy: 70.15985790408526\n",
            "Iteration: 24600. Loss: 0.8042584657669067. Accuracy: 69.19563562547577\n",
            "Epoch 51\n",
            "-------------------------------\n",
            "Iteration: 24700. Loss: 1.0019737482070923. Accuracy: 73.027150469424\n",
            "Iteration: 24800. Loss: 0.8451963067054749. Accuracy: 72.11367673179396\n",
            "Iteration: 24900. Loss: 1.0412126779556274. Accuracy: 75.20933773154022\n",
            "Iteration: 25000. Loss: 0.873330295085907. Accuracy: 70.38822633849277\n",
            "Iteration: 25100. Loss: 0.578368604183197. Accuracy: 68.71352448617102\n",
            "Epoch 52\n",
            "-------------------------------\n",
            "Iteration: 25200. Loss: 0.7447152733802795. Accuracy: 68.56127886323269\n",
            "Iteration: 25300. Loss: 0.6721462607383728. Accuracy: 70.38822633849277\n",
            "Iteration: 25400. Loss: 1.2251183986663818. Accuracy: 71.30170007612281\n",
            "Iteration: 25500. Loss: 0.9831591248512268. Accuracy: 66.83582846993149\n",
            "Iteration: 25600. Loss: 0.7353954315185547. Accuracy: 70.41360060898249\n",
            "Epoch 53\n",
            "-------------------------------\n",
            "Iteration: 25700. Loss: 0.7945235967636108. Accuracy: 73.33164171530069\n",
            "Iteration: 25800. Loss: 0.4877079725265503. Accuracy: 68.66277594519157\n",
            "Iteration: 25900. Loss: 0.9369309544563293. Accuracy: 72.74803349403705\n",
            "Iteration: 26000. Loss: 0.8870415091514587. Accuracy: 72.67191068256787\n",
            "Iteration: 26100. Loss: 0.649370551109314. Accuracy: 75.00634356762244\n",
            "Epoch 54\n",
            "-------------------------------\n",
            "Iteration: 26200. Loss: 0.524257242679596. Accuracy: 74.3212382643999\n",
            "Iteration: 26300. Loss: 1.1338582038879395. Accuracy: 72.77340776452677\n",
            "Iteration: 26400. Loss: 0.6952183246612549. Accuracy: 68.56127886323269\n",
            "Iteration: 26500. Loss: 0.6781871318817139. Accuracy: 65.31337224054809\n",
            "Iteration: 26600. Loss: 0.6569653749465942. Accuracy: 66.07460035523978\n",
            "Epoch 55\n",
            "-------------------------------\n",
            "Iteration: 26700. Loss: 0.8165600895881653. Accuracy: 73.05252473991372\n",
            "Iteration: 26800. Loss: 0.6112849712371826. Accuracy: 71.04795737122558\n",
            "Iteration: 26900. Loss: 0.6909775733947754. Accuracy: 63.86703882263385\n",
            "Iteration: 27000. Loss: 0.9195669889450073. Accuracy: 65.61786348642477\n",
            "Iteration: 27100. Loss: 1.1124368906021118. Accuracy: 74.90484648566354\n",
            "Epoch 56\n",
            "-------------------------------\n",
            "Iteration: 27200. Loss: 0.41610071063041687. Accuracy: 69.85536665820858\n",
            "Iteration: 27300. Loss: 0.8818144202232361. Accuracy: 75.0824663790916\n",
            "Iteration: 27400. Loss: 0.8970354795455933. Accuracy: 74.19436691195128\n",
            "Iteration: 27500. Loss: 0.5702694654464722. Accuracy: 64.52676985536665\n",
            "Iteration: 27600. Loss: 0.9513120055198669. Accuracy: 68.00304491245876\n",
            "Epoch 57\n",
            "-------------------------------\n",
            "Iteration: 27700. Loss: 0.8826317191123962. Accuracy: 75.51382897741689\n",
            "Iteration: 27800. Loss: 0.9596153497695923. Accuracy: 68.73889875666075\n",
            "Iteration: 27900. Loss: 1.0126672983169556. Accuracy: 71.58081705150977\n",
            "Iteration: 28000. Loss: 0.6713046431541443. Accuracy: 62.85206800304491\n",
            "Iteration: 28100. Loss: 0.927071213722229. Accuracy: 60.89824917533621\n",
            "Epoch 58\n",
            "-------------------------------\n",
            "Iteration: 28200. Loss: 0.6157883405685425. Accuracy: 71.50469424004059\n",
            "Iteration: 28300. Loss: 0.7782004475593567. Accuracy: 75.38695762496828\n",
            "Iteration: 28400. Loss: 0.6565955281257629. Accuracy: 76.45267698553667\n",
            "Iteration: 28500. Loss: 0.3898446261882782. Accuracy: 69.72849530575996\n",
            "Epoch 59\n",
            "-------------------------------\n",
            "Iteration: 28600. Loss: 0.610973060131073. Accuracy: 72.29129662522203\n",
            "Iteration: 28700. Loss: 0.684188723564148. Accuracy: 73.40776452676985\n",
            "Iteration: 28800. Loss: 0.6247379183769226. Accuracy: 59.832529814767824\n",
            "Iteration: 28900. Loss: 0.5488176941871643. Accuracy: 67.77467647805126\n",
            "Iteration: 29000. Loss: 0.4724375009536743. Accuracy: 73.96599847754376\n",
            "Epoch 60\n",
            "-------------------------------\n",
            "Iteration: 29100. Loss: 1.021643877029419. Accuracy: 70.33747779751332\n",
            "Iteration: 29200. Loss: 1.0051660537719727. Accuracy: 70.92108601877696\n",
            "Iteration: 29300. Loss: 0.6614908576011658. Accuracy: 72.29129662522203\n",
            "Iteration: 29400. Loss: 0.6825519800186157. Accuracy: 70.71809185485917\n",
            "Iteration: 29500. Loss: 0.6693849563598633. Accuracy: 75.13321492007105\n",
            "Epoch 61\n",
            "-------------------------------\n",
            "Iteration: 29600. Loss: 1.2305803298950195. Accuracy: 69.52550114184217\n",
            "Iteration: 29700. Loss: 0.7727353572845459. Accuracy: 75.26008627251967\n",
            "Iteration: 29800. Loss: 0.7544965147972107. Accuracy: 63.10581070794215\n",
            "Iteration: 29900. Loss: 0.9563520550727844. Accuracy: 69.52550114184217\n",
            "Iteration: 30000. Loss: 0.7859728336334229. Accuracy: 73.1286475513829\n",
            "Epoch 62\n",
            "-------------------------------\n",
            "Iteration: 30100. Loss: 1.0528756380081177. Accuracy: 76.50342552651611\n",
            "Iteration: 30200. Loss: 1.0134482383728027. Accuracy: 72.06292819081452\n",
            "Iteration: 30300. Loss: 0.5661546587944031. Accuracy: 75.00634356762244\n",
            "Iteration: 30400. Loss: 0.7706987261772156. Accuracy: 69.09413854351688\n",
            "Iteration: 30500. Loss: 0.6090570688247681. Accuracy: 74.80334940370464\n",
            "Epoch 63\n",
            "-------------------------------\n",
            "Iteration: 30600. Loss: 0.7779004573822021. Accuracy: 70.51509769094139\n",
            "Iteration: 30700. Loss: 0.8650702238082886. Accuracy: 60.16239533113423\n",
            "Iteration: 30800. Loss: 0.4754668176174164. Accuracy: 49.53057599594012\n",
            "Iteration: 30900. Loss: 0.7656183838844299. Accuracy: 64.72976401928445\n",
            "Iteration: 31000. Loss: 0.7297239303588867. Accuracy: 74.11824410048212\n",
            "Epoch 64\n",
            "-------------------------------\n",
            "Iteration: 31100. Loss: 1.0779231786727905. Accuracy: 55.64577518396346\n",
            "Iteration: 31200. Loss: 1.113364577293396. Accuracy: 71.68231413346867\n",
            "Iteration: 31300. Loss: 0.8080299496650696. Accuracy: 68.6881502156813\n",
            "Iteration: 31400. Loss: 0.8138018846511841. Accuracy: 73.33164171530069\n",
            "Iteration: 31500. Loss: 0.5677888989448547. Accuracy: 70.05836082212636\n",
            "Epoch 65\n",
            "-------------------------------\n",
            "Iteration: 31600. Loss: 0.9660525918006897. Accuracy: 77.18853082973864\n",
            "Iteration: 31700. Loss: 0.6306506395339966. Accuracy: 72.62116214158843\n",
            "Iteration: 31800. Loss: 0.7842528820037842. Accuracy: 68.6881502156813\n",
            "Iteration: 31900. Loss: 0.7071530222892761. Accuracy: 77.06165947729002\n",
            "Iteration: 32000. Loss: 0.6939764022827148. Accuracy: 76.88403958386196\n",
            "Epoch 66\n",
            "-------------------------------\n",
            "Iteration: 32100. Loss: 0.7040086984634399. Accuracy: 75.31083481349911\n",
            "Iteration: 32200. Loss: 0.4738042950630188. Accuracy: 75.56457751839635\n",
            "Iteration: 32300. Loss: 1.0840553045272827. Accuracy: 71.47931996955087\n",
            "Iteration: 32400. Loss: 0.6233454942703247. Accuracy: 71.09870591220502\n",
            "Iteration: 32500. Loss: 1.077282428741455. Accuracy: 73.56001014970819\n",
            "Epoch 67\n",
            "-------------------------------\n",
            "Iteration: 32600. Loss: 0.6277416348457336. Accuracy: 62.67444810961685\n",
            "Iteration: 32700. Loss: 0.7840648889541626. Accuracy: 71.68231413346867\n",
            "Iteration: 32800. Loss: 0.6999139189720154. Accuracy: 76.09743719868054\n",
            "Iteration: 32900. Loss: 0.7096296548843384. Accuracy: 76.2750570921086\n",
            "Iteration: 33000. Loss: 0.7209402322769165. Accuracy: 75.8436944937833\n",
            "Epoch 68\n",
            "-------------------------------\n",
            "Iteration: 33100. Loss: 0.9506998062133789. Accuracy: 77.34077645267699\n",
            "Iteration: 33200. Loss: 0.6196900010108948. Accuracy: 74.3212382643999\n",
            "Iteration: 33300. Loss: 1.529056429862976. Accuracy: 73.30626744481096\n",
            "Iteration: 33400. Loss: 0.5661512017250061. Accuracy: 73.45851306774931\n",
            "Iteration: 33500. Loss: 0.748630166053772. Accuracy: 77.31540218218726\n",
            "Epoch 69\n",
            "-------------------------------\n",
            "Iteration: 33600. Loss: 0.8766977190971375. Accuracy: 71.27632580563309\n",
            "Iteration: 33700. Loss: 0.8733685612678528. Accuracy: 71.47931996955087\n",
            "Iteration: 33800. Loss: 0.5052951574325562. Accuracy: 76.75716823141335\n",
            "Iteration: 33900. Loss: 0.8408383727073669. Accuracy: 70.61659477290029\n",
            "Iteration: 34000. Loss: 0.6497218012809753. Accuracy: 63.91778736361329\n",
            "Epoch 70\n",
            "-------------------------------\n",
            "Iteration: 34100. Loss: 0.7967955470085144. Accuracy: 66.12534889621924\n",
            "Iteration: 34200. Loss: 0.4571247398853302. Accuracy: 73.58538442019793\n",
            "Iteration: 34300. Loss: 0.6724451184272766. Accuracy: 73.07789901040346\n",
            "Iteration: 34400. Loss: 0.6748663783073425. Accuracy: 71.63156559248921\n",
            "Iteration: 34500. Loss: 0.48159030079841614. Accuracy: 72.31667089571175\n",
            "Epoch 71\n",
            "-------------------------------\n",
            "Iteration: 34600. Loss: 1.4069979190826416. Accuracy: 63.3849276833291\n",
            "Iteration: 34700. Loss: 0.8728228807449341. Accuracy: 66.98807409286982\n",
            "Iteration: 34800. Loss: 1.3672189712524414. Accuracy: 67.54630804364375\n",
            "Iteration: 34900. Loss: 0.41364991664886475. Accuracy: 75.43770616594773\n",
            "Iteration: 35000. Loss: 0.7825835347175598. Accuracy: 73.17939609236234\n",
            "Epoch 72\n",
            "-------------------------------\n",
            "Iteration: 35100. Loss: 0.4961667060852051. Accuracy: 59.02055315909668\n",
            "Iteration: 35200. Loss: 0.6863580942153931. Accuracy: 74.54960669880741\n",
            "Iteration: 35300. Loss: 0.41099026799201965. Accuracy: 72.90027911697538\n",
            "Iteration: 35400. Loss: 0.7930511236190796. Accuracy: 77.21390510022837\n",
            "Epoch 73\n",
            "-------------------------------\n",
            "Iteration: 35500. Loss: 1.0304856300354004. Accuracy: 73.53463587921847\n",
            "Iteration: 35600. Loss: 0.48649752140045166. Accuracy: 77.2392793707181\n",
            "Iteration: 35700. Loss: 0.8169844150543213. Accuracy: 45.97817812737884\n",
            "Iteration: 35800. Loss: 0.6847674250602722. Accuracy: 78.7617356001015\n",
            "Iteration: 35900. Loss: 0.5462194681167603. Accuracy: 76.3765541740675\n",
            "Epoch 74\n",
            "-------------------------------\n",
            "Iteration: 36000. Loss: 0.7018473148345947. Accuracy: 78.17812737883786\n",
            "Iteration: 36100. Loss: 0.6017200946807861. Accuracy: 75.28546054300939\n",
            "Iteration: 36200. Loss: 0.38392946124076843. Accuracy: 78.25425019030703\n",
            "Iteration: 36300. Loss: 0.5158971548080444. Accuracy: 77.74676478051256\n",
            "Iteration: 36400. Loss: 0.7710320353507996. Accuracy: 78.68561278863233\n",
            "Epoch 75\n",
            "-------------------------------\n",
            "Iteration: 36500. Loss: 0.9242554903030396. Accuracy: 75.7421974118244\n",
            "Iteration: 36600. Loss: 0.6241912841796875. Accuracy: 66.81045419944176\n",
            "Iteration: 36700. Loss: 0.5493611693382263. Accuracy: 77.11240801826948\n",
            "Iteration: 36800. Loss: 0.6655331254005432. Accuracy: 73.30626744481096\n",
            "Iteration: 36900. Loss: 0.8354896306991577. Accuracy: 70.43897487947221\n",
            "Epoch 76\n",
            "-------------------------------\n",
            "Iteration: 37000. Loss: 0.7829665541648865. Accuracy: 77.1377822887592\n",
            "Iteration: 37100. Loss: 0.9248886108398438. Accuracy: 77.18853082973864\n",
            "Iteration: 37200. Loss: 0.6811034083366394. Accuracy: 70.3121035270236\n",
            "Iteration: 37300. Loss: 1.0457897186279297. Accuracy: 76.80791677239279\n",
            "Iteration: 37400. Loss: 0.45789670944213867. Accuracy: 71.1748287236742\n",
            "Epoch 77\n",
            "-------------------------------\n",
            "Iteration: 37500. Loss: 0.6639547348022461. Accuracy: 70.33747779751332\n",
            "Iteration: 37600. Loss: 0.7871251702308655. Accuracy: 79.42146663283431\n",
            "Iteration: 37700. Loss: 0.8281621336936951. Accuracy: 75.13321492007105\n",
            "Iteration: 37800. Loss: 1.0221481323242188. Accuracy: 71.7330626744481\n",
            "Iteration: 37900. Loss: 0.8091930747032166. Accuracy: 72.72265922354732\n",
            "Epoch 78\n",
            "-------------------------------\n",
            "Iteration: 38000. Loss: 0.9420768022537231. Accuracy: 76.85866531337224\n",
            "Iteration: 38100. Loss: 0.7158116102218628. Accuracy: 73.38239025628013\n",
            "Iteration: 38200. Loss: 0.6875940561294556. Accuracy: 72.59578787109871\n",
            "Iteration: 38300. Loss: 0.9931788444519043. Accuracy: 74.39736107586907\n",
            "Iteration: 38400. Loss: 0.6296097040176392. Accuracy: 75.76757168231413\n",
            "Epoch 79\n",
            "-------------------------------\n",
            "Iteration: 38500. Loss: 0.4543638825416565. Accuracy: 72.08830246130424\n",
            "Iteration: 38600. Loss: 0.48932144045829773. Accuracy: 79.0916011164679\n",
            "Iteration: 38700. Loss: 0.3961448073387146. Accuracy: 73.83912712509516\n",
            "Iteration: 38800. Loss: 0.6808583736419678. Accuracy: 71.50469424004059\n",
            "Iteration: 38900. Loss: 0.5236803889274597. Accuracy: 72.24054808424258\n",
            "Epoch 80\n",
            "-------------------------------\n",
            "Iteration: 39000. Loss: 0.5851788520812988. Accuracy: 73.2301446333418\n",
            "Iteration: 39100. Loss: 1.103201985359192. Accuracy: 73.30626744481096\n",
            "Iteration: 39200. Loss: 0.4816816449165344. Accuracy: 62.87744227353463\n",
            "Iteration: 39300. Loss: 0.34626317024230957. Accuracy: 76.30043136259833\n",
            "Iteration: 39400. Loss: 1.1831457614898682. Accuracy: 76.85866531337224\n",
            "Epoch 81\n",
            "-------------------------------\n",
            "Iteration: 39500. Loss: 0.7228728532791138. Accuracy: 73.7883785841157\n",
            "Iteration: 39600. Loss: 0.8012090921401978. Accuracy: 65.54174067495559\n",
            "Iteration: 39700. Loss: 0.5987550020217896. Accuracy: 70.23598071555443\n",
            "Iteration: 39800. Loss: 0.5466070771217346. Accuracy: 72.18979954326313\n",
            "Iteration: 39900. Loss: 0.5342835783958435. Accuracy: 76.50342552651611\n",
            "Epoch 82\n",
            "-------------------------------\n",
            "Iteration: 40000. Loss: 0.44905710220336914. Accuracy: 73.61075869068765\n",
            "Iteration: 40100. Loss: 0.6189824938774109. Accuracy: 71.834559756407\n",
            "Iteration: 40200. Loss: 0.8523844480514526. Accuracy: 66.6328343060137\n",
            "Iteration: 40300. Loss: 0.8248016238212585. Accuracy: 77.06165947729002\n",
            "Iteration: 40400. Loss: 0.6366738677024841. Accuracy: 78.2288759198173\n",
            "Epoch 83\n",
            "-------------------------------\n",
            "Iteration: 40500. Loss: 0.6513918042182922. Accuracy: 71.9360568383659\n",
            "Iteration: 40600. Loss: 0.42191559076309204. Accuracy: 76.90941385435168\n",
            "Iteration: 40700. Loss: 0.4318298101425171. Accuracy: 78.0005074854098\n",
            "Iteration: 40800. Loss: 0.5488851070404053. Accuracy: 78.20350164932758\n",
            "Iteration: 40900. Loss: 0.29824650287628174. Accuracy: 78.60948997716315\n",
            "Epoch 84\n",
            "-------------------------------\n",
            "Iteration: 41000. Loss: 0.9015712738037109. Accuracy: 72.74803349403705\n",
            "Iteration: 41100. Loss: 0.4994581341743469. Accuracy: 76.24968282161888\n",
            "Iteration: 41200. Loss: 0.6050413250923157. Accuracy: 69.93148946967774\n",
            "Iteration: 41300. Loss: 0.7146944403648376. Accuracy: 74.37198680537935\n",
            "Iteration: 41400. Loss: 0.7749080061912537. Accuracy: 76.65567114945445\n",
            "Epoch 85\n",
            "-------------------------------\n",
            "Iteration: 41500. Loss: 0.6795974969863892. Accuracy: 78.2288759198173\n",
            "Iteration: 41600. Loss: 0.38770416378974915. Accuracy: 80.53793453438213\n",
            "Iteration: 41700. Loss: 0.8683521747589111. Accuracy: 73.9913727480335\n",
            "Iteration: 41800. Loss: 0.47979867458343506. Accuracy: 75.61532605937579\n",
            "Iteration: 41900. Loss: 0.6478531956672668. Accuracy: 79.11697538695762\n",
            "Epoch 86\n",
            "-------------------------------\n",
            "Iteration: 42000. Loss: 0.4477354884147644. Accuracy: 64.22227860948998\n",
            "Iteration: 42100. Loss: 0.540550947189331. Accuracy: 78.38112154275565\n",
            "Iteration: 42200. Loss: 0.700670599937439. Accuracy: 77.29002791169754\n",
            "Iteration: 42300. Loss: 1.0049018859863281. Accuracy: 74.87947221517382\n",
            "Epoch 87\n",
            "-------------------------------\n",
            "Iteration: 42400. Loss: 1.3291212320327759. Accuracy: 73.76300431362598\n",
            "Iteration: 42500. Loss: 0.5468141436576843. Accuracy: 79.8528292311596\n",
            "Iteration: 42600. Loss: 0.7708750367164612. Accuracy: 71.14945445318448\n",
            "Iteration: 42700. Loss: 0.5832940936088562. Accuracy: 70.71809185485917\n",
            "Iteration: 42800. Loss: 0.31002506613731384. Accuracy: 79.21847246891652\n",
            "Epoch 88\n",
            "-------------------------------\n",
            "Iteration: 42900. Loss: 0.42069411277770996. Accuracy: 74.85409794468409\n",
            "Iteration: 43000. Loss: 0.9232672452926636. Accuracy: 75.48845470692717\n",
            "Iteration: 43100. Loss: 0.6925923228263855. Accuracy: 78.25425019030703\n",
            "Iteration: 43200. Loss: 0.9891565442085266. Accuracy: 74.14361837097184\n",
            "Iteration: 43300. Loss: 0.40848833322525024. Accuracy: 70.69271758436945\n",
            "Epoch 89\n",
            "-------------------------------\n",
            "Iteration: 43400. Loss: 0.9916404485702515. Accuracy: 63.0550621669627\n",
            "Iteration: 43500. Loss: 0.7464455962181091. Accuracy: 79.64983506724181\n",
            "Iteration: 43600. Loss: 0.6461021900177002. Accuracy: 78.990104034509\n",
            "Iteration: 43700. Loss: 0.9246006011962891. Accuracy: 76.73179396092362\n",
            "Iteration: 43800. Loss: 0.6853792071342468. Accuracy: 75.89444303476274\n",
            "Epoch 90\n",
            "-------------------------------\n",
            "Iteration: 43900. Loss: 0.6294065117835999. Accuracy: 78.73636132961177\n",
            "Iteration: 44000. Loss: 0.33864808082580566. Accuracy: 77.41689926414615\n",
            "Iteration: 44100. Loss: 0.503272294998169. Accuracy: 75.66607460035524\n",
            "Iteration: 44200. Loss: 0.5974130630493164. Accuracy: 67.85079928952042\n",
            "Iteration: 44300. Loss: 0.40195906162261963. Accuracy: 80.48718599340269\n",
            "Epoch 91\n",
            "-------------------------------\n",
            "Iteration: 44400. Loss: 1.3594564199447632. Accuracy: 79.29459528038569\n",
            "Iteration: 44500. Loss: 0.400994211435318. Accuracy: 75.8436944937833\n",
            "Iteration: 44600. Loss: 0.5071000456809998. Accuracy: 76.57954833798529\n",
            "Iteration: 44700. Loss: 0.5349958539009094. Accuracy: 72.2659223547323\n",
            "Iteration: 44800. Loss: 0.9541389346122742. Accuracy: 76.22430855112916\n",
            "Epoch 92\n",
            "-------------------------------\n",
            "Iteration: 44900. Loss: 0.5877341032028198. Accuracy: 77.26465364120781\n",
            "Iteration: 45000. Loss: 0.47889891266822815. Accuracy: 77.11240801826948\n",
            "Iteration: 45100. Loss: 0.6670151948928833. Accuracy: 73.91524993656432\n",
            "Iteration: 45200. Loss: 1.065000057220459. Accuracy: 65.0088809946714\n",
            "Iteration: 45300. Loss: 1.0554354190826416. Accuracy: 80.84242578025882\n",
            "Epoch 93\n",
            "-------------------------------\n",
            "Iteration: 45400. Loss: 0.6854599714279175. Accuracy: 71.30170007612281\n",
            "Iteration: 45500. Loss: 0.4530780613422394. Accuracy: 76.52879979700583\n",
            "Iteration: 45600. Loss: 0.8002625703811646. Accuracy: 77.16315655924892\n",
            "Iteration: 45700. Loss: 0.7214506268501282. Accuracy: 77.0362852068003\n",
            "Iteration: 45800. Loss: 0.5439409613609314. Accuracy: 74.67647805125603\n",
            "Epoch 94\n",
            "-------------------------------\n",
            "Iteration: 45900. Loss: 0.8025622367858887. Accuracy: 80.53793453438213\n",
            "Iteration: 46000. Loss: 1.1618987321853638. Accuracy: 55.95026642984014\n",
            "Iteration: 46100. Loss: 0.8039032816886902. Accuracy: 73.28089317432124\n",
            "Iteration: 46200. Loss: 0.6905299425125122. Accuracy: 77.64526769855367\n",
            "Iteration: 46300. Loss: 0.526262640953064. Accuracy: 75.79294595280386\n",
            "Epoch 95\n",
            "-------------------------------\n",
            "Iteration: 46400. Loss: 0.923652172088623. Accuracy: 63.0550621669627\n",
            "Iteration: 46500. Loss: 0.6354366540908813. Accuracy: 80.36031464095407\n",
            "Iteration: 46600. Loss: 0.6649326682090759. Accuracy: 78.55874143618371\n",
            "Iteration: 46700. Loss: 0.6528156995773315. Accuracy: 79.67520933773154\n",
            "Iteration: 46800. Loss: 0.8940845727920532. Accuracy: 76.35117990357777\n",
            "Epoch 96\n",
            "-------------------------------\n",
            "Iteration: 46900. Loss: 0.5891538858413696. Accuracy: 73.38239025628013\n",
            "Iteration: 47000. Loss: 0.8840793967247009. Accuracy: 75.89444303476274\n",
            "Iteration: 47100. Loss: 0.3880730867385864. Accuracy: 76.65567114945445\n",
            "Iteration: 47200. Loss: 0.5559841394424438. Accuracy: 80.56330880487187\n",
            "Iteration: 47300. Loss: 0.3696828782558441. Accuracy: 67.54630804364375\n",
            "Epoch 97\n",
            "-------------------------------\n",
            "Iteration: 47400. Loss: 0.5060924887657166. Accuracy: 79.29459528038569\n",
            "Iteration: 47500. Loss: 0.5052520036697388. Accuracy: 78.38112154275565\n",
            "Iteration: 47600. Loss: 0.7694284319877625. Accuracy: 77.0362852068003\n",
            "Iteration: 47700. Loss: 0.5207239389419556. Accuracy: 76.42730271504695\n",
            "Iteration: 47800. Loss: 0.5192692875862122. Accuracy: 78.2288759198173\n",
            "Epoch 98\n",
            "-------------------------------\n",
            "Iteration: 47900. Loss: 0.5186210870742798. Accuracy: 77.87363613296118\n",
            "Iteration: 48000. Loss: 0.4206182658672333. Accuracy: 74.27048972342045\n",
            "Iteration: 48100. Loss: 0.5793445110321045. Accuracy: 71.09870591220502\n",
            "Iteration: 48200. Loss: 0.7996689081192017. Accuracy: 69.82999238771885\n",
            "Iteration: 48300. Loss: 0.48472586274147034. Accuracy: 76.09743719868054\n",
            "Epoch 99\n",
            "-------------------------------\n",
            "Iteration: 48400. Loss: 0.36131027340888977. Accuracy: 72.64653641207815\n",
            "Iteration: 48500. Loss: 0.5777144432067871. Accuracy: 78.2288759198173\n",
            "Iteration: 48600. Loss: 0.3355674743652344. Accuracy: 77.97513321492008\n",
            "Iteration: 48700. Loss: 0.6094898581504822. Accuracy: 79.39609236234459\n",
            "Iteration: 48800. Loss: 0.5638277530670166. Accuracy: 73.07789901040346\n",
            "Epoch 100\n",
            "-------------------------------\n",
            "Iteration: 48900. Loss: 0.6343469023704529. Accuracy: 77.36615072316671\n",
            "Iteration: 49000. Loss: 1.0030723810195923. Accuracy: 66.07460035523978\n",
            "Iteration: 49100. Loss: 0.638170599937439. Accuracy: 79.57371225577265\n",
            "Iteration: 49200. Loss: 0.89036625623703. Accuracy: 76.45267698553667\n",
            "Epoch 101\n",
            "-------------------------------\n",
            "Iteration: 49300. Loss: 0.5750031471252441. Accuracy: 69.47475260086273\n",
            "Iteration: 49400. Loss: 0.6899827122688293. Accuracy: 79.57371225577265\n",
            "Iteration: 49500. Loss: 0.3493862748146057. Accuracy: 76.35117990357777\n",
            "Iteration: 49600. Loss: 0.8079390525817871. Accuracy: 72.21517381375286\n",
            "Iteration: 49700. Loss: 1.0228320360183716. Accuracy: 61.60872874904847\n",
            "Epoch 102\n",
            "-------------------------------\n",
            "Iteration: 49800. Loss: 0.4265698194503784. Accuracy: 78.990104034509\n",
            "Iteration: 49900. Loss: 0.4718960225582123. Accuracy: 79.97970058360822\n",
            "Iteration: 50000. Loss: 0.8379598259925842. Accuracy: 66.91195128140066\n",
            "Iteration: 50100. Loss: 0.6104450225830078. Accuracy: 80.51256026389241\n",
            "Iteration: 50200. Loss: 0.5764301419258118. Accuracy: 74.01674701852322\n",
            "Epoch 103\n",
            "-------------------------------\n",
            "Iteration: 50300. Loss: 0.45852193236351013. Accuracy: 76.65567114945445\n",
            "Iteration: 50400. Loss: 0.581802248954773. Accuracy: 80.13194620654656\n",
            "Iteration: 50500. Loss: 0.6618187427520752. Accuracy: 80.15732047703628\n",
            "Iteration: 50600. Loss: 0.6378230452537537. Accuracy: 75.51382897741689\n",
            "Iteration: 50700. Loss: 0.5514761209487915. Accuracy: 79.77670641969043\n",
            "Epoch 104\n",
            "-------------------------------\n",
            "Iteration: 50800. Loss: 0.4944603741168976. Accuracy: 79.64983506724181\n",
            "Iteration: 50900. Loss: 0.40701037645339966. Accuracy: 81.45140827201217\n",
            "Iteration: 51000. Loss: 0.42729344964027405. Accuracy: 78.96472976401928\n",
            "Iteration: 51100. Loss: 0.8745189309120178. Accuracy: 79.82745496066988\n",
            "Iteration: 51200. Loss: 0.5869236588478088. Accuracy: 76.0466886577011\n",
            "Epoch 105\n",
            "-------------------------------\n",
            "Iteration: 51300. Loss: 0.6733313202857971. Accuracy: 80.03044912458766\n",
            "Iteration: 51400. Loss: 0.4338311553001404. Accuracy: 79.62446079675209\n",
            "Iteration: 51500. Loss: 0.679936945438385. Accuracy: 81.1469170261355\n",
            "Iteration: 51600. Loss: 0.5403367280960083. Accuracy: 79.8528292311596\n",
            "Iteration: 51700. Loss: 0.7431432604789734. Accuracy: 64.9073839127125\n",
            "Epoch 106\n",
            "-------------------------------\n",
            "Iteration: 51800. Loss: 0.7202467322349548. Accuracy: 71.02258310073586\n",
            "Iteration: 51900. Loss: 0.37138059735298157. Accuracy: 81.22303983760467\n",
            "Iteration: 52000. Loss: 0.6657223105430603. Accuracy: 67.69855366658209\n",
            "Iteration: 52100. Loss: 0.8385829329490662. Accuracy: 79.0916011164679\n",
            "Iteration: 52200. Loss: 0.6883186101913452. Accuracy: 68.76427302715047\n",
            "Epoch 107\n",
            "-------------------------------\n",
            "Iteration: 52300. Loss: 0.8565189838409424. Accuracy: 72.31667089571175\n",
            "Iteration: 52400. Loss: 0.8587663173675537. Accuracy: 73.91524993656432\n",
            "Iteration: 52500. Loss: 1.1668447256088257. Accuracy: 80.0558233950774\n",
            "Iteration: 52600. Loss: 0.4918439984321594. Accuracy: 75.81832022329358\n",
            "Iteration: 52700. Loss: 0.7459623217582703. Accuracy: 74.04212128901294\n",
            "Epoch 108\n",
            "-------------------------------\n",
            "Iteration: 52800. Loss: 0.6907697319984436. Accuracy: 73.43313879725957\n",
            "Iteration: 52900. Loss: 0.3776295483112335. Accuracy: 81.45140827201217\n",
            "Iteration: 53000. Loss: 0.5412768125534058. Accuracy: 77.39152499365643\n",
            "Iteration: 53100. Loss: 0.7398282289505005. Accuracy: 77.08703374777976\n",
            "Iteration: 53200. Loss: 1.0296225547790527. Accuracy: 69.50012687135245\n",
            "Epoch 109\n",
            "-------------------------------\n",
            "Iteration: 53300. Loss: 0.7323675751686096. Accuracy: 76.88403958386196\n",
            "Iteration: 53400. Loss: 0.231393963098526. Accuracy: 80.69018015732048\n",
            "Iteration: 53500. Loss: 0.4954626262187958. Accuracy: 80.41106318193351\n",
            "Iteration: 53600. Loss: 0.47436413168907166. Accuracy: 79.54833798528293\n",
            "Iteration: 53700. Loss: 0.40973711013793945. Accuracy: 77.64526769855367\n",
            "Epoch 110\n",
            "-------------------------------\n",
            "Iteration: 53800. Loss: 0.6521663665771484. Accuracy: 73.43313879725957\n",
            "Iteration: 53900. Loss: 0.4535321593284607. Accuracy: 78.0005074854098\n",
            "Iteration: 54000. Loss: 1.203452467918396. Accuracy: 76.22430855112916\n",
            "Iteration: 54100. Loss: 0.6904693841934204. Accuracy: 77.87363613296118\n",
            "Iteration: 54200. Loss: 0.660920262336731. Accuracy: 80.33494037046435\n",
            "Epoch 111\n",
            "-------------------------------\n",
            "Iteration: 54300. Loss: 0.42217496037483215. Accuracy: 81.62902816544025\n",
            "Iteration: 54400. Loss: 0.3890335261821747. Accuracy: 79.97970058360822\n",
            "Iteration: 54500. Loss: 0.36847057938575745. Accuracy: 79.8528292311596\n",
            "Iteration: 54600. Loss: 0.6722038388252258. Accuracy: 70.84496320730779\n",
            "Iteration: 54700. Loss: 0.40835148096084595. Accuracy: 79.5229637147932\n",
            "Epoch 112\n",
            "-------------------------------\n",
            "Iteration: 54800. Loss: 0.48365122079849243. Accuracy: 79.90357777213904\n",
            "Iteration: 54900. Loss: 0.8337097764015198. Accuracy: 70.13448363359554\n",
            "Iteration: 55000. Loss: 0.5416879653930664. Accuracy: 80.69018015732048\n",
            "Iteration: 55100. Loss: 0.45313310623168945. Accuracy: 80.0558233950774\n",
            "Iteration: 55200. Loss: 0.5275801420211792. Accuracy: 78.30499873128647\n",
            "Epoch 113\n",
            "-------------------------------\n",
            "Iteration: 55300. Loss: 0.6738213300704956. Accuracy: 76.35117990357777\n",
            "Iteration: 55400. Loss: 0.4046730697154999. Accuracy: 81.07079421466632\n",
            "Iteration: 55500. Loss: 0.660062849521637. Accuracy: 74.60035523978685\n",
            "Iteration: 55600. Loss: 0.790153980255127. Accuracy: 81.67977670641969\n",
            "Iteration: 55700. Loss: 0.9572252035140991. Accuracy: 81.42603400152245\n",
            "Epoch 114\n",
            "-------------------------------\n",
            "Iteration: 55800. Loss: 0.33537420630455017. Accuracy: 76.60492260847501\n",
            "Iteration: 55900. Loss: 0.7159079313278198. Accuracy: 72.39279370718091\n",
            "Iteration: 56000. Loss: 0.4159528911113739. Accuracy: 69.57624968282163\n",
            "Iteration: 56100. Loss: 0.6939463019371033. Accuracy: 79.21847246891652\n",
            "Iteration: 56200. Loss: 0.6748120784759521. Accuracy: 69.85536665820858\n",
            "Epoch 115\n",
            "-------------------------------\n",
            "Iteration: 56300. Loss: 0.25961947441101074. Accuracy: 76.75716823141335\n",
            "Iteration: 56400. Loss: 0.38682329654693604. Accuracy: 82.23801065719361\n",
            "Iteration: 56500. Loss: 0.31736475229263306. Accuracy: 81.73052524739914\n",
            "Iteration: 56600. Loss: 0.46808403730392456. Accuracy: 79.37071809185485\n",
            "Epoch 116\n",
            "-------------------------------\n",
            "Iteration: 56700. Loss: 0.38967448472976685. Accuracy: 82.41563055062167\n",
            "Iteration: 56800. Loss: 0.4546213746070862. Accuracy: 81.45140827201217\n",
            "Iteration: 56900. Loss: 0.5683470368385315. Accuracy: 75.64070032986551\n",
            "Iteration: 57000. Loss: 0.5752084255218506. Accuracy: 79.77670641969043\n",
            "Iteration: 57100. Loss: 0.5851569175720215. Accuracy: 76.80791677239279\n",
            "Epoch 117\n",
            "-------------------------------\n",
            "Iteration: 57200. Loss: 0.33112818002700806. Accuracy: 79.16772392793708\n",
            "Iteration: 57300. Loss: 0.39227110147476196. Accuracy: 76.7064196904339\n",
            "Iteration: 57400. Loss: 0.3548644483089447. Accuracy: 71.75843694493783\n",
            "Iteration: 57500. Loss: 0.4789092242717743. Accuracy: 77.94975894443034\n",
            "Iteration: 57600. Loss: 0.883750319480896. Accuracy: 78.55874143618371\n",
            "Epoch 118\n",
            "-------------------------------\n",
            "Iteration: 57700. Loss: 0.9491249918937683. Accuracy: 75.9451915757422\n",
            "Iteration: 57800. Loss: 0.7329918742179871. Accuracy: 78.53336716569399\n",
            "Iteration: 57900. Loss: 0.5212700366973877. Accuracy: 79.39609236234459\n",
            "Iteration: 58000. Loss: 0.3628484606742859. Accuracy: 73.9913727480335\n",
            "Iteration: 58100. Loss: 0.12687480449676514. Accuracy: 82.6693732555189\n",
            "Epoch 119\n",
            "-------------------------------\n",
            "Iteration: 58200. Loss: 0.666033923625946. Accuracy: 78.02588175589952\n",
            "Iteration: 58300. Loss: 0.5894579887390137. Accuracy: 77.72139051002284\n",
            "Iteration: 58400. Loss: 0.6130487322807312. Accuracy: 78.81248414108094\n",
            "Iteration: 58500. Loss: 0.5481105446815491. Accuracy: 72.29129662522203\n",
            "Iteration: 58600. Loss: 0.2996791899204254. Accuracy: 77.87363613296118\n",
            "Epoch 120\n",
            "-------------------------------\n",
            "Iteration: 58700. Loss: 0.6698223948478699. Accuracy: 73.1286475513829\n",
            "Iteration: 58800. Loss: 0.38894736766815186. Accuracy: 74.19436691195128\n",
            "Iteration: 58900. Loss: 0.6943458914756775. Accuracy: 73.17939609236234\n",
            "Iteration: 59000. Loss: 0.4943518340587616. Accuracy: 79.06622684597818\n",
            "Iteration: 59100. Loss: 0.4165184199810028. Accuracy: 77.92438467394062\n",
            "Epoch 121\n",
            "-------------------------------\n",
            "Iteration: 59200. Loss: 0.23443366587162018. Accuracy: 82.03501649327582\n",
            "Iteration: 59300. Loss: 0.7840249538421631. Accuracy: 63.664044658716065\n",
            "Iteration: 59400. Loss: 0.393605500459671. Accuracy: 80.23344328850546\n",
            "Iteration: 59500. Loss: 0.6204944252967834. Accuracy: 79.11697538695762\n",
            "Iteration: 59600. Loss: 0.5197475552558899. Accuracy: 80.13194620654656\n",
            "Epoch 122\n",
            "-------------------------------\n",
            "Iteration: 59700. Loss: 0.45385855436325073. Accuracy: 77.97513321492008\n",
            "Iteration: 59800. Loss: 0.45783165097236633. Accuracy: 79.04085257548846\n",
            "Iteration: 59900. Loss: 0.24811655282974243. Accuracy: 79.9543263131185\n",
            "Iteration: 60000. Loss: 1.0715142488479614. Accuracy: 68.05379345343822\n",
            "Iteration: 60100. Loss: 0.46463677287101746. Accuracy: 79.11697538695762\n",
            "Epoch 123\n",
            "-------------------------------\n",
            "Iteration: 60200. Loss: 0.49281081557273865. Accuracy: 79.8528292311596\n",
            "Iteration: 60300. Loss: 0.7543085813522339. Accuracy: 76.83329104288252\n",
            "Iteration: 60400. Loss: 0.5551803112030029. Accuracy: 80.96929713270744\n",
            "Iteration: 60500. Loss: 0.7763851881027222. Accuracy: 79.92895204262878\n",
            "Iteration: 60600. Loss: 0.22939035296440125. Accuracy: 81.65440243592997\n",
            "Epoch 124\n",
            "-------------------------------\n",
            "Iteration: 60700. Loss: 0.38668692111968994. Accuracy: 78.96472976401928\n",
            "Iteration: 60800. Loss: 0.4436599016189575. Accuracy: 81.67977670641969\n",
            "Iteration: 60900. Loss: 1.1241339445114136. Accuracy: 74.24511545293073\n",
            "Iteration: 61000. Loss: 0.3884120285511017. Accuracy: 81.75589951788886\n",
            "Iteration: 61100. Loss: 0.316074013710022. Accuracy: 81.70515097690941\n",
            "Epoch 125\n",
            "-------------------------------\n",
            "Iteration: 61200. Loss: 0.5822473764419556. Accuracy: 75.8436944937833\n",
            "Iteration: 61300. Loss: 0.35884127020835876. Accuracy: 77.82288759198173\n",
            "Iteration: 61400. Loss: 0.35105031728744507. Accuracy: 81.2484141080944\n",
            "Iteration: 61500. Loss: 0.6887061595916748. Accuracy: 75.23471200202994\n",
            "Iteration: 61600. Loss: 0.5470983386039734. Accuracy: 81.17229129662522\n",
            "Epoch 126\n",
            "-------------------------------\n",
            "Iteration: 61700. Loss: 0.417835533618927. Accuracy: 80.63943161634103\n",
            "Iteration: 61800. Loss: 0.21242570877075195. Accuracy: 81.45140827201217\n",
            "Iteration: 61900. Loss: 0.6111346483230591. Accuracy: 80.79167723927937\n",
            "Iteration: 62000. Loss: 0.8051149249076843. Accuracy: 76.50342552651611\n",
            "Iteration: 62100. Loss: 0.7389572262763977. Accuracy: 80.91854859172798\n",
            "Epoch 127\n",
            "-------------------------------\n",
            "Iteration: 62200. Loss: 0.2918805480003357. Accuracy: 78.78710987059122\n",
            "Iteration: 62300. Loss: 0.8070930242538452. Accuracy: 78.7617356001015\n",
            "Iteration: 62400. Loss: 0.3460942506790161. Accuracy: 76.40192844455721\n",
            "Iteration: 62500. Loss: 0.6260504126548767. Accuracy: 82.26338492768333\n",
            "Iteration: 62600. Loss: 0.4824393391609192. Accuracy: 81.75589951788886\n",
            "Epoch 128\n",
            "-------------------------------\n",
            "Iteration: 62700. Loss: 0.6039524078369141. Accuracy: 77.59451915757423\n",
            "Iteration: 62800. Loss: 0.6831513047218323. Accuracy: 76.60492260847501\n",
            "Iteration: 62900. Loss: 0.43174779415130615. Accuracy: 74.82872367419436\n",
            "Iteration: 63000. Loss: 0.5843520164489746. Accuracy: 77.67064196904339\n",
            "Iteration: 63100. Loss: 0.39525920152664185. Accuracy: 77.92438467394062\n",
            "Epoch 129\n",
            "-------------------------------\n",
            "Iteration: 63200. Loss: 0.5326253175735474. Accuracy: 79.59908652626237\n",
            "Iteration: 63300. Loss: 0.8695827722549438. Accuracy: 74.93022075615326\n",
            "Iteration: 63400. Loss: 0.39577484130859375. Accuracy: 81.8066480588683\n",
            "Iteration: 63500. Loss: 0.7323442697525024. Accuracy: 82.7708703374778\n",
            "Epoch 130\n",
            "-------------------------------\n",
            "Iteration: 63600. Loss: 0.5285211205482483. Accuracy: 82.74549606698807\n",
            "Iteration: 63700. Loss: 1.1171612739562988. Accuracy: 75.38695762496828\n",
            "Iteration: 63800. Loss: 0.470805823802948. Accuracy: 79.37071809185485\n",
            "Iteration: 63900. Loss: 0.6000027656555176. Accuracy: 78.3303730017762\n",
            "Iteration: 64000. Loss: 0.6225422024726868. Accuracy: 72.77340776452677\n",
            "Epoch 131\n",
            "-------------------------------\n",
            "Iteration: 64100. Loss: 0.7076207399368286. Accuracy: 69.8807409286983\n",
            "Iteration: 64200. Loss: 0.449317067861557. Accuracy: 80.89317432123826\n",
            "Iteration: 64300. Loss: 0.5074426531791687. Accuracy: 79.8528292311596\n",
            "Iteration: 64400. Loss: 0.6614025235176086. Accuracy: 80.69018015732048\n",
            "Iteration: 64500. Loss: 0.5043548345565796. Accuracy: 81.50215681299163\n",
            "Epoch 132\n",
            "-------------------------------\n",
            "Iteration: 64600. Loss: 0.27595841884613037. Accuracy: 79.59908652626237\n",
            "Iteration: 64700. Loss: 0.4400518536567688. Accuracy: 79.14234965744735\n",
            "Iteration: 64800. Loss: 0.32818248867988586. Accuracy: 82.44100482111139\n",
            "Iteration: 64900. Loss: 0.5139557123184204. Accuracy: 78.20350164932758\n",
            "Iteration: 65000. Loss: 1.498687982559204. Accuracy: 66.12534889621924\n",
            "Epoch 133\n",
            "-------------------------------\n",
            "Iteration: 65100. Loss: 0.7044639587402344. Accuracy: 71.98680537934534\n",
            "Iteration: 65200. Loss: 0.8506985902786255. Accuracy: 80.96929713270744\n",
            "Iteration: 65300. Loss: 0.49582144618034363. Accuracy: 82.6693732555189\n",
            "Iteration: 65400. Loss: 0.3253074884414673. Accuracy: 82.16188784572444\n",
            "Iteration: 65500. Loss: 0.5170266628265381. Accuracy: 81.9081451408272\n",
            "Epoch 134\n",
            "-------------------------------\n",
            "Iteration: 65600. Loss: 0.31046074628829956. Accuracy: 65.99847754377062\n",
            "Iteration: 65700. Loss: 0.49098896980285645. Accuracy: 80.8170515097691\n",
            "Iteration: 65800. Loss: 0.4175795614719391. Accuracy: 74.93022075615326\n",
            "Iteration: 65900. Loss: 0.49439913034439087. Accuracy: 81.83202232935803\n",
            "Iteration: 66000. Loss: 0.4843388497829437. Accuracy: 82.36488200964223\n",
            "Epoch 135\n",
            "-------------------------------\n",
            "Iteration: 66100. Loss: 0.3505430519580841. Accuracy: 81.45140827201217\n",
            "Iteration: 66200. Loss: 0.4052276313304901. Accuracy: 77.08703374777976\n",
            "Iteration: 66300. Loss: 0.40166449546813965. Accuracy: 81.55290535397107\n",
            "Iteration: 66400. Loss: 0.4599139988422394. Accuracy: 75.41233189545801\n",
            "Iteration: 66500. Loss: 0.2514638900756836. Accuracy: 82.51712763258057\n",
            "Epoch 136\n",
            "-------------------------------\n",
            "Iteration: 66600. Loss: 0.8426206111907959. Accuracy: 76.75716823141335\n",
            "Iteration: 66700. Loss: 0.7664209604263306. Accuracy: 79.47221517381375\n",
            "Iteration: 66800. Loss: 0.2487410604953766. Accuracy: 81.02004567368688\n",
            "Iteration: 66900. Loss: 0.7977921962738037. Accuracy: 79.24384673940624\n",
            "Iteration: 67000. Loss: 0.36721041798591614. Accuracy: 79.77670641969043\n",
            "Epoch 137\n",
            "-------------------------------\n",
            "Iteration: 67100. Loss: 0.49389854073524475. Accuracy: 80.89317432123826\n",
            "Iteration: 67200. Loss: 0.4693998396396637. Accuracy: 80.74092869829992\n",
            "Iteration: 67300. Loss: 0.652298629283905. Accuracy: 69.32250697792439\n",
            "Iteration: 67400. Loss: 0.4977239966392517. Accuracy: 76.98553666582086\n",
            "Iteration: 67500. Loss: 0.3766974210739136. Accuracy: 81.22303983760467\n",
            "Epoch 138\n",
            "-------------------------------\n",
            "Iteration: 67600. Loss: 0.8552548289299011. Accuracy: 74.57498096929713\n",
            "Iteration: 67700. Loss: 0.47146034240722656. Accuracy: 77.54377061659477\n",
            "Iteration: 67800. Loss: 1.1115659475326538. Accuracy: 76.14818573965998\n",
            "Iteration: 67900. Loss: 0.43807870149612427. Accuracy: 76.57954833798529\n",
            "Iteration: 68000. Loss: 0.3008575141429901. Accuracy: 77.31540218218726\n",
            "Epoch 139\n",
            "-------------------------------\n",
            "Iteration: 68100. Loss: 0.6674069166183472. Accuracy: 78.43187008373509\n",
            "Iteration: 68200. Loss: 0.281108558177948. Accuracy: 82.94849023090586\n",
            "Iteration: 68300. Loss: 0.5988894104957581. Accuracy: 80.41106318193351\n",
            "Iteration: 68400. Loss: 0.9135990142822266. Accuracy: 78.71098705912205\n",
            "Iteration: 68500. Loss: 0.3564896583557129. Accuracy: 80.36031464095407\n",
            "Epoch 140\n",
            "-------------------------------\n",
            "Iteration: 68600. Loss: 0.9528421759605408. Accuracy: 78.53336716569399\n",
            "Iteration: 68700. Loss: 0.2835109233856201. Accuracy: 79.31996955087541\n",
            "Iteration: 68800. Loss: 0.8973352909088135. Accuracy: 72.64653641207815\n",
            "Iteration: 68900. Loss: 0.3608384132385254. Accuracy: 83.2022329358031\n",
            "Iteration: 69000. Loss: 0.5494280457496643. Accuracy: 66.15072316670896\n",
            "Epoch 141\n",
            "-------------------------------\n",
            "Iteration: 69100. Loss: 0.2914719879627228. Accuracy: 75.97056584623192\n",
            "Iteration: 69200. Loss: 0.28587964177131653. Accuracy: 78.71098705912205\n",
            "Iteration: 69300. Loss: 0.6281026601791382. Accuracy: 76.0466886577011\n",
            "Iteration: 69400. Loss: 0.592589795589447. Accuracy: 67.74930220756153\n",
            "Iteration: 69500. Loss: 0.3635556697845459. Accuracy: 81.70515097690941\n",
            "Epoch 142\n",
            "-------------------------------\n",
            "Iteration: 69600. Loss: 0.270981103181839. Accuracy: 77.59451915757423\n",
            "Iteration: 69700. Loss: 0.5456790328025818. Accuracy: 75.46308043643745\n",
            "Iteration: 69800. Loss: 0.491677850484848. Accuracy: 80.15732047703628\n",
            "Iteration: 69900. Loss: 0.3995070457458496. Accuracy: 80.25881755899518\n",
            "Iteration: 70000. Loss: 0.40870463848114014. Accuracy: 82.13651357523472\n",
            "Epoch 143\n",
            "-------------------------------\n",
            "Iteration: 70100. Loss: 1.2358980178833008. Accuracy: 80.89317432123826\n",
            "Iteration: 70200. Loss: 0.8266348242759705. Accuracy: 78.86323268206039\n",
            "Iteration: 70300. Loss: 0.4080788195133209. Accuracy: 71.20020299416392\n",
            "Iteration: 70400. Loss: 0.2844553291797638. Accuracy: 79.01547830499874\n",
            "Epoch 144\n",
            "-------------------------------\n",
            "Iteration: 70500. Loss: 0.17572791874408722. Accuracy: 81.98426795229638\n",
            "Iteration: 70600. Loss: 0.42693570256233215. Accuracy: 81.73052524739914\n",
            "Iteration: 70700. Loss: 0.8436471223831177. Accuracy: 77.67064196904339\n",
            "Iteration: 70800. Loss: 1.04355788230896. Accuracy: 78.71098705912205\n",
            "Iteration: 70900. Loss: 0.2008940726518631. Accuracy: 82.39025628013195\n",
            "Epoch 145\n",
            "-------------------------------\n",
            "Iteration: 71000. Loss: 0.5094457268714905. Accuracy: 81.60365389495053\n",
            "Iteration: 71100. Loss: 0.2991170883178711. Accuracy: 80.00507485409794\n",
            "Iteration: 71200. Loss: 1.0949949026107788. Accuracy: 73.50926160872875\n",
            "Iteration: 71300. Loss: 0.4839721620082855. Accuracy: 80.23344328850546\n",
            "Iteration: 71400. Loss: 0.410462886095047. Accuracy: 76.83329104288252\n",
            "Epoch 146\n",
            "-------------------------------\n",
            "Iteration: 71500. Loss: 0.7090495824813843. Accuracy: 80.3856889114438\n",
            "Iteration: 71600. Loss: 0.4038018584251404. Accuracy: 82.21263638670388\n",
            "Iteration: 71700. Loss: 0.31859734654426575. Accuracy: 79.62446079675209\n",
            "Iteration: 71800. Loss: 0.22776108980178833. Accuracy: 80.25881755899518\n",
            "Iteration: 71900. Loss: 0.5653563737869263. Accuracy: 75.41233189545801\n",
            "Epoch 147\n",
            "-------------------------------\n",
            "Iteration: 72000. Loss: 0.6887818574905396. Accuracy: 82.51712763258057\n",
            "Iteration: 72100. Loss: 0.46405357122421265. Accuracy: 78.96472976401928\n",
            "Iteration: 72200. Loss: 0.4622638523578644. Accuracy: 79.67520933773154\n",
            "Iteration: 72300. Loss: 0.26022931933403015. Accuracy: 77.44227353463587\n",
            "Iteration: 72400. Loss: 0.6145615577697754. Accuracy: 79.21847246891652\n",
            "Epoch 148\n",
            "-------------------------------\n",
            "Iteration: 72500. Loss: 0.32065117359161377. Accuracy: 82.49175336209083\n",
            "Iteration: 72600. Loss: 0.31912580132484436. Accuracy: 77.49302207561533\n",
            "Iteration: 72700. Loss: 0.6627346873283386. Accuracy: 80.23344328850546\n",
            "Iteration: 72800. Loss: 0.7225189208984375. Accuracy: 73.15402182187262\n",
            "Iteration: 72900. Loss: 0.7418012022972107. Accuracy: 81.02004567368688\n",
            "Epoch 149\n",
            "-------------------------------\n",
            "Iteration: 73000. Loss: 0.41784581542015076. Accuracy: 82.03501649327582\n",
            "Iteration: 73100. Loss: 0.7124350666999817. Accuracy: 80.58868307536159\n",
            "Iteration: 73200. Loss: 0.3295772969722748. Accuracy: 80.51256026389241\n",
            "Iteration: 73300. Loss: 0.5382026433944702. Accuracy: 73.76300431362598\n",
            "Iteration: 73400. Loss: 0.43303442001342773. Accuracy: 80.99467140319716\n",
            "Epoch 150\n",
            "-------------------------------\n",
            "Iteration: 73500. Loss: 0.456327348947525. Accuracy: 80.74092869829992\n",
            "Iteration: 73600. Loss: 0.21986059844493866. Accuracy: 82.13651357523472\n",
            "Iteration: 73700. Loss: 0.8799804449081421. Accuracy: 74.72722659223547\n",
            "Iteration: 73800. Loss: 0.3657979369163513. Accuracy: 84.0649581324537\n",
            "Iteration: 73900. Loss: 0.37622231245040894. Accuracy: 80.13194620654656\n",
            "Epoch 151\n",
            "-------------------------------\n",
            "Iteration: 74000. Loss: 0.3535933494567871. Accuracy: 81.83202232935803\n",
            "Iteration: 74100. Loss: 0.46931761503219604. Accuracy: 82.49175336209083\n",
            "Iteration: 74200. Loss: 0.35479408502578735. Accuracy: 77.1377822887592\n",
            "Iteration: 74300. Loss: 0.31041479110717773. Accuracy: 78.25425019030703\n",
            "Iteration: 74400. Loss: 0.4141067862510681. Accuracy: 83.91271250951534\n",
            "Epoch 152\n",
            "-------------------------------\n",
            "Iteration: 74500. Loss: 0.598295271396637. Accuracy: 74.01674701852322\n",
            "Iteration: 74600. Loss: 0.8309290409088135. Accuracy: 82.28875919817305\n",
            "Iteration: 74700. Loss: 0.7371452450752258. Accuracy: 78.68561278863233\n",
            "Iteration: 74800. Loss: 0.43461769819259644. Accuracy: 81.45140827201217\n",
            "Iteration: 74900. Loss: 0.3514406383037567. Accuracy: 81.88277087033748\n",
            "Epoch 153\n",
            "-------------------------------\n",
            "Iteration: 75000. Loss: 0.5132479667663574. Accuracy: 81.52753108348135\n",
            "Iteration: 75100. Loss: 0.8782914876937866. Accuracy: 81.98426795229638\n",
            "Iteration: 75200. Loss: 0.3698859214782715. Accuracy: 81.1469170261355\n",
            "Iteration: 75300. Loss: 0.6240357160568237. Accuracy: 80.20806901801573\n",
            "Iteration: 75400. Loss: 0.3813004195690155. Accuracy: 81.19766556711494\n",
            "Epoch 154\n",
            "-------------------------------\n",
            "Iteration: 75500. Loss: 0.3064100444316864. Accuracy: 77.56914488708449\n",
            "Iteration: 75600. Loss: 0.3080485463142395. Accuracy: 80.61405734585131\n",
            "Iteration: 75700. Loss: 0.22293725609779358. Accuracy: 71.60619132199949\n",
            "Iteration: 75800. Loss: 0.33127477765083313. Accuracy: 82.54250190307029\n",
            "Iteration: 75900. Loss: 0.629561185836792. Accuracy: 83.9634610504948\n",
            "Epoch 155\n",
            "-------------------------------\n",
            "Iteration: 76000. Loss: 0.7228780388832092. Accuracy: 80.43643745242325\n",
            "Iteration: 76100. Loss: 0.6473416686058044. Accuracy: 81.0454199441766\n",
            "Iteration: 76200. Loss: 0.48099321126937866. Accuracy: 82.54250190307029\n",
            "Iteration: 76300. Loss: 0.7921521067619324. Accuracy: 81.32453691956356\n",
            "Iteration: 76400. Loss: 0.5981268286705017. Accuracy: 79.57371225577265\n",
            "Epoch 156\n",
            "-------------------------------\n",
            "Iteration: 76500. Loss: 0.535489022731781. Accuracy: 81.98426795229638\n",
            "Iteration: 76600. Loss: 0.08468782156705856. Accuracy: 77.34077645267699\n",
            "Iteration: 76700. Loss: 0.4869549572467804. Accuracy: 82.79624460796752\n",
            "Iteration: 76800. Loss: 0.32831916213035583. Accuracy: 79.24384673940624\n",
            "Iteration: 76900. Loss: 0.658297061920166. Accuracy: 81.85739659984776\n",
            "Epoch 157\n",
            "-------------------------------\n",
            "Iteration: 77000. Loss: 0.6247647404670715. Accuracy: 79.97970058360822\n",
            "Iteration: 77100. Loss: 0.3626682460308075. Accuracy: 83.37985282923115\n",
            "Iteration: 77200. Loss: 0.5823839902877808. Accuracy: 79.16772392793708\n",
            "Iteration: 77300. Loss: 0.2950432300567627. Accuracy: 83.88733823902562\n",
            "Iteration: 77400. Loss: 0.10989073663949966. Accuracy: 75.91981730525248\n",
            "Epoch 158\n",
            "-------------------------------\n",
            "Iteration: 77500. Loss: 0.43545645475387573. Accuracy: 80.61405734585131\n",
            "Iteration: 77600. Loss: 0.9763944149017334. Accuracy: 80.89317432123826\n",
            "Iteration: 77700. Loss: 0.44829240441322327. Accuracy: 81.1469170261355\n",
            "Iteration: 77800. Loss: 0.27197155356407166. Accuracy: 81.07079421466632\n",
            "Epoch 159\n",
            "-------------------------------\n",
            "Iteration: 77900. Loss: 0.17818348109722137. Accuracy: 80.00507485409794\n",
            "Iteration: 78000. Loss: 0.27992498874664307. Accuracy: 78.68561278863233\n",
            "Iteration: 78100. Loss: 0.40841931104660034. Accuracy: 82.23801065719361\n",
            "Iteration: 78200. Loss: 0.28079742193222046. Accuracy: 82.64399898502919\n",
            "Iteration: 78300. Loss: 0.4597141444683075. Accuracy: 56.787617356001014\n",
            "Epoch 160\n",
            "-------------------------------\n",
            "Iteration: 78400. Loss: 0.31671029329299927. Accuracy: 83.70971834559757\n",
            "Iteration: 78500. Loss: 0.2878318428993225. Accuracy: 71.75843694493783\n",
            "Iteration: 78600. Loss: 0.792711615562439. Accuracy: 77.64526769855367\n",
            "Iteration: 78700. Loss: 0.39784693717956543. Accuracy: 78.15275310834814\n",
            "Iteration: 78800. Loss: 0.7522953748703003. Accuracy: 64.65364120781527\n",
            "Epoch 161\n",
            "-------------------------------\n",
            "Iteration: 78900. Loss: 0.4989340305328369. Accuracy: 70.26135498604415\n",
            "Iteration: 79000. Loss: 0.40080201625823975. Accuracy: 80.91854859172798\n",
            "Iteration: 79100. Loss: 0.6021012663841248. Accuracy: 82.21263638670388\n",
            "Iteration: 79200. Loss: 0.5638409852981567. Accuracy: 83.68434407510784\n",
            "Iteration: 79300. Loss: 0.3142186105251312. Accuracy: 81.95889368180664\n",
            "Epoch 162\n",
            "-------------------------------\n",
            "Iteration: 79400. Loss: 0.4297316372394562. Accuracy: 74.60035523978685\n",
            "Iteration: 79500. Loss: 0.7030601501464844. Accuracy: 82.51712763258057\n",
            "Iteration: 79600. Loss: 0.39265701174736023. Accuracy: 84.85156051763512\n",
            "Iteration: 79700. Loss: 0.3660983145236969. Accuracy: 82.28875919817305\n",
            "Iteration: 79800. Loss: 0.38542014360427856. Accuracy: 81.9081451408272\n",
            "Epoch 163\n",
            "-------------------------------\n",
            "Iteration: 79900. Loss: 0.3888602554798126. Accuracy: 82.36488200964223\n",
            "Iteration: 80000. Loss: 0.4095537066459656. Accuracy: 78.38112154275565\n",
            "Iteration: 80100. Loss: 0.5384378433227539. Accuracy: 81.40065973103273\n",
            "Iteration: 80200. Loss: 0.4099585711956024. Accuracy: 77.61989342806395\n",
            "Iteration: 80300. Loss: 0.6030857563018799. Accuracy: 76.85866531337224\n",
            "Epoch 164\n",
            "-------------------------------\n",
            "Iteration: 80400. Loss: 0.4063142240047455. Accuracy: 75.64070032986551\n",
            "Iteration: 80500. Loss: 0.7011873722076416. Accuracy: 69.06876427302716\n",
            "Iteration: 80600. Loss: 0.14800991117954254. Accuracy: 79.8528292311596\n",
            "Iteration: 80700. Loss: 0.1444275677204132. Accuracy: 82.64399898502919\n",
            "Iteration: 80800. Loss: 0.5393402576446533. Accuracy: 81.73052524739914\n",
            "Epoch 165\n",
            "-------------------------------\n",
            "Iteration: 80900. Loss: 0.22801843285560608. Accuracy: 84.16645521441258\n",
            "Iteration: 81000. Loss: 0.2958211600780487. Accuracy: 79.16772392793708\n",
            "Iteration: 81100. Loss: 0.5182788372039795. Accuracy: 84.0649581324537\n",
            "Iteration: 81200. Loss: 1.0339843034744263. Accuracy: 70.08373509261608\n",
            "Iteration: 81300. Loss: 0.6256749629974365. Accuracy: 82.49175336209083\n",
            "Epoch 166\n",
            "-------------------------------\n",
            "Iteration: 81400. Loss: 0.4061208963394165. Accuracy: 82.03501649327582\n",
            "Iteration: 81500. Loss: 0.4500081539154053. Accuracy: 83.35447855874143\n",
            "Iteration: 81600. Loss: 0.48797401785850525. Accuracy: 80.56330880487187\n",
            "Iteration: 81700. Loss: 0.2110048532485962. Accuracy: 78.86323268206039\n",
            "Iteration: 81800. Loss: 0.30226004123687744. Accuracy: 83.55747272265923\n",
            "Epoch 167\n",
            "-------------------------------\n",
            "Iteration: 81900. Loss: 0.6776515245437622. Accuracy: 79.44684090332403\n",
            "Iteration: 82000. Loss: 0.6407648324966431. Accuracy: 84.01420959147424\n",
            "Iteration: 82100. Loss: 0.28837981820106506. Accuracy: 79.29459528038569\n",
            "Iteration: 82200. Loss: 0.533917248249054. Accuracy: 83.07536158335448\n",
            "Iteration: 82300. Loss: 0.44272172451019287. Accuracy: 83.07536158335448\n",
            "Epoch 168\n",
            "-------------------------------\n",
            "Iteration: 82400. Loss: 0.3746698498725891. Accuracy: 81.73052524739914\n",
            "Iteration: 82500. Loss: 0.3665418028831482. Accuracy: 83.04998731286476\n",
            "Iteration: 82600. Loss: 0.2780674695968628. Accuracy: 82.92311596041614\n",
            "Iteration: 82700. Loss: 0.23482604324817657. Accuracy: 81.47678254250191\n",
            "Iteration: 82800. Loss: 0.28484153747558594. Accuracy: 78.96472976401928\n",
            "Epoch 169\n",
            "-------------------------------\n",
            "Iteration: 82900. Loss: 0.3599867522716522. Accuracy: 85.00380614057346\n",
            "Iteration: 83000. Loss: 0.3408657908439636. Accuracy: 67.95229637147932\n",
            "Iteration: 83100. Loss: 0.33181267976760864. Accuracy: 83.07536158335448\n",
            "Iteration: 83200. Loss: 0.39367881417274475. Accuracy: 78.73636132961177\n",
            "Iteration: 83300. Loss: 0.4913783371448517. Accuracy: 79.97970058360822\n",
            "Epoch 170\n",
            "-------------------------------\n",
            "Iteration: 83400. Loss: 0.5998971462249756. Accuracy: 70.9718345597564\n",
            "Iteration: 83500. Loss: 0.532791018486023. Accuracy: 77.36615072316671\n",
            "Iteration: 83600. Loss: 0.33468055725097656. Accuracy: 82.79624460796752\n",
            "Iteration: 83700. Loss: 0.3084874451160431. Accuracy: 85.02918041106318\n",
            "Iteration: 83800. Loss: 0.6166305541992188. Accuracy: 79.70058360822127\n",
            "Epoch 171\n",
            "-------------------------------\n",
            "Iteration: 83900. Loss: 0.36435046792030334. Accuracy: 79.64983506724181\n",
            "Iteration: 84000. Loss: 0.27488359808921814. Accuracy: 74.90484648566354\n",
            "Iteration: 84100. Loss: 0.3123786747455597. Accuracy: 81.57827962446079\n",
            "Iteration: 84200. Loss: 0.47418275475502014. Accuracy: 84.14108094392286\n",
            "Iteration: 84300. Loss: 0.42636987566947937. Accuracy: 79.29459528038569\n",
            "Epoch 172\n",
            "-------------------------------\n",
            "Iteration: 84400. Loss: 0.49405404925346375. Accuracy: 69.9822380106572\n",
            "Iteration: 84500. Loss: 0.1561715453863144. Accuracy: 81.67977670641969\n",
            "Iteration: 84600. Loss: 0.47180092334747314. Accuracy: 83.83658969804618\n",
            "Iteration: 84700. Loss: 0.5465879440307617. Accuracy: 79.7513321492007\n",
            "Epoch 173\n",
            "-------------------------------\n",
            "Iteration: 84800. Loss: 0.4737379550933838. Accuracy: 83.07536158335448\n",
            "Iteration: 84900. Loss: 0.13295383751392365. Accuracy: 81.50215681299163\n",
            "Iteration: 85000. Loss: 0.4689382314682007. Accuracy: 81.78127378837858\n",
            "Iteration: 85100. Loss: 0.45394712686538696. Accuracy: 78.25425019030703\n",
            "Iteration: 85200. Loss: 0.2926637828350067. Accuracy: 84.8261862471454\n",
            "Epoch 174\n",
            "-------------------------------\n",
            "Iteration: 85300. Loss: 0.36397796869277954. Accuracy: 75.89444303476274\n",
            "Iteration: 85400. Loss: 0.28403329849243164. Accuracy: 75.46308043643745\n",
            "Iteration: 85500. Loss: 0.40918782353401184. Accuracy: 84.16645521441258\n",
            "Iteration: 85600. Loss: 0.35214731097221375. Accuracy: 78.38112154275565\n",
            "Iteration: 85700. Loss: 0.768152117729187. Accuracy: 81.78127378837858\n",
            "Epoch 175\n",
            "-------------------------------\n",
            "Iteration: 85800. Loss: 0.29951730370521545. Accuracy: 77.94975894443034\n",
            "Iteration: 85900. Loss: 0.34909796714782715. Accuracy: 80.91854859172798\n",
            "Iteration: 86000. Loss: 0.3541811406612396. Accuracy: 81.62902816544025\n",
            "Iteration: 86100. Loss: 0.24947330355644226. Accuracy: 82.39025628013195\n",
            "Iteration: 86200. Loss: 0.36737117171287537. Accuracy: 74.219741182441\n",
            "Epoch 176\n",
            "-------------------------------\n",
            "Iteration: 86300. Loss: 0.25295859575271606. Accuracy: 80.03044912458766\n",
            "Iteration: 86400. Loss: 0.4973876178264618. Accuracy: 82.49175336209083\n",
            "Iteration: 86500. Loss: 0.36066582798957825. Accuracy: 81.40065973103273\n",
            "Iteration: 86600. Loss: 0.18357084691524506. Accuracy: 72.64653641207815\n",
            "Iteration: 86700. Loss: 0.4336076080799103. Accuracy: 75.81832022329358\n",
            "Epoch 177\n",
            "-------------------------------\n",
            "Iteration: 86800. Loss: 0.3084850609302521. Accuracy: 84.11570667343314\n",
            "Iteration: 86900. Loss: 0.7661074995994568. Accuracy: 78.05125602638924\n",
            "Iteration: 87000. Loss: 0.5225845575332642. Accuracy: 83.9634610504948\n",
            "Iteration: 87100. Loss: 0.4472659230232239. Accuracy: 81.47678254250191\n",
            "Iteration: 87200. Loss: 0.11653707921504974. Accuracy: 79.37071809185485\n",
            "Epoch 178\n",
            "-------------------------------\n",
            "Iteration: 87300. Loss: 0.714077889919281. Accuracy: 83.17685866531338\n",
            "Iteration: 87400. Loss: 0.31256103515625. Accuracy: 74.77797513321492\n",
            "Iteration: 87500. Loss: 0.4357439875602722. Accuracy: 78.38112154275565\n",
            "Iteration: 87600. Loss: 0.1535455882549286. Accuracy: 80.25881755899518\n",
            "Iteration: 87700. Loss: 0.2675108313560486. Accuracy: 81.83202232935803\n",
            "Epoch 179\n",
            "-------------------------------\n",
            "Iteration: 87800. Loss: 0.5082390308380127. Accuracy: 84.0649581324537\n",
            "Iteration: 87900. Loss: 0.8364889621734619. Accuracy: 82.94849023090586\n",
            "Iteration: 88000. Loss: 0.28609347343444824. Accuracy: 84.59781781273789\n",
            "Iteration: 88100. Loss: 0.20611447095870972. Accuracy: 63.232682060390765\n",
            "Iteration: 88200. Loss: 0.39847660064697266. Accuracy: 84.75006343567622\n",
            "Epoch 180\n",
            "-------------------------------\n",
            "Iteration: 88300. Loss: 0.41323122382164. Accuracy: 80.36031464095407\n",
            "Iteration: 88400. Loss: 0.6833131313323975. Accuracy: 81.70515097690941\n",
            "Iteration: 88500. Loss: 0.5522263646125793. Accuracy: 84.92768332910428\n",
            "Iteration: 88600. Loss: 0.396572470664978. Accuracy: 68.96726719106826\n",
            "Iteration: 88700. Loss: 0.2820572853088379. Accuracy: 80.18269474752601\n",
            "Epoch 181\n",
            "-------------------------------\n",
            "Iteration: 88800. Loss: 0.46496063470840454. Accuracy: 82.94849023090586\n",
            "Iteration: 88900. Loss: 0.2908710837364197. Accuracy: 80.76630296878965\n",
            "Iteration: 89000. Loss: 0.29743391275405884. Accuracy: 83.07536158335448\n",
            "Iteration: 89100. Loss: 0.3385257422924042. Accuracy: 81.42603400152245\n",
            "Iteration: 89200. Loss: 0.4636056125164032. Accuracy: 80.15732047703628\n",
            "Epoch 182\n",
            "-------------------------------\n",
            "Iteration: 89300. Loss: 0.30481454730033875. Accuracy: 83.91271250951534\n",
            "Iteration: 89400. Loss: 0.8227881193161011. Accuracy: 81.93351941131692\n",
            "Iteration: 89500. Loss: 0.2280368208885193. Accuracy: 83.58284699314895\n",
            "Iteration: 89600. Loss: 0.5633898377418518. Accuracy: 83.07536158335448\n",
            "Iteration: 89700. Loss: 0.31699123978614807. Accuracy: 76.98553666582086\n",
            "Epoch 183\n",
            "-------------------------------\n",
            "Iteration: 89800. Loss: 0.3671489655971527. Accuracy: 84.49632073077899\n",
            "Iteration: 89900. Loss: 0.756625771522522. Accuracy: 83.27835574727227\n",
            "Iteration: 90000. Loss: 0.44987067580223083. Accuracy: 83.02461304237504\n",
            "Iteration: 90100. Loss: 0.35925978422164917. Accuracy: 80.33494037046435\n",
            "Iteration: 90200. Loss: 0.7774090766906738. Accuracy: 61.38036031464095\n",
            "Epoch 184\n",
            "-------------------------------\n",
            "Iteration: 90300. Loss: 0.42448890209198. Accuracy: 68.58665313372241\n",
            "Iteration: 90400. Loss: 0.37227389216423035. Accuracy: 84.85156051763512\n",
            "Iteration: 90500. Loss: 0.4490374028682709. Accuracy: 84.26795229637148\n",
            "Iteration: 90600. Loss: 0.6219591498374939. Accuracy: 78.02588175589952\n",
            "Iteration: 90700. Loss: 0.7363411784172058. Accuracy: 79.29459528038569\n",
            "Epoch 185\n",
            "-------------------------------\n",
            "Iteration: 90800. Loss: 0.6713855266571045. Accuracy: 80.58868307536159\n",
            "Iteration: 90900. Loss: 0.6173872947692871. Accuracy: 81.37528546054301\n",
            "Iteration: 91000. Loss: 0.2713834047317505. Accuracy: 83.68434407510784\n",
            "Iteration: 91100. Loss: 0.4871026873588562. Accuracy: 81.52753108348135\n",
            "Iteration: 91200. Loss: 0.3966621458530426. Accuracy: 82.72012179649835\n",
            "Epoch 186\n",
            "-------------------------------\n",
            "Iteration: 91300. Loss: 0.05921948701143265. Accuracy: 81.95889368180664\n",
            "Iteration: 91400. Loss: 0.5282036066055298. Accuracy: 77.46764780512561\n",
            "Iteration: 91500. Loss: 0.2342040240764618. Accuracy: 78.93935549352956\n",
            "Iteration: 91600. Loss: 0.30180245637893677. Accuracy: 81.37528546054301\n",
            "Epoch 187\n",
            "-------------------------------\n",
            "Iteration: 91700. Loss: 0.43399593234062195. Accuracy: 84.31870083735093\n",
            "Iteration: 91800. Loss: 0.712704062461853. Accuracy: 79.49758944430347\n",
            "Iteration: 91900. Loss: 0.6414615511894226. Accuracy: 84.52169500126871\n",
            "Iteration: 92000. Loss: 0.517030656337738. Accuracy: 78.05125602638924\n",
            "Iteration: 92100. Loss: 0.49355557560920715. Accuracy: 79.06622684597818\n",
            "Epoch 188\n",
            "-------------------------------\n",
            "Iteration: 92200. Loss: 0.3175095319747925. Accuracy: 83.55747272265923\n",
            "Iteration: 92300. Loss: 0.523213803768158. Accuracy: 84.49632073077899\n",
            "Iteration: 92400. Loss: 0.4749806523323059. Accuracy: 83.60822126363867\n",
            "Iteration: 92500. Loss: 0.40555667877197266. Accuracy: 82.92311596041614\n",
            "Iteration: 92600. Loss: 0.2633857727050781. Accuracy: 82.9992387718853\n",
            "Epoch 189\n",
            "-------------------------------\n",
            "Iteration: 92700. Loss: 0.28303882479667664. Accuracy: 84.57244354224817\n",
            "Iteration: 92800. Loss: 0.08197592198848724. Accuracy: 75.46308043643745\n",
            "Iteration: 92900. Loss: 0.24137133359909058. Accuracy: 84.47094646028927\n",
            "Iteration: 93000. Loss: 0.5335566997528076. Accuracy: 83.88733823902562\n",
            "Iteration: 93100. Loss: 0.6173608303070068. Accuracy: 79.54833798528293\n",
            "Epoch 190\n",
            "-------------------------------\n",
            "Iteration: 93200. Loss: 0.4460202157497406. Accuracy: 78.27962446079675\n",
            "Iteration: 93300. Loss: 0.243305504322052. Accuracy: 83.9634610504948\n",
            "Iteration: 93400. Loss: 1.009135127067566. Accuracy: 83.65896980461812\n",
            "Iteration: 93500. Loss: 0.6822651624679565. Accuracy: 81.17229129662522\n",
            "Iteration: 93600. Loss: 0.3169088661670685. Accuracy: 82.13651357523472\n",
            "Epoch 191\n",
            "-------------------------------\n",
            "Iteration: 93700. Loss: 0.5345515012741089. Accuracy: 82.82161887845724\n",
            "Iteration: 93800. Loss: 0.3751913905143738. Accuracy: 84.97843187008374\n",
            "Iteration: 93900. Loss: 0.3963333070278168. Accuracy: 75.97056584623192\n",
            "Iteration: 94000. Loss: 0.36467933654785156. Accuracy: 83.65896980461812\n",
            "Iteration: 94100. Loss: 0.37991389632225037. Accuracy: 75.51382897741689\n",
            "Epoch 192\n",
            "-------------------------------\n",
            "Iteration: 94200. Loss: 0.1333000659942627. Accuracy: 86.06952550114184\n",
            "Iteration: 94300. Loss: 0.3890964686870575. Accuracy: 72.79878203501649\n",
            "Iteration: 94400. Loss: 0.33978271484375. Accuracy: 80.99467140319716\n",
            "Iteration: 94500. Loss: 0.6893917322158813. Accuracy: 77.08703374777976\n",
            "Iteration: 94600. Loss: 0.2816310524940491. Accuracy: 84.67394062420705\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8_GyIxVijwAj",
        "outputId": "b32316dd-d304-4110-f83a-6b98fe1ca432"
      },
      "source": [
        "print(model_ds1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DeepNeuralNetworkModel(\n",
            "  (linear_1): Linear(in_features=784, out_features=200, bias=True)\n",
            "  (act_1): Tanh()\n",
            "  (linear_2): Linear(in_features=200, out_features=200, bias=True)\n",
            "  (act_2): Tanh()\n",
            "  (linear_3): Linear(in_features=200, out_features=200, bias=True)\n",
            "  (act_3): Tanh()\n",
            "  (linear_4): Linear(in_features=200, out_features=200, bias=True)\n",
            "  (act_4): Tanh()\n",
            "  (linear_5): Linear(in_features=200, out_features=200, bias=True)\n",
            "  (act_5): Tanh()\n",
            "  (linear_6): Linear(in_features=200, out_features=200, bias=True)\n",
            "  (act_6): Tanh()\n",
            "  (linear_out): Linear(in_features=200, out_features=10, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2wwmqlxEjv9U"
      },
      "source": [
        "torch.save(model_ds1.state_dict(), '/content/drive/MyDrive/Soft Computing Lab/model_exp2_ds_a.pt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mIO6XmBxWFHM"
      },
      "source": [
        "### Iteration vs Loss graph"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "RvfTs-xYWQYX",
        "outputId": "43a985e2-c194-4f27-83ff-d5810b078cbd"
      },
      "source": [
        "iter_range=np.arange(0,94700,100)\n",
        "plt.xlabel('Iteration')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Iteration vs Loss graph for dataset-A')\n",
        "plt.plot(iter_range,iter_loss_ds1);"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GGpPKVbDpc5E"
      },
      "source": [
        "### Load the train and test set of dataset-2 from drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ov-db_r0pcLp",
        "outputId": "bfd60940-aa70-42ab-b8eb-c839c132e88b"
      },
      "source": [
        "train_set_ds2=torch.load('/content/drive/MyDrive/Soft Computing Lab/training_set_2.pt')\n",
        "test_set_ds2=torch.load('/content/drive/MyDrive/Soft Computing Lab/testing_set_2.pt')\n",
        "train_set_ds2[0][0].shape,test_set_ds2[0][0].shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([1, 28, 28]), torch.Size([1, 28, 28]))"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q-GRh0F_eJMN"
      },
      "source": [
        "### Evaluate model on `Dataset 2`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zHQskzdYaxTV",
        "outputId": "fe228660-7e24-4ac6-c89d-35e1c7d7bf16"
      },
      "source": [
        "g = torch.Generator()\n",
        "g.manual_seed(42)\n",
        "model_ds2 = DeepNeuralNetworkModel(input_size = input_dim,\n",
        "                               num_classes = output_dim,\n",
        "                               num_hidden = num_hidden)\n",
        "model_ds2.to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model_ds2.parameters(), lr=learning_rate)\n",
        "\n",
        "train_loader_ds2 = torch.utils.data.DataLoader(dataset=train_set_ds2, \n",
        "                                           batch_size=batch_size, \n",
        "                                           shuffle=True,\n",
        "                                           generator=g)\n",
        "\n",
        "test_loader_ds2 = torch.utils.data.DataLoader(dataset=test_set_ds2, \n",
        "                                          batch_size=batch_size, \n",
        "                                          shuffle=False)\n",
        "\n",
        "num_epochs_ds2 = num_iters / (len(train_set_ds2) / batch_size)\n",
        "num_epochs_ds2 = int(num_epochs_ds2)\n",
        "iter_loss_ds2=evaluate_model(model_ds2,train_loader_ds2,test_loader_ds2,num_epochs_ds2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "-------------------------------\n",
            "Iteration: 0. Loss: 2.3124630451202393. Accuracy: 10.0\n",
            "Iteration: 100. Loss: 1.230684757232666. Accuracy: 47.63\n",
            "Iteration: 200. Loss: 0.9441340565681458. Accuracy: 59.89\n",
            "Iteration: 300. Loss: 1.1022429466247559. Accuracy: 66.2\n",
            "Iteration: 400. Loss: 0.7023475170135498. Accuracy: 69.92\n",
            "Iteration: 500. Loss: 1.121370553970337. Accuracy: 72.91\n",
            "Iteration: 600. Loss: 0.5624690055847168. Accuracy: 73.33\n",
            "Iteration: 700. Loss: 0.44508665800094604. Accuracy: 75.9\n",
            "Iteration: 800. Loss: 0.540910005569458. Accuracy: 77.95\n",
            "Iteration: 900. Loss: 0.6426400542259216. Accuracy: 78.73\n",
            "Iteration: 1000. Loss: 0.4541211724281311. Accuracy: 79.71\n",
            "Iteration: 1100. Loss: 1.1283775568008423. Accuracy: 79.81\n",
            "Iteration: 1200. Loss: 0.8185717463493347. Accuracy: 79.63\n",
            "Iteration: 1300. Loss: 0.3994275629520416. Accuracy: 80.46\n",
            "Iteration: 1400. Loss: 0.9227643609046936. Accuracy: 81.63\n",
            "Iteration: 1500. Loss: 0.5264735817909241. Accuracy: 80.97\n",
            "Iteration: 1600. Loss: 0.44603604078292847. Accuracy: 81.96\n",
            "Iteration: 1700. Loss: 0.4666939675807953. Accuracy: 81.89\n",
            "Iteration: 1800. Loss: 0.6822455525398254. Accuracy: 81.78\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "Iteration: 1900. Loss: 0.3832663297653198. Accuracy: 82.53\n",
            "Iteration: 2000. Loss: 0.48457297682762146. Accuracy: 80.8\n",
            "Iteration: 2100. Loss: 0.29548099637031555. Accuracy: 82.69\n",
            "Iteration: 2200. Loss: 0.5575433969497681. Accuracy: 82.93\n",
            "Iteration: 2300. Loss: 0.4555529057979584. Accuracy: 82.02\n",
            "Iteration: 2400. Loss: 0.3070470988750458. Accuracy: 82.71\n",
            "Iteration: 2500. Loss: 0.573049783706665. Accuracy: 83.21\n",
            "Iteration: 2600. Loss: 0.6373180150985718. Accuracy: 82.1\n",
            "Iteration: 2700. Loss: 0.6000268459320068. Accuracy: 83.2\n",
            "Iteration: 2800. Loss: 0.35279935598373413. Accuracy: 83.28\n",
            "Iteration: 2900. Loss: 0.7223410606384277. Accuracy: 83.23\n",
            "Iteration: 3000. Loss: 0.5364987850189209. Accuracy: 83.67\n",
            "Iteration: 3100. Loss: 0.5323123335838318. Accuracy: 83.41\n",
            "Iteration: 3200. Loss: 0.5363401174545288. Accuracy: 83.33\n",
            "Iteration: 3300. Loss: 0.6332160830497742. Accuracy: 82.73\n",
            "Iteration: 3400. Loss: 0.24326862394809723. Accuracy: 83.77\n",
            "Iteration: 3500. Loss: 0.5858348608016968. Accuracy: 84.26\n",
            "Iteration: 3600. Loss: 0.6579387784004211. Accuracy: 83.33\n",
            "Iteration: 3700. Loss: 0.13647538423538208. Accuracy: 83.86\n",
            "Epoch 3\n",
            "-------------------------------\n",
            "Iteration: 3800. Loss: 0.6134747266769409. Accuracy: 83.99\n",
            "Iteration: 3900. Loss: 0.5031991600990295. Accuracy: 84.59\n",
            "Iteration: 4000. Loss: 0.25531941652297974. Accuracy: 84.67\n",
            "Iteration: 4100. Loss: 0.4581376612186432. Accuracy: 84.52\n",
            "Iteration: 4200. Loss: 0.46250155568122864. Accuracy: 84.35\n",
            "Iteration: 4300. Loss: 0.5235388278961182. Accuracy: 84.31\n",
            "Iteration: 4400. Loss: 0.3067241907119751. Accuracy: 84.49\n",
            "Iteration: 4500. Loss: 0.45949676632881165. Accuracy: 84.8\n",
            "Iteration: 4600. Loss: 0.39579710364341736. Accuracy: 83.94\n",
            "Iteration: 4700. Loss: 0.3984394669532776. Accuracy: 84.55\n",
            "Iteration: 4800. Loss: 0.5022925138473511. Accuracy: 83.86\n",
            "Iteration: 4900. Loss: 0.4528438448905945. Accuracy: 84.94\n",
            "Iteration: 5000. Loss: 0.366370290517807. Accuracy: 84.8\n",
            "Iteration: 5100. Loss: 0.6010907292366028. Accuracy: 84.19\n",
            "Iteration: 5200. Loss: 0.5026278495788574. Accuracy: 84.03\n",
            "Iteration: 5300. Loss: 0.38641461730003357. Accuracy: 84.94\n",
            "Iteration: 5400. Loss: 0.3380710482597351. Accuracy: 84.86\n",
            "Iteration: 5500. Loss: 0.21283146739006042. Accuracy: 85.35\n",
            "Iteration: 5600. Loss: 0.5822575092315674. Accuracy: 85.33\n",
            "Epoch 4\n",
            "-------------------------------\n",
            "Iteration: 5700. Loss: 0.3903343975543976. Accuracy: 85.33\n",
            "Iteration: 5800. Loss: 0.5301834344863892. Accuracy: 84.75\n",
            "Iteration: 5900. Loss: 0.16135674715042114. Accuracy: 84.52\n",
            "Iteration: 6000. Loss: 0.34213143587112427. Accuracy: 84.33\n",
            "Iteration: 6100. Loss: 0.4301529824733734. Accuracy: 84.93\n",
            "Iteration: 6200. Loss: 0.6689271926879883. Accuracy: 84.51\n",
            "Iteration: 6300. Loss: 0.4805624485015869. Accuracy: 85.64\n",
            "Iteration: 6400. Loss: 0.3074890375137329. Accuracy: 85.55\n",
            "Iteration: 6500. Loss: 0.36181649565696716. Accuracy: 84.9\n",
            "Iteration: 6600. Loss: 0.3132302463054657. Accuracy: 85.68\n",
            "Iteration: 6700. Loss: 0.47188180685043335. Accuracy: 84.52\n",
            "Iteration: 6800. Loss: 0.25419580936431885. Accuracy: 85.78\n",
            "Iteration: 6900. Loss: 0.28100091218948364. Accuracy: 85.37\n",
            "Iteration: 7000. Loss: 0.18306787312030792. Accuracy: 85.32\n",
            "Iteration: 7100. Loss: 0.6302620768547058. Accuracy: 85.58\n",
            "Iteration: 7200. Loss: 0.4972310960292816. Accuracy: 85.81\n",
            "Iteration: 7300. Loss: 0.19439175724983215. Accuracy: 85.15\n",
            "Iteration: 7400. Loss: 0.259464830160141. Accuracy: 85.04\n",
            "Epoch 5\n",
            "-------------------------------\n",
            "Iteration: 7500. Loss: 0.23775357007980347. Accuracy: 84.79\n",
            "Iteration: 7600. Loss: 0.19042307138442993. Accuracy: 84.72\n",
            "Iteration: 7700. Loss: 0.41506582498550415. Accuracy: 85.51\n",
            "Iteration: 7800. Loss: 0.349756121635437. Accuracy: 85.83\n",
            "Iteration: 7900. Loss: 0.34151506423950195. Accuracy: 85.48\n",
            "Iteration: 8000. Loss: 0.4015475809574127. Accuracy: 84.99\n",
            "Iteration: 8100. Loss: 0.4770411550998688. Accuracy: 84.78\n",
            "Iteration: 8200. Loss: 0.3085964322090149. Accuracy: 85.41\n",
            "Iteration: 8300. Loss: 0.519762396812439. Accuracy: 85.4\n",
            "Iteration: 8400. Loss: 0.22201058268547058. Accuracy: 86.08\n",
            "Iteration: 8500. Loss: 0.18611140549182892. Accuracy: 85.77\n",
            "Iteration: 8600. Loss: 0.48744747042655945. Accuracy: 85.83\n",
            "Iteration: 8700. Loss: 0.200351744890213. Accuracy: 85.58\n",
            "Iteration: 8800. Loss: 0.3975067436695099. Accuracy: 85.3\n",
            "Iteration: 8900. Loss: 0.42355990409851074. Accuracy: 85.75\n",
            "Iteration: 9000. Loss: 0.5001280903816223. Accuracy: 85.83\n",
            "Iteration: 9100. Loss: 0.2508099377155304. Accuracy: 83.75\n",
            "Iteration: 9200. Loss: 0.3103005886077881. Accuracy: 85.85\n",
            "Iteration: 9300. Loss: 0.36002814769744873. Accuracy: 85.87\n",
            "Epoch 6\n",
            "-------------------------------\n",
            "Iteration: 9400. Loss: 0.43450361490249634. Accuracy: 86.25\n",
            "Iteration: 9500. Loss: 0.383353590965271. Accuracy: 86.16\n",
            "Iteration: 9600. Loss: 0.1840537190437317. Accuracy: 86.19\n",
            "Iteration: 9700. Loss: 0.2329259067773819. Accuracy: 86.06\n",
            "Iteration: 9800. Loss: 0.45959728956222534. Accuracy: 85.95\n",
            "Iteration: 9900. Loss: 0.2786708176136017. Accuracy: 85.83\n",
            "Iteration: 10000. Loss: 0.3072809875011444. Accuracy: 86.3\n",
            "Iteration: 10100. Loss: 0.4851331114768982. Accuracy: 85.57\n",
            "Iteration: 10200. Loss: 0.2841828167438507. Accuracy: 85.77\n",
            "Iteration: 10300. Loss: 0.2849371135234833. Accuracy: 86.39\n",
            "Iteration: 10400. Loss: 0.31810298562049866. Accuracy: 86.26\n",
            "Iteration: 10500. Loss: 0.37078577280044556. Accuracy: 84.96\n",
            "Iteration: 10600. Loss: 0.28492581844329834. Accuracy: 85.75\n",
            "Iteration: 10700. Loss: 0.3171047568321228. Accuracy: 86.01\n",
            "Iteration: 10800. Loss: 0.2568296790122986. Accuracy: 86.39\n",
            "Iteration: 10900. Loss: 0.3026191294193268. Accuracy: 86.22\n",
            "Iteration: 11000. Loss: 0.17524923384189606. Accuracy: 86.68\n",
            "Iteration: 11100. Loss: 0.3366268575191498. Accuracy: 86.54\n",
            "Iteration: 11200. Loss: 0.5232346057891846. Accuracy: 86.72\n",
            "Epoch 7\n",
            "-------------------------------\n",
            "Iteration: 11300. Loss: 0.3230184316635132. Accuracy: 85.22\n",
            "Iteration: 11400. Loss: 0.2411586493253708. Accuracy: 86.38\n",
            "Iteration: 11500. Loss: 0.1569017916917801. Accuracy: 85.85\n",
            "Iteration: 11600. Loss: 0.29647669196128845. Accuracy: 85.78\n",
            "Iteration: 11700. Loss: 0.4324471950531006. Accuracy: 86.26\n",
            "Iteration: 11800. Loss: 0.1917763352394104. Accuracy: 85.94\n",
            "Iteration: 11900. Loss: 0.2591125965118408. Accuracy: 85.79\n",
            "Iteration: 12000. Loss: 0.4163112938404083. Accuracy: 86.71\n",
            "Iteration: 12100. Loss: 0.35838285088539124. Accuracy: 86.81\n",
            "Iteration: 12200. Loss: 0.43941906094551086. Accuracy: 86.53\n",
            "Iteration: 12300. Loss: 0.3840380012989044. Accuracy: 86.72\n",
            "Iteration: 12400. Loss: 0.2385682314634323. Accuracy: 85.99\n",
            "Iteration: 12500. Loss: 0.21624603867530823. Accuracy: 86.58\n",
            "Iteration: 12600. Loss: 0.6663679480552673. Accuracy: 86.76\n",
            "Iteration: 12700. Loss: 0.2932075560092926. Accuracy: 85.77\n",
            "Iteration: 12800. Loss: 0.2318267673254013. Accuracy: 86.63\n",
            "Iteration: 12900. Loss: 0.3166504502296448. Accuracy: 86.45\n",
            "Iteration: 13000. Loss: 0.4109936058521271. Accuracy: 86.05\n",
            "Iteration: 13100. Loss: 0.19711218774318695. Accuracy: 85.9\n",
            "Epoch 8\n",
            "-------------------------------\n",
            "Iteration: 13200. Loss: 0.41435766220092773. Accuracy: 86.9\n",
            "Iteration: 13300. Loss: 0.4777699112892151. Accuracy: 86.92\n",
            "Iteration: 13400. Loss: 0.6461656093597412. Accuracy: 86.59\n",
            "Iteration: 13500. Loss: 0.2209380716085434. Accuracy: 86.53\n",
            "Iteration: 13600. Loss: 0.3378102779388428. Accuracy: 86.66\n",
            "Iteration: 13700. Loss: 0.39198607206344604. Accuracy: 86.57\n",
            "Iteration: 13800. Loss: 0.4749124050140381. Accuracy: 86.34\n",
            "Iteration: 13900. Loss: 0.2939802408218384. Accuracy: 86.35\n",
            "Iteration: 14000. Loss: 0.2190065234899521. Accuracy: 84.98\n",
            "Iteration: 14100. Loss: 0.4617740511894226. Accuracy: 86.8\n",
            "Iteration: 14200. Loss: 0.47826245427131653. Accuracy: 86.57\n",
            "Iteration: 14300. Loss: 0.6554570198059082. Accuracy: 86.29\n",
            "Iteration: 14400. Loss: 0.2566341757774353. Accuracy: 86.87\n",
            "Iteration: 14500. Loss: 0.3493296205997467. Accuracy: 86.67\n",
            "Iteration: 14600. Loss: 0.16662566363811493. Accuracy: 87.02\n",
            "Iteration: 14700. Loss: 0.2634551227092743. Accuracy: 86.66\n",
            "Iteration: 14800. Loss: 0.35996508598327637. Accuracy: 87.07\n",
            "Iteration: 14900. Loss: 0.41152241826057434. Accuracy: 86.42\n",
            "Epoch 9\n",
            "-------------------------------\n",
            "Iteration: 15000. Loss: 0.3913112282752991. Accuracy: 86.78\n",
            "Iteration: 15100. Loss: 0.2175157070159912. Accuracy: 86.49\n",
            "Iteration: 15200. Loss: 0.36101940274238586. Accuracy: 85.25\n",
            "Iteration: 15300. Loss: 0.3794631361961365. Accuracy: 86.35\n",
            "Iteration: 15400. Loss: 0.27157339453697205. Accuracy: 86.82\n",
            "Iteration: 15500. Loss: 0.29452502727508545. Accuracy: 86.32\n",
            "Iteration: 15600. Loss: 0.16036656498908997. Accuracy: 86.93\n",
            "Iteration: 15700. Loss: 0.5327640771865845. Accuracy: 87.09\n",
            "Iteration: 15800. Loss: 0.35602861642837524. Accuracy: 86.35\n",
            "Iteration: 15900. Loss: 0.3872319459915161. Accuracy: 86.22\n",
            "Iteration: 16000. Loss: 0.35059118270874023. Accuracy: 86.86\n",
            "Iteration: 16100. Loss: 0.4481754004955292. Accuracy: 86.21\n",
            "Iteration: 16200. Loss: 0.2124212384223938. Accuracy: 87.06\n",
            "Iteration: 16300. Loss: 0.2120969444513321. Accuracy: 87.26\n",
            "Iteration: 16400. Loss: 0.26414355635643005. Accuracy: 86.79\n",
            "Iteration: 16500. Loss: 0.55374675989151. Accuracy: 86.68\n",
            "Iteration: 16600. Loss: 0.5200989842414856. Accuracy: 87.04\n",
            "Iteration: 16700. Loss: 0.2378731667995453. Accuracy: 87.02\n",
            "Iteration: 16800. Loss: 0.5113312005996704. Accuracy: 87.11\n",
            "Epoch 10\n",
            "-------------------------------\n",
            "Iteration: 16900. Loss: 0.259004682302475. Accuracy: 86.61\n",
            "Iteration: 17000. Loss: 0.4053855240345001. Accuracy: 87.09\n",
            "Iteration: 17100. Loss: 0.3451521098613739. Accuracy: 87.37\n",
            "Iteration: 17200. Loss: 0.191346675157547. Accuracy: 87.19\n",
            "Iteration: 17300. Loss: 0.286917507648468. Accuracy: 86.89\n",
            "Iteration: 17400. Loss: 0.6282029151916504. Accuracy: 87.2\n",
            "Iteration: 17500. Loss: 0.16586507856845856. Accuracy: 87.53\n",
            "Iteration: 17600. Loss: 0.5719802975654602. Accuracy: 86.13\n",
            "Iteration: 17700. Loss: 0.5585976243019104. Accuracy: 87.3\n",
            "Iteration: 17800. Loss: 0.36154705286026. Accuracy: 87.01\n",
            "Iteration: 17900. Loss: 0.29485636949539185. Accuracy: 86.64\n",
            "Iteration: 18000. Loss: 0.5251391530036926. Accuracy: 87.27\n",
            "Iteration: 18100. Loss: 0.29637205600738525. Accuracy: 87.52\n",
            "Iteration: 18200. Loss: 0.39808300137519836. Accuracy: 87.33\n",
            "Iteration: 18300. Loss: 0.5523092746734619. Accuracy: 87.17\n",
            "Iteration: 18400. Loss: 0.3324977457523346. Accuracy: 86.82\n",
            "Iteration: 18500. Loss: 0.2256467640399933. Accuracy: 86.96\n",
            "Iteration: 18600. Loss: 0.28197601437568665. Accuracy: 87.31\n",
            "Iteration: 18700. Loss: 0.36127573251724243. Accuracy: 87.1\n",
            "Epoch 11\n",
            "-------------------------------\n",
            "Iteration: 18800. Loss: 0.3829786479473114. Accuracy: 87.3\n",
            "Iteration: 18900. Loss: 0.14305266737937927. Accuracy: 86.99\n",
            "Iteration: 19000. Loss: 0.19297799468040466. Accuracy: 87.25\n",
            "Iteration: 19100. Loss: 0.42972710728645325. Accuracy: 87.45\n",
            "Iteration: 19200. Loss: 0.21786364912986755. Accuracy: 87.28\n",
            "Iteration: 19300. Loss: 0.2868248522281647. Accuracy: 86.76\n",
            "Iteration: 19400. Loss: 0.5630866289138794. Accuracy: 87.3\n",
            "Iteration: 19500. Loss: 0.527594804763794. Accuracy: 87.31\n",
            "Iteration: 19600. Loss: 0.47923803329467773. Accuracy: 86.71\n",
            "Iteration: 19700. Loss: 0.1991807520389557. Accuracy: 87.21\n",
            "Iteration: 19800. Loss: 0.2481442540884018. Accuracy: 87.24\n",
            "Iteration: 19900. Loss: 0.112466000020504. Accuracy: 87.51\n",
            "Iteration: 20000. Loss: 0.4426374137401581. Accuracy: 86.81\n",
            "Iteration: 20100. Loss: 0.1731589138507843. Accuracy: 86.44\n",
            "Iteration: 20200. Loss: 0.24340829253196716. Accuracy: 85.82\n",
            "Iteration: 20300. Loss: 0.33050963282585144. Accuracy: 86.72\n",
            "Iteration: 20400. Loss: 0.2048109620809555. Accuracy: 87.26\n",
            "Iteration: 20500. Loss: 0.28838393092155457. Accuracy: 86.36\n",
            "Iteration: 20600. Loss: 0.3519250154495239. Accuracy: 87.02\n",
            "Epoch 12\n",
            "-------------------------------\n",
            "Iteration: 20700. Loss: 0.2955440580844879. Accuracy: 87.64\n",
            "Iteration: 20800. Loss: 0.1724448949098587. Accuracy: 87.43\n",
            "Iteration: 20900. Loss: 0.2386760413646698. Accuracy: 87.43\n",
            "Iteration: 21000. Loss: 0.3402225375175476. Accuracy: 87.22\n",
            "Iteration: 21100. Loss: 0.3416682481765747. Accuracy: 86.95\n",
            "Iteration: 21200. Loss: 0.3233773112297058. Accuracy: 86.97\n",
            "Iteration: 21300. Loss: 0.20179572701454163. Accuracy: 86.89\n",
            "Iteration: 21400. Loss: 0.5128583312034607. Accuracy: 85.78\n",
            "Iteration: 21500. Loss: 0.27908405661582947. Accuracy: 87.32\n",
            "Iteration: 21600. Loss: 0.4066164195537567. Accuracy: 85.61\n",
            "Iteration: 21700. Loss: 0.5785328149795532. Accuracy: 87.4\n",
            "Iteration: 21800. Loss: 0.28381335735321045. Accuracy: 87.39\n",
            "Iteration: 21900. Loss: 0.26323121786117554. Accuracy: 87.19\n",
            "Iteration: 22000. Loss: 0.21127867698669434. Accuracy: 87.57\n",
            "Iteration: 22100. Loss: 0.38401368260383606. Accuracy: 87.42\n",
            "Iteration: 22200. Loss: 0.5565760135650635. Accuracy: 87.03\n",
            "Iteration: 22300. Loss: 0.3953024446964264. Accuracy: 87.01\n",
            "Iteration: 22400. Loss: 0.28487280011177063. Accuracy: 86.62\n",
            "Epoch 13\n",
            "-------------------------------\n",
            "Iteration: 22500. Loss: 0.653702437877655. Accuracy: 87.3\n",
            "Iteration: 22600. Loss: 0.4030195474624634. Accuracy: 87.68\n",
            "Iteration: 22700. Loss: 0.15285854041576385. Accuracy: 87.72\n",
            "Iteration: 22800. Loss: 0.2864903509616852. Accuracy: 87.56\n",
            "Iteration: 22900. Loss: 0.10315638035535812. Accuracy: 87.7\n",
            "Iteration: 23000. Loss: 0.34323081374168396. Accuracy: 87.77\n",
            "Iteration: 23100. Loss: 0.5730040073394775. Accuracy: 87.85\n",
            "Iteration: 23200. Loss: 0.3608599305152893. Accuracy: 87.63\n",
            "Iteration: 23300. Loss: 0.12823960185050964. Accuracy: 87.67\n",
            "Iteration: 23400. Loss: 0.4387860894203186. Accuracy: 87.66\n",
            "Iteration: 23500. Loss: 0.2237062156200409. Accuracy: 87.49\n",
            "Iteration: 23600. Loss: 0.3050044775009155. Accuracy: 87.69\n",
            "Iteration: 23700. Loss: 0.43321356177330017. Accuracy: 87.31\n",
            "Iteration: 23800. Loss: 0.36535561084747314. Accuracy: 87.73\n",
            "Iteration: 23900. Loss: 0.19536744058132172. Accuracy: 87.54\n",
            "Iteration: 24000. Loss: 0.318024218082428. Accuracy: 87.25\n",
            "Iteration: 24100. Loss: 0.29023516178131104. Accuracy: 87.02\n",
            "Iteration: 24200. Loss: 0.387551873922348. Accuracy: 87.45\n",
            "Iteration: 24300. Loss: 0.2405950129032135. Accuracy: 86.69\n",
            "Epoch 14\n",
            "-------------------------------\n",
            "Iteration: 24400. Loss: 0.2624920904636383. Accuracy: 87.36\n",
            "Iteration: 24500. Loss: 0.28138267993927. Accuracy: 87.48\n",
            "Iteration: 24600. Loss: 0.428726464509964. Accuracy: 87.33\n",
            "Iteration: 24700. Loss: 0.2510625123977661. Accuracy: 86.21\n",
            "Iteration: 24800. Loss: 0.11474437266588211. Accuracy: 87.82\n",
            "Iteration: 24900. Loss: 0.4834941625595093. Accuracy: 87.39\n",
            "Iteration: 25000. Loss: 0.3447971045970917. Accuracy: 87.79\n",
            "Iteration: 25100. Loss: 0.231853187084198. Accuracy: 87.66\n",
            "Iteration: 25200. Loss: 0.28134486079216003. Accuracy: 86.97\n",
            "Iteration: 25300. Loss: 0.40846967697143555. Accuracy: 88.16\n",
            "Iteration: 25400. Loss: 0.3851957321166992. Accuracy: 87.91\n",
            "Iteration: 25500. Loss: 0.2879769504070282. Accuracy: 87.57\n",
            "Iteration: 25600. Loss: 0.5759039521217346. Accuracy: 87.86\n",
            "Iteration: 25700. Loss: 0.33210939168930054. Accuracy: 87.37\n",
            "Iteration: 25800. Loss: 0.11261887103319168. Accuracy: 87.96\n",
            "Iteration: 25900. Loss: 0.8739397525787354. Accuracy: 88.02\n",
            "Iteration: 26000. Loss: 0.6311840415000916. Accuracy: 87.23\n",
            "Iteration: 26100. Loss: 0.13886922597885132. Accuracy: 88.17\n",
            "Iteration: 26200. Loss: 0.14559298753738403. Accuracy: 87.37\n",
            "Epoch 15\n",
            "-------------------------------\n",
            "Iteration: 26300. Loss: 0.4292711615562439. Accuracy: 87.96\n",
            "Iteration: 26400. Loss: 0.2671535909175873. Accuracy: 87.72\n",
            "Iteration: 26500. Loss: 0.1617206335067749. Accuracy: 87.94\n",
            "Iteration: 26600. Loss: 0.18560852110385895. Accuracy: 87.81\n",
            "Iteration: 26700. Loss: 0.3387748897075653. Accuracy: 87.4\n",
            "Iteration: 26800. Loss: 0.4260544180870056. Accuracy: 87.63\n",
            "Iteration: 26900. Loss: 0.23579367995262146. Accuracy: 87.35\n",
            "Iteration: 27000. Loss: 0.193690225481987. Accuracy: 87.88\n",
            "Iteration: 27100. Loss: 0.33321413397789. Accuracy: 88.34\n",
            "Iteration: 27200. Loss: 0.321328341960907. Accuracy: 87.4\n",
            "Iteration: 27300. Loss: 0.3784969449043274. Accuracy: 87.67\n",
            "Iteration: 27400. Loss: 0.1178593710064888. Accuracy: 87.88\n",
            "Iteration: 27500. Loss: 0.4131764769554138. Accuracy: 87.52\n",
            "Iteration: 27600. Loss: 0.37384527921676636. Accuracy: 87.82\n",
            "Iteration: 27700. Loss: 0.4181457757949829. Accuracy: 87.66\n",
            "Iteration: 27800. Loss: 0.17402106523513794. Accuracy: 87.37\n",
            "Iteration: 27900. Loss: 0.31864428520202637. Accuracy: 87.51\n",
            "Iteration: 28000. Loss: 0.3895314931869507. Accuracy: 86.82\n",
            "Iteration: 28100. Loss: 0.132253959774971. Accuracy: 86.71\n",
            "Epoch 16\n",
            "-------------------------------\n",
            "Iteration: 28200. Loss: 0.37837138772010803. Accuracy: 87.52\n",
            "Iteration: 28300. Loss: 0.23467043042182922. Accuracy: 88.08\n",
            "Iteration: 28400. Loss: 0.3550035059452057. Accuracy: 87.57\n",
            "Iteration: 28500. Loss: 0.3732098639011383. Accuracy: 87.24\n",
            "Iteration: 28600. Loss: 0.4474731683731079. Accuracy: 87.4\n",
            "Iteration: 28700. Loss: 0.18916688859462738. Accuracy: 87.68\n",
            "Iteration: 28800. Loss: 0.2760380506515503. Accuracy: 87.68\n",
            "Iteration: 28900. Loss: 0.1574806272983551. Accuracy: 87.83\n",
            "Iteration: 29000. Loss: 0.22904936969280243. Accuracy: 87.79\n",
            "Iteration: 29100. Loss: 0.07295046746730804. Accuracy: 88.08\n",
            "Iteration: 29200. Loss: 0.41935640573501587. Accuracy: 87.87\n",
            "Iteration: 29300. Loss: 0.05873287096619606. Accuracy: 87.93\n",
            "Iteration: 29400. Loss: 0.22588035464286804. Accuracy: 87.65\n",
            "Iteration: 29500. Loss: 0.7542303204536438. Accuracy: 88.16\n",
            "Iteration: 29600. Loss: 0.27757081389427185. Accuracy: 87.88\n",
            "Iteration: 29700. Loss: 0.1295294463634491. Accuracy: 87.88\n",
            "Iteration: 29800. Loss: 0.30603018403053284. Accuracy: 87.69\n",
            "Iteration: 29900. Loss: 0.3369333744049072. Accuracy: 87.56\n",
            "Epoch 17\n",
            "-------------------------------\n",
            "Iteration: 30000. Loss: 0.36340340971946716. Accuracy: 88.06\n",
            "Iteration: 30100. Loss: 0.35812312364578247. Accuracy: 88.18\n",
            "Iteration: 30200. Loss: 0.2935731112957001. Accuracy: 87.72\n",
            "Iteration: 30300. Loss: 0.13675187528133392. Accuracy: 88.1\n",
            "Iteration: 30400. Loss: 0.2842462658882141. Accuracy: 87.67\n",
            "Iteration: 30500. Loss: 0.31108978390693665. Accuracy: 88.24\n",
            "Iteration: 30600. Loss: 0.2640472650527954. Accuracy: 87.6\n",
            "Iteration: 30700. Loss: 0.12285088002681732. Accuracy: 87.86\n",
            "Iteration: 30800. Loss: 0.3910917043685913. Accuracy: 87.87\n",
            "Iteration: 30900. Loss: 0.2544839680194855. Accuracy: 87.56\n",
            "Iteration: 31000. Loss: 0.19210302829742432. Accuracy: 87.37\n",
            "Iteration: 31100. Loss: 0.15628410875797272. Accuracy: 87.89\n",
            "Iteration: 31200. Loss: 0.17138256132602692. Accuracy: 86.96\n",
            "Iteration: 31300. Loss: 0.26649346947669983. Accuracy: 88.09\n",
            "Iteration: 31400. Loss: 0.29154905676841736. Accuracy: 88.29\n",
            "Iteration: 31500. Loss: 0.11415152251720428. Accuracy: 87.55\n",
            "Iteration: 31600. Loss: 0.27806469798088074. Accuracy: 87.53\n",
            "Iteration: 31700. Loss: 0.3083544969558716. Accuracy: 87.8\n",
            "Iteration: 31800. Loss: 0.18594148755073547. Accuracy: 87.84\n",
            "Epoch 18\n",
            "-------------------------------\n",
            "Iteration: 31900. Loss: 0.12754963338375092. Accuracy: 88.14\n",
            "Iteration: 32000. Loss: 0.3881855309009552. Accuracy: 88.2\n",
            "Iteration: 32100. Loss: 0.4185976982116699. Accuracy: 88.29\n",
            "Iteration: 32200. Loss: 0.3421443700790405. Accuracy: 87.78\n",
            "Iteration: 32300. Loss: 0.3505377769470215. Accuracy: 87.73\n",
            "Iteration: 32400. Loss: 0.17870411276817322. Accuracy: 87.85\n",
            "Iteration: 32500. Loss: 0.20518805086612701. Accuracy: 88.07\n",
            "Iteration: 32600. Loss: 0.2635093927383423. Accuracy: 87.77\n",
            "Iteration: 32700. Loss: 0.14550940692424774. Accuracy: 87.23\n",
            "Iteration: 32800. Loss: 0.22158002853393555. Accuracy: 88.05\n",
            "Iteration: 32900. Loss: 0.34620827436447144. Accuracy: 87.9\n",
            "Iteration: 33000. Loss: 0.28886479139328003. Accuracy: 88.18\n",
            "Iteration: 33100. Loss: 0.1884070336818695. Accuracy: 87.85\n",
            "Iteration: 33200. Loss: 0.3459378182888031. Accuracy: 87.93\n",
            "Iteration: 33300. Loss: 0.4354647397994995. Accuracy: 87.96\n",
            "Iteration: 33400. Loss: 0.4435667097568512. Accuracy: 87.94\n",
            "Iteration: 33500. Loss: 0.16321608424186707. Accuracy: 88.51\n",
            "Iteration: 33600. Loss: 0.4480802118778229. Accuracy: 88.74\n",
            "Iteration: 33700. Loss: 0.13976353406906128. Accuracy: 87.7\n",
            "Epoch 19\n",
            "-------------------------------\n",
            "Iteration: 33800. Loss: 0.23987586796283722. Accuracy: 87.77\n",
            "Iteration: 33900. Loss: 0.29394811391830444. Accuracy: 88.19\n",
            "Iteration: 34000. Loss: 0.4927160143852234. Accuracy: 88.06\n",
            "Iteration: 34100. Loss: 0.5115591287612915. Accuracy: 87.88\n",
            "Iteration: 34200. Loss: 0.29764989018440247. Accuracy: 88.3\n",
            "Iteration: 34300. Loss: 0.18032243847846985. Accuracy: 88.03\n",
            "Iteration: 34400. Loss: 0.2914186418056488. Accuracy: 88.35\n",
            "Iteration: 34500. Loss: 0.36587026715278625. Accuracy: 88.21\n",
            "Iteration: 34600. Loss: 0.31546398997306824. Accuracy: 87.63\n",
            "Iteration: 34700. Loss: 0.5434849858283997. Accuracy: 87.74\n",
            "Iteration: 34800. Loss: 0.2509192228317261. Accuracy: 88.13\n",
            "Iteration: 34900. Loss: 0.16003353893756866. Accuracy: 88.17\n",
            "Iteration: 35000. Loss: 0.2655506730079651. Accuracy: 88.13\n",
            "Iteration: 35100. Loss: 0.38424891233444214. Accuracy: 87.92\n",
            "Iteration: 35200. Loss: 0.23688697814941406. Accuracy: 87.39\n",
            "Iteration: 35300. Loss: 0.11874494701623917. Accuracy: 88.01\n",
            "Iteration: 35400. Loss: 0.08819908648729324. Accuracy: 88.15\n",
            "Iteration: 35500. Loss: 0.09990691393613815. Accuracy: 88.11\n",
            "Iteration: 35600. Loss: 0.29882460832595825. Accuracy: 88.26\n",
            "Epoch 20\n",
            "-------------------------------\n",
            "Iteration: 35700. Loss: 0.16745556890964508. Accuracy: 88.26\n",
            "Iteration: 35800. Loss: 0.1491744965314865. Accuracy: 88.35\n",
            "Iteration: 35900. Loss: 0.37462207674980164. Accuracy: 87.89\n",
            "Iteration: 36000. Loss: 0.3059287965297699. Accuracy: 88.61\n",
            "Iteration: 36100. Loss: 0.3886215388774872. Accuracy: 88.01\n",
            "Iteration: 36200. Loss: 0.2736753523349762. Accuracy: 88.3\n",
            "Iteration: 36300. Loss: 0.3555043041706085. Accuracy: 87.93\n",
            "Iteration: 36400. Loss: 0.3861822783946991. Accuracy: 88.43\n",
            "Iteration: 36500. Loss: 0.21327507495880127. Accuracy: 87.94\n",
            "Iteration: 36600. Loss: 0.15582555532455444. Accuracy: 87.59\n",
            "Iteration: 36700. Loss: 0.17181046307086945. Accuracy: 88.39\n",
            "Iteration: 36800. Loss: 0.20420433580875397. Accuracy: 88.27\n",
            "Iteration: 36900. Loss: 0.26032665371894836. Accuracy: 88.61\n",
            "Iteration: 37000. Loss: 0.3899073898792267. Accuracy: 87.82\n",
            "Iteration: 37100. Loss: 0.28132364153862. Accuracy: 88.13\n",
            "Iteration: 37200. Loss: 0.2609410881996155. Accuracy: 87.97\n",
            "Iteration: 37300. Loss: 0.3253867030143738. Accuracy: 88.54\n",
            "Iteration: 37400. Loss: 0.29111248254776. Accuracy: 87.96\n",
            "Epoch 21\n",
            "-------------------------------\n",
            "Iteration: 37500. Loss: 0.368336021900177. Accuracy: 87.95\n",
            "Iteration: 37600. Loss: 0.15645869076251984. Accuracy: 88.04\n",
            "Iteration: 37700. Loss: 0.2369522601366043. Accuracy: 87.55\n",
            "Iteration: 37800. Loss: 0.13558581471443176. Accuracy: 88.29\n",
            "Iteration: 37900. Loss: 0.25585076212882996. Accuracy: 88.4\n",
            "Iteration: 38000. Loss: 0.25745320320129395. Accuracy: 88.25\n",
            "Iteration: 38100. Loss: 0.3255804777145386. Accuracy: 87.37\n",
            "Iteration: 38200. Loss: 0.43032872676849365. Accuracy: 88.18\n",
            "Iteration: 38300. Loss: 0.3401428163051605. Accuracy: 88.38\n",
            "Iteration: 38400. Loss: 0.1462983936071396. Accuracy: 88.28\n",
            "Iteration: 38500. Loss: 0.2755500078201294. Accuracy: 88.48\n",
            "Iteration: 38600. Loss: 0.08262526243925095. Accuracy: 87.85\n",
            "Iteration: 38700. Loss: 0.26408979296684265. Accuracy: 87.44\n",
            "Iteration: 38800. Loss: 0.44768252968788147. Accuracy: 87.95\n",
            "Iteration: 38900. Loss: 0.19008813798427582. Accuracy: 88.19\n",
            "Iteration: 39000. Loss: 0.2026830017566681. Accuracy: 88.13\n",
            "Iteration: 39100. Loss: 0.155705064535141. Accuracy: 88.06\n",
            "Iteration: 39200. Loss: 0.4050857126712799. Accuracy: 87.59\n",
            "Iteration: 39300. Loss: 0.25362521409988403. Accuracy: 88.21\n",
            "Epoch 22\n",
            "-------------------------------\n",
            "Iteration: 39400. Loss: 0.3243792951107025. Accuracy: 88.49\n",
            "Iteration: 39500. Loss: 0.13874198496341705. Accuracy: 88.51\n",
            "Iteration: 39600. Loss: 0.48813340067863464. Accuracy: 88.26\n",
            "Iteration: 39700. Loss: 0.2901514768600464. Accuracy: 87.97\n",
            "Iteration: 39800. Loss: 0.3145279288291931. Accuracy: 88.18\n",
            "Iteration: 39900. Loss: 0.23943489789962769. Accuracy: 87.98\n",
            "Iteration: 40000. Loss: 0.288059800863266. Accuracy: 88.21\n",
            "Iteration: 40100. Loss: 0.34497129917144775. Accuracy: 88.23\n",
            "Iteration: 40200. Loss: 0.247292622923851. Accuracy: 88.09\n",
            "Iteration: 40300. Loss: 0.2617565989494324. Accuracy: 88.15\n",
            "Iteration: 40400. Loss: 0.3452337980270386. Accuracy: 88.52\n",
            "Iteration: 40500. Loss: 0.248627707362175. Accuracy: 88.3\n",
            "Iteration: 40600. Loss: 0.48195573687553406. Accuracy: 88.32\n",
            "Iteration: 40700. Loss: 0.190000981092453. Accuracy: 88.68\n",
            "Iteration: 40800. Loss: 0.2017110288143158. Accuracy: 87.6\n",
            "Iteration: 40900. Loss: 0.24593093991279602. Accuracy: 88.54\n",
            "Iteration: 41000. Loss: 0.24834026396274567. Accuracy: 88.17\n",
            "Iteration: 41100. Loss: 0.17709606885910034. Accuracy: 88.54\n",
            "Iteration: 41200. Loss: 0.2067524492740631. Accuracy: 88.41\n",
            "Epoch 23\n",
            "-------------------------------\n",
            "Iteration: 41300. Loss: 0.390206515789032. Accuracy: 87.92\n",
            "Iteration: 41400. Loss: 0.04251628741621971. Accuracy: 88.71\n",
            "Iteration: 41500. Loss: 0.7086867690086365. Accuracy: 88.59\n",
            "Iteration: 41600. Loss: 0.27492186427116394. Accuracy: 88.39\n",
            "Iteration: 41700. Loss: 0.25504401326179504. Accuracy: 88.47\n",
            "Iteration: 41800. Loss: 0.2139083445072174. Accuracy: 88.46\n",
            "Iteration: 41900. Loss: 0.18342499434947968. Accuracy: 88.11\n",
            "Iteration: 42000. Loss: 0.17035765945911407. Accuracy: 88.62\n",
            "Iteration: 42100. Loss: 0.3534611463546753. Accuracy: 88.43\n",
            "Iteration: 42200. Loss: 0.07510734349489212. Accuracy: 87.99\n",
            "Iteration: 42300. Loss: 0.08983665704727173. Accuracy: 88.48\n",
            "Iteration: 42400. Loss: 0.13652727007865906. Accuracy: 88.35\n",
            "Iteration: 42500. Loss: 0.21610046923160553. Accuracy: 88.45\n",
            "Iteration: 42600. Loss: 0.08933752030134201. Accuracy: 88.21\n",
            "Iteration: 42700. Loss: 0.3581022620201111. Accuracy: 88.66\n",
            "Iteration: 42800. Loss: 0.06595772504806519. Accuracy: 88.52\n",
            "Iteration: 42900. Loss: 0.3630047142505646. Accuracy: 87.73\n",
            "Iteration: 43000. Loss: 0.18351200222969055. Accuracy: 88.61\n",
            "Iteration: 43100. Loss: 0.07495236396789551. Accuracy: 88.54\n",
            "Epoch 24\n",
            "-------------------------------\n",
            "Iteration: 43200. Loss: 0.1153375431895256. Accuracy: 88.36\n",
            "Iteration: 43300. Loss: 0.43935370445251465. Accuracy: 87.77\n",
            "Iteration: 43400. Loss: 0.21965940296649933. Accuracy: 88.55\n",
            "Iteration: 43500. Loss: 0.27099835872650146. Accuracy: 88.44\n",
            "Iteration: 43600. Loss: 0.20335234701633453. Accuracy: 88.42\n",
            "Iteration: 43700. Loss: 0.39629560708999634. Accuracy: 88.51\n",
            "Iteration: 43800. Loss: 0.3814639747142792. Accuracy: 88.08\n",
            "Iteration: 43900. Loss: 0.17668801546096802. Accuracy: 87.58\n",
            "Iteration: 44000. Loss: 0.3272937536239624. Accuracy: 88.13\n",
            "Iteration: 44100. Loss: 0.10112465918064117. Accuracy: 87.82\n",
            "Iteration: 44200. Loss: 0.3402842581272125. Accuracy: 88.75\n",
            "Iteration: 44300. Loss: 0.358921080827713. Accuracy: 88.39\n",
            "Iteration: 44400. Loss: 0.2619084119796753. Accuracy: 88.44\n",
            "Iteration: 44500. Loss: 0.1002911701798439. Accuracy: 88.5\n",
            "Iteration: 44600. Loss: 0.34157487750053406. Accuracy: 88.23\n",
            "Iteration: 44700. Loss: 0.18183888494968414. Accuracy: 88.56\n",
            "Iteration: 44800. Loss: 0.21908026933670044. Accuracy: 88.66\n",
            "Iteration: 44900. Loss: 0.2676655650138855. Accuracy: 88.34\n",
            "Epoch 25\n",
            "-------------------------------\n",
            "Iteration: 45000. Loss: 0.21610943973064423. Accuracy: 88.0\n",
            "Iteration: 45100. Loss: 0.25853922963142395. Accuracy: 88.59\n",
            "Iteration: 45200. Loss: 0.154465451836586. Accuracy: 88.5\n",
            "Iteration: 45300. Loss: 0.286178857088089. Accuracy: 88.54\n",
            "Iteration: 45400. Loss: 0.2654160261154175. Accuracy: 88.59\n",
            "Iteration: 45500. Loss: 0.1272716373205185. Accuracy: 88.61\n",
            "Iteration: 45600. Loss: 0.21504628658294678. Accuracy: 88.26\n",
            "Iteration: 45700. Loss: 0.2819325923919678. Accuracy: 88.85\n",
            "Iteration: 45800. Loss: 0.19749903678894043. Accuracy: 88.57\n",
            "Iteration: 45900. Loss: 0.2698460519313812. Accuracy: 88.56\n",
            "Iteration: 46000. Loss: 0.09443635493516922. Accuracy: 88.5\n",
            "Iteration: 46100. Loss: 0.3273734450340271. Accuracy: 88.02\n",
            "Iteration: 46200. Loss: 0.5789346098899841. Accuracy: 88.27\n",
            "Iteration: 46300. Loss: 0.24847006797790527. Accuracy: 88.54\n",
            "Iteration: 46400. Loss: 0.35743430256843567. Accuracy: 88.26\n",
            "Iteration: 46500. Loss: 0.2524881660938263. Accuracy: 88.71\n",
            "Iteration: 46600. Loss: 0.13313427567481995. Accuracy: 88.53\n",
            "Iteration: 46700. Loss: 0.23890328407287598. Accuracy: 88.13\n",
            "Iteration: 46800. Loss: 0.2511197328567505. Accuracy: 88.09\n",
            "Epoch 26\n",
            "-------------------------------\n",
            "Iteration: 46900. Loss: 0.17932836711406708. Accuracy: 88.64\n",
            "Iteration: 47000. Loss: 0.2682063579559326. Accuracy: 88.61\n",
            "Iteration: 47100. Loss: 0.27753257751464844. Accuracy: 88.05\n",
            "Iteration: 47200. Loss: 0.4046693444252014. Accuracy: 87.9\n",
            "Iteration: 47300. Loss: 0.13123741745948792. Accuracy: 88.05\n",
            "Iteration: 47400. Loss: 0.2309838831424713. Accuracy: 88.58\n",
            "Iteration: 47500. Loss: 0.2611714005470276. Accuracy: 87.3\n",
            "Iteration: 47600. Loss: 0.4115302860736847. Accuracy: 88.85\n",
            "Iteration: 47700. Loss: 0.4419194757938385. Accuracy: 88.62\n",
            "Iteration: 47800. Loss: 0.2290075272321701. Accuracy: 88.44\n",
            "Iteration: 47900. Loss: 0.13037650287151337. Accuracy: 88.14\n",
            "Iteration: 48000. Loss: 0.33392030000686646. Accuracy: 88.63\n",
            "Iteration: 48100. Loss: 0.3153679668903351. Accuracy: 87.67\n",
            "Iteration: 48200. Loss: 0.3346593677997589. Accuracy: 88.53\n",
            "Iteration: 48300. Loss: 0.1756301373243332. Accuracy: 88.52\n",
            "Iteration: 48400. Loss: 0.14386054873466492. Accuracy: 88.41\n",
            "Iteration: 48500. Loss: 0.21053358912467957. Accuracy: 88.41\n",
            "Iteration: 48600. Loss: 0.08846675604581833. Accuracy: 88.68\n",
            "Iteration: 48700. Loss: 0.46279630064964294. Accuracy: 88.84\n",
            "Epoch 27\n",
            "-------------------------------\n",
            "Iteration: 48800. Loss: 0.17908011376857758. Accuracy: 88.64\n",
            "Iteration: 48900. Loss: 0.5030801892280579. Accuracy: 88.95\n",
            "Iteration: 49000. Loss: 0.3370557725429535. Accuracy: 87.86\n",
            "Iteration: 49100. Loss: 0.2569974362850189. Accuracy: 87.58\n",
            "Iteration: 49200. Loss: 0.0872679352760315. Accuracy: 88.73\n",
            "Iteration: 49300. Loss: 0.320102334022522. Accuracy: 88.92\n",
            "Iteration: 49400. Loss: 0.2521381080150604. Accuracy: 88.65\n",
            "Iteration: 49500. Loss: 0.20068861544132233. Accuracy: 88.65\n",
            "Iteration: 49600. Loss: 0.2548384368419647. Accuracy: 88.84\n",
            "Iteration: 49700. Loss: 0.15426725149154663. Accuracy: 88.98\n",
            "Iteration: 49800. Loss: 0.39615464210510254. Accuracy: 88.88\n",
            "Iteration: 49900. Loss: 0.3021097779273987. Accuracy: 88.55\n",
            "Iteration: 50000. Loss: 0.10927767306566238. Accuracy: 88.54\n",
            "Iteration: 50100. Loss: 0.12091278284788132. Accuracy: 88.69\n",
            "Iteration: 50200. Loss: 0.13906393945217133. Accuracy: 88.87\n",
            "Iteration: 50300. Loss: 0.4799506366252899. Accuracy: 88.67\n",
            "Iteration: 50400. Loss: 0.2789812386035919. Accuracy: 88.66\n",
            "Iteration: 50500. Loss: 0.4236632287502289. Accuracy: 88.03\n",
            "Iteration: 50600. Loss: 0.30801859498023987. Accuracy: 88.82\n",
            "Epoch 28\n",
            "-------------------------------\n",
            "Iteration: 50700. Loss: 0.17591555416584015. Accuracy: 88.31\n",
            "Iteration: 50800. Loss: 0.28398609161376953. Accuracy: 89.01\n",
            "Iteration: 50900. Loss: 0.15658073127269745. Accuracy: 87.85\n",
            "Iteration: 51000. Loss: 0.2035842388868332. Accuracy: 88.47\n",
            "Iteration: 51100. Loss: 0.1217416450381279. Accuracy: 88.58\n",
            "Iteration: 51200. Loss: 0.1785660684108734. Accuracy: 88.63\n",
            "Iteration: 51300. Loss: 0.15376582741737366. Accuracy: 89.09\n",
            "Iteration: 51400. Loss: 0.23129485547542572. Accuracy: 88.5\n",
            "Iteration: 51500. Loss: 0.1997860074043274. Accuracy: 88.79\n",
            "Iteration: 51600. Loss: 0.39311039447784424. Accuracy: 88.88\n",
            "Iteration: 51700. Loss: 0.2454395443201065. Accuracy: 88.29\n",
            "Iteration: 51800. Loss: 0.16898317635059357. Accuracy: 88.76\n",
            "Iteration: 51900. Loss: 0.16922248899936676. Accuracy: 88.83\n",
            "Iteration: 52000. Loss: 0.21970222890377045. Accuracy: 88.63\n",
            "Iteration: 52100. Loss: 0.7924603223800659. Accuracy: 88.71\n",
            "Iteration: 52200. Loss: 0.14724798500537872. Accuracy: 88.5\n",
            "Iteration: 52300. Loss: 0.34766507148742676. Accuracy: 88.99\n",
            "Iteration: 52400. Loss: 0.19234679639339447. Accuracy: 88.67\n",
            "Epoch 29\n",
            "-------------------------------\n",
            "Iteration: 52500. Loss: 0.21005435287952423. Accuracy: 88.54\n",
            "Iteration: 52600. Loss: 0.1341048628091812. Accuracy: 88.71\n",
            "Iteration: 52700. Loss: 0.04961444064974785. Accuracy: 88.64\n",
            "Iteration: 52800. Loss: 0.1622616946697235. Accuracy: 88.98\n",
            "Iteration: 52900. Loss: 0.48026159405708313. Accuracy: 89.03\n",
            "Iteration: 53000. Loss: 0.12904880940914154. Accuracy: 89.02\n",
            "Iteration: 53100. Loss: 0.2489161640405655. Accuracy: 88.24\n",
            "Iteration: 53200. Loss: 0.3208952844142914. Accuracy: 88.63\n",
            "Iteration: 53300. Loss: 0.32094138860702515. Accuracy: 88.98\n",
            "Iteration: 53400. Loss: 0.13597792387008667. Accuracy: 89.04\n",
            "Iteration: 53500. Loss: 0.23121105134487152. Accuracy: 88.58\n",
            "Iteration: 53600. Loss: 0.09110124409198761. Accuracy: 89.13\n",
            "Iteration: 53700. Loss: 0.29235100746154785. Accuracy: 88.49\n",
            "Iteration: 53800. Loss: 0.1987680196762085. Accuracy: 88.52\n",
            "Iteration: 53900. Loss: 0.27360162138938904. Accuracy: 88.3\n",
            "Iteration: 54000. Loss: 0.19977691769599915. Accuracy: 88.85\n",
            "Iteration: 54100. Loss: 0.283334881067276. Accuracy: 87.84\n",
            "Iteration: 54200. Loss: 0.1536327302455902. Accuracy: 88.55\n",
            "Iteration: 54300. Loss: 0.13212144374847412. Accuracy: 88.78\n",
            "Epoch 30\n",
            "-------------------------------\n",
            "Iteration: 54400. Loss: 0.09990105032920837. Accuracy: 88.35\n",
            "Iteration: 54500. Loss: 0.16145066916942596. Accuracy: 88.48\n",
            "Iteration: 54600. Loss: 0.05151880905032158. Accuracy: 88.89\n",
            "Iteration: 54700. Loss: 0.36705896258354187. Accuracy: 88.73\n",
            "Iteration: 54800. Loss: 0.13657449185848236. Accuracy: 88.63\n",
            "Iteration: 54900. Loss: 0.347462922334671. Accuracy: 88.91\n",
            "Iteration: 55000. Loss: 0.2398861199617386. Accuracy: 89.12\n",
            "Iteration: 55100. Loss: 0.08787374943494797. Accuracy: 88.93\n",
            "Iteration: 55200. Loss: 0.20914681255817413. Accuracy: 89.13\n",
            "Iteration: 55300. Loss: 0.20035049319267273. Accuracy: 88.05\n",
            "Iteration: 55400. Loss: 0.13622185587882996. Accuracy: 88.95\n",
            "Iteration: 55500. Loss: 0.15020667016506195. Accuracy: 88.94\n",
            "Iteration: 55600. Loss: 0.17668114602565765. Accuracy: 88.72\n",
            "Iteration: 55700. Loss: 0.2971164286136627. Accuracy: 88.36\n",
            "Iteration: 55800. Loss: 0.21083511412143707. Accuracy: 88.42\n",
            "Iteration: 55900. Loss: 0.08064103871583939. Accuracy: 88.14\n",
            "Iteration: 56000. Loss: 0.3888261616230011. Accuracy: 88.88\n",
            "Iteration: 56100. Loss: 0.1630438268184662. Accuracy: 88.58\n",
            "Iteration: 56200. Loss: 0.24481526017189026. Accuracy: 88.66\n",
            "Epoch 31\n",
            "-------------------------------\n",
            "Iteration: 56300. Loss: 0.5357806086540222. Accuracy: 89.0\n",
            "Iteration: 56400. Loss: 0.1389545202255249. Accuracy: 88.25\n",
            "Iteration: 56500. Loss: 0.2986716032028198. Accuracy: 88.68\n",
            "Iteration: 56600. Loss: 0.3065342605113983. Accuracy: 88.92\n",
            "Iteration: 56700. Loss: 0.2333291620016098. Accuracy: 88.99\n",
            "Iteration: 56800. Loss: 0.09749338030815125. Accuracy: 88.9\n",
            "Iteration: 56900. Loss: 0.36882486939430237. Accuracy: 89.0\n",
            "Iteration: 57000. Loss: 0.22607307136058807. Accuracy: 88.86\n",
            "Iteration: 57100. Loss: 0.21072953939437866. Accuracy: 89.21\n",
            "Iteration: 57200. Loss: 0.262738972902298. Accuracy: 88.84\n",
            "Iteration: 57300. Loss: 0.2785046696662903. Accuracy: 88.96\n",
            "Iteration: 57400. Loss: 0.4830949902534485. Accuracy: 89.19\n",
            "Iteration: 57500. Loss: 0.17332439124584198. Accuracy: 88.75\n",
            "Iteration: 57600. Loss: 0.2692844867706299. Accuracy: 88.96\n",
            "Iteration: 57700. Loss: 0.1441151648759842. Accuracy: 89.15\n",
            "Iteration: 57800. Loss: 0.2940496504306793. Accuracy: 88.49\n",
            "Iteration: 57900. Loss: 0.23710288107395172. Accuracy: 89.03\n",
            "Iteration: 58000. Loss: 0.19726580381393433. Accuracy: 88.64\n",
            "Iteration: 58100. Loss: 0.21915289759635925. Accuracy: 88.7\n",
            "Epoch 32\n",
            "-------------------------------\n",
            "Iteration: 58200. Loss: 0.5140522122383118. Accuracy: 88.95\n",
            "Iteration: 58300. Loss: 0.31629323959350586. Accuracy: 89.13\n",
            "Iteration: 58400. Loss: 0.3262714147567749. Accuracy: 88.65\n",
            "Iteration: 58500. Loss: 0.2850581109523773. Accuracy: 88.86\n",
            "Iteration: 58600. Loss: 0.18239954113960266. Accuracy: 88.94\n",
            "Iteration: 58700. Loss: 0.21805468201637268. Accuracy: 88.7\n",
            "Iteration: 58800. Loss: 0.3004736006259918. Accuracy: 89.04\n",
            "Iteration: 58900. Loss: 0.16009755432605743. Accuracy: 88.98\n",
            "Iteration: 59000. Loss: 0.14794301986694336. Accuracy: 88.75\n",
            "Iteration: 59100. Loss: 0.31080424785614014. Accuracy: 88.88\n",
            "Iteration: 59200. Loss: 0.23745782673358917. Accuracy: 88.68\n",
            "Iteration: 59300. Loss: 0.2544575333595276. Accuracy: 89.19\n",
            "Iteration: 59400. Loss: 0.2425025999546051. Accuracy: 89.17\n",
            "Iteration: 59500. Loss: 0.15710364282131195. Accuracy: 88.47\n",
            "Iteration: 59600. Loss: 0.41968944668769836. Accuracy: 88.86\n",
            "Iteration: 59700. Loss: 0.3548186421394348. Accuracy: 89.06\n",
            "Iteration: 59800. Loss: 0.3366653323173523. Accuracy: 88.75\n",
            "Iteration: 59900. Loss: 0.4168911874294281. Accuracy: 88.89\n",
            "Epoch 33\n",
            "-------------------------------\n",
            "Iteration: 60000. Loss: 0.21213549375534058. Accuracy: 87.5\n",
            "Iteration: 60100. Loss: 0.1402914971113205. Accuracy: 88.8\n",
            "Iteration: 60200. Loss: 0.18241682648658752. Accuracy: 89.2\n",
            "Iteration: 60300. Loss: 0.09737619012594223. Accuracy: 88.46\n",
            "Iteration: 60400. Loss: 0.18283683061599731. Accuracy: 89.22\n",
            "Iteration: 60500. Loss: 0.22975441813468933. Accuracy: 88.91\n",
            "Iteration: 60600. Loss: 0.18701724708080292. Accuracy: 88.43\n",
            "Iteration: 60700. Loss: 0.15321078896522522. Accuracy: 88.75\n",
            "Iteration: 60800. Loss: 0.1453690528869629. Accuracy: 88.7\n",
            "Iteration: 60900. Loss: 0.24731115996837616. Accuracy: 87.98\n",
            "Iteration: 61000. Loss: 0.049548741430044174. Accuracy: 88.77\n",
            "Iteration: 61100. Loss: 0.27358341217041016. Accuracy: 88.86\n",
            "Iteration: 61200. Loss: 0.17863701283931732. Accuracy: 89.36\n",
            "Iteration: 61300. Loss: 0.24087831377983093. Accuracy: 88.82\n",
            "Iteration: 61400. Loss: 0.13845495879650116. Accuracy: 88.6\n",
            "Iteration: 61500. Loss: 0.18923743069171906. Accuracy: 88.47\n",
            "Iteration: 61600. Loss: 0.11560963094234467. Accuracy: 89.39\n",
            "Iteration: 61700. Loss: 0.19271528720855713. Accuracy: 88.12\n",
            "Iteration: 61800. Loss: 0.5458824038505554. Accuracy: 89.04\n",
            "Epoch 34\n",
            "-------------------------------\n",
            "Iteration: 61900. Loss: 0.15346094965934753. Accuracy: 89.12\n",
            "Iteration: 62000. Loss: 0.24925975501537323. Accuracy: 89.29\n",
            "Iteration: 62100. Loss: 0.23453570902347565. Accuracy: 88.7\n",
            "Iteration: 62200. Loss: 0.0413254052400589. Accuracy: 88.95\n",
            "Iteration: 62300. Loss: 0.11291103065013885. Accuracy: 89.11\n",
            "Iteration: 62400. Loss: 0.32488006353378296. Accuracy: 89.04\n",
            "Iteration: 62500. Loss: 0.24465928971767426. Accuracy: 88.87\n",
            "Iteration: 62600. Loss: 0.6174130439758301. Accuracy: 88.97\n",
            "Iteration: 62700. Loss: 0.15953433513641357. Accuracy: 89.15\n",
            "Iteration: 62800. Loss: 0.20292700827121735. Accuracy: 88.63\n",
            "Iteration: 62900. Loss: 0.18327872455120087. Accuracy: 88.72\n",
            "Iteration: 63000. Loss: 0.2861262559890747. Accuracy: 88.47\n",
            "Iteration: 63100. Loss: 0.24336710572242737. Accuracy: 89.07\n",
            "Iteration: 63200. Loss: 0.2958851456642151. Accuracy: 88.81\n",
            "Iteration: 63300. Loss: 0.11739560216665268. Accuracy: 89.1\n",
            "Iteration: 63400. Loss: 0.07339327037334442. Accuracy: 89.15\n",
            "Iteration: 63500. Loss: 0.32635846734046936. Accuracy: 89.36\n",
            "Iteration: 63600. Loss: 0.22287669777870178. Accuracy: 88.66\n",
            "Iteration: 63700. Loss: 0.22365115582942963. Accuracy: 89.18\n",
            "Epoch 35\n",
            "-------------------------------\n",
            "Iteration: 63800. Loss: 0.06439898163080215. Accuracy: 88.89\n",
            "Iteration: 63900. Loss: 0.2315351366996765. Accuracy: 89.38\n",
            "Iteration: 64000. Loss: 0.2307569980621338. Accuracy: 89.09\n",
            "Iteration: 64100. Loss: 0.20568260550498962. Accuracy: 89.26\n",
            "Iteration: 64200. Loss: 0.2363809198141098. Accuracy: 88.97\n",
            "Iteration: 64300. Loss: 0.31273597478866577. Accuracy: 89.27\n",
            "Iteration: 64400. Loss: 0.060374122112989426. Accuracy: 89.0\n",
            "Iteration: 64500. Loss: 0.16836072504520416. Accuracy: 88.8\n",
            "Iteration: 64600. Loss: 0.17115682363510132. Accuracy: 88.71\n",
            "Iteration: 64700. Loss: 0.24973390996456146. Accuracy: 88.78\n",
            "Iteration: 64800. Loss: 0.43331071734428406. Accuracy: 88.86\n",
            "Iteration: 64900. Loss: 0.1692623794078827. Accuracy: 88.91\n",
            "Iteration: 65000. Loss: 0.15969780087471008. Accuracy: 88.9\n",
            "Iteration: 65100. Loss: 0.08719126880168915. Accuracy: 89.16\n",
            "Iteration: 65200. Loss: 0.13404212892055511. Accuracy: 89.17\n",
            "Iteration: 65300. Loss: 0.0961121991276741. Accuracy: 88.87\n",
            "Iteration: 65400. Loss: 0.16228874027729034. Accuracy: 88.76\n",
            "Iteration: 65500. Loss: 0.3255370855331421. Accuracy: 88.73\n",
            "Iteration: 65600. Loss: 0.1402502804994583. Accuracy: 88.96\n",
            "Epoch 36\n",
            "-------------------------------\n",
            "Iteration: 65700. Loss: 0.2880345284938812. Accuracy: 89.41\n",
            "Iteration: 65800. Loss: 0.2153124362230301. Accuracy: 89.08\n",
            "Iteration: 65900. Loss: 0.3368394672870636. Accuracy: 88.9\n",
            "Iteration: 66000. Loss: 0.028772614896297455. Accuracy: 89.31\n",
            "Iteration: 66100. Loss: 0.08041407912969589. Accuracy: 88.89\n",
            "Iteration: 66200. Loss: 0.3230915069580078. Accuracy: 88.55\n",
            "Iteration: 66300. Loss: 0.16956180334091187. Accuracy: 89.17\n",
            "Iteration: 66400. Loss: 0.29762640595436096. Accuracy: 88.76\n",
            "Iteration: 66500. Loss: 0.2931305468082428. Accuracy: 88.85\n",
            "Iteration: 66600. Loss: 0.21979089081287384. Accuracy: 89.34\n",
            "Iteration: 66700. Loss: 0.17208027839660645. Accuracy: 89.03\n",
            "Iteration: 66800. Loss: 0.06703812628984451. Accuracy: 89.01\n",
            "Iteration: 66900. Loss: 0.23235167562961578. Accuracy: 88.83\n",
            "Iteration: 67000. Loss: 0.18252812325954437. Accuracy: 89.02\n",
            "Iteration: 67100. Loss: 0.16855505108833313. Accuracy: 89.23\n",
            "Iteration: 67200. Loss: 0.14236564934253693. Accuracy: 88.65\n",
            "Iteration: 67300. Loss: 0.3064880669116974. Accuracy: 88.85\n",
            "Iteration: 67400. Loss: 0.22200478613376617. Accuracy: 89.28\n",
            "Epoch 37\n",
            "-------------------------------\n",
            "Iteration: 67500. Loss: 0.14051847159862518. Accuracy: 89.0\n",
            "Iteration: 67600. Loss: 0.06868993490934372. Accuracy: 88.47\n",
            "Iteration: 67700. Loss: 0.3191593289375305. Accuracy: 89.01\n",
            "Iteration: 67800. Loss: 0.3372175097465515. Accuracy: 89.07\n",
            "Iteration: 67900. Loss: 0.10701677203178406. Accuracy: 89.12\n",
            "Iteration: 68000. Loss: 0.15121671557426453. Accuracy: 89.01\n",
            "Iteration: 68100. Loss: 0.410473495721817. Accuracy: 89.26\n",
            "Iteration: 68200. Loss: 0.18798720836639404. Accuracy: 89.37\n",
            "Iteration: 68300. Loss: 0.2373000979423523. Accuracy: 89.05\n",
            "Iteration: 68400. Loss: 0.30167216062545776. Accuracy: 88.79\n",
            "Iteration: 68500. Loss: 0.11261627823114395. Accuracy: 88.63\n",
            "Iteration: 68600. Loss: 0.30533257126808167. Accuracy: 88.48\n",
            "Iteration: 68700. Loss: 0.23299634456634521. Accuracy: 89.05\n",
            "Iteration: 68800. Loss: 0.2001487910747528. Accuracy: 88.87\n",
            "Iteration: 68900. Loss: 0.399097740650177. Accuracy: 88.93\n",
            "Iteration: 69000. Loss: 0.11247049272060394. Accuracy: 89.23\n",
            "Iteration: 69100. Loss: 0.04512714222073555. Accuracy: 89.35\n",
            "Iteration: 69200. Loss: 0.18123354017734528. Accuracy: 87.85\n",
            "Iteration: 69300. Loss: 0.40122219920158386. Accuracy: 89.34\n",
            "Epoch 38\n",
            "-------------------------------\n",
            "Iteration: 69400. Loss: 0.19384026527404785. Accuracy: 89.19\n",
            "Iteration: 69500. Loss: 0.30346620082855225. Accuracy: 89.11\n",
            "Iteration: 69600. Loss: 0.2249615639448166. Accuracy: 88.74\n",
            "Iteration: 69700. Loss: 0.2571137547492981. Accuracy: 89.27\n",
            "Iteration: 69800. Loss: 0.18255500495433807. Accuracy: 88.95\n",
            "Iteration: 69900. Loss: 0.20315322279930115. Accuracy: 88.96\n",
            "Iteration: 70000. Loss: 0.11284592747688293. Accuracy: 89.35\n",
            "Iteration: 70100. Loss: 0.3643670082092285. Accuracy: 89.37\n",
            "Iteration: 70200. Loss: 0.1420264095067978. Accuracy: 88.88\n",
            "Iteration: 70300. Loss: 0.30694687366485596. Accuracy: 88.82\n",
            "Iteration: 70400. Loss: 0.3284868597984314. Accuracy: 89.09\n",
            "Iteration: 70500. Loss: 0.18514806032180786. Accuracy: 89.09\n",
            "Iteration: 70600. Loss: 0.09463632106781006. Accuracy: 89.24\n",
            "Iteration: 70700. Loss: 0.08622999489307404. Accuracy: 88.71\n",
            "Iteration: 70800. Loss: 0.07349500060081482. Accuracy: 88.52\n",
            "Iteration: 70900. Loss: 0.30127161741256714. Accuracy: 89.46\n",
            "Iteration: 71000. Loss: 0.15105435252189636. Accuracy: 89.31\n",
            "Iteration: 71100. Loss: 0.3125845193862915. Accuracy: 88.95\n",
            "Iteration: 71200. Loss: 0.1640896052122116. Accuracy: 88.47\n",
            "Epoch 39\n",
            "-------------------------------\n",
            "Iteration: 71300. Loss: 0.061669886112213135. Accuracy: 89.25\n",
            "Iteration: 71400. Loss: 0.19758494198322296. Accuracy: 89.36\n",
            "Iteration: 71500. Loss: 0.2299523800611496. Accuracy: 88.71\n",
            "Iteration: 71600. Loss: 0.21411314606666565. Accuracy: 88.88\n",
            "Iteration: 71700. Loss: 0.17679879069328308. Accuracy: 88.71\n",
            "Iteration: 71800. Loss: 0.4717022180557251. Accuracy: 89.54\n",
            "Iteration: 71900. Loss: 0.038866523653268814. Accuracy: 89.21\n",
            "Iteration: 72000. Loss: 0.14092816412448883. Accuracy: 88.69\n",
            "Iteration: 72100. Loss: 0.06209887936711311. Accuracy: 89.27\n",
            "Iteration: 72200. Loss: 0.3316645622253418. Accuracy: 88.47\n",
            "Iteration: 72300. Loss: 0.17399606108665466. Accuracy: 89.14\n",
            "Iteration: 72400. Loss: 0.25167521834373474. Accuracy: 89.46\n",
            "Iteration: 72500. Loss: 0.21432523429393768. Accuracy: 88.72\n",
            "Iteration: 72600. Loss: 0.18289613723754883. Accuracy: 89.35\n",
            "Iteration: 72700. Loss: 0.16104114055633545. Accuracy: 88.57\n",
            "Iteration: 72800. Loss: 0.17874613404273987. Accuracy: 89.36\n",
            "Iteration: 72900. Loss: 0.16860239207744598. Accuracy: 89.19\n",
            "Iteration: 73000. Loss: 0.13581092655658722. Accuracy: 89.29\n",
            "Iteration: 73100. Loss: 0.04707692563533783. Accuracy: 89.18\n",
            "Epoch 40\n",
            "-------------------------------\n",
            "Iteration: 73200. Loss: 0.16119657456874847. Accuracy: 89.18\n",
            "Iteration: 73300. Loss: 0.26330697536468506. Accuracy: 88.84\n",
            "Iteration: 73400. Loss: 0.17243655025959015. Accuracy: 89.41\n",
            "Iteration: 73500. Loss: 0.2287558764219284. Accuracy: 89.56\n",
            "Iteration: 73600. Loss: 0.07287781685590744. Accuracy: 89.22\n",
            "Iteration: 73700. Loss: 0.24133481085300446. Accuracy: 89.22\n",
            "Iteration: 73800. Loss: 0.1272653043270111. Accuracy: 89.24\n",
            "Iteration: 73900. Loss: 0.2086155265569687. Accuracy: 88.76\n",
            "Iteration: 74000. Loss: 0.1905583292245865. Accuracy: 89.25\n",
            "Iteration: 74100. Loss: 0.2331538051366806. Accuracy: 89.31\n",
            "Iteration: 74200. Loss: 0.27314504981040955. Accuracy: 89.05\n",
            "Iteration: 74300. Loss: 0.17884039878845215. Accuracy: 89.19\n",
            "Iteration: 74400. Loss: 0.19906236231327057. Accuracy: 89.36\n",
            "Iteration: 74500. Loss: 0.2780594825744629. Accuracy: 89.38\n",
            "Iteration: 74600. Loss: 0.22216886281967163. Accuracy: 89.12\n",
            "Iteration: 74700. Loss: 0.04478876292705536. Accuracy: 89.3\n",
            "Iteration: 74800. Loss: 0.09366067498922348. Accuracy: 89.21\n",
            "Iteration: 74900. Loss: 0.10338306427001953. Accuracy: 89.45\n",
            "Epoch 41\n",
            "-------------------------------\n",
            "Iteration: 75000. Loss: 0.21401089429855347. Accuracy: 89.06\n",
            "Iteration: 75100. Loss: 0.10688459128141403. Accuracy: 88.97\n",
            "Iteration: 75200. Loss: 0.12702281773090363. Accuracy: 88.47\n",
            "Iteration: 75300. Loss: 0.09382367879152298. Accuracy: 89.26\n",
            "Iteration: 75400. Loss: 0.1150500699877739. Accuracy: 88.48\n",
            "Iteration: 75500. Loss: 0.06368032097816467. Accuracy: 89.1\n",
            "Iteration: 75600. Loss: 0.13686159253120422. Accuracy: 89.48\n",
            "Iteration: 75700. Loss: 0.1398240625858307. Accuracy: 89.56\n",
            "Iteration: 75800. Loss: 0.22249667346477509. Accuracy: 89.48\n",
            "Iteration: 75900. Loss: 0.13116498291492462. Accuracy: 88.76\n",
            "Iteration: 76000. Loss: 0.10029572248458862. Accuracy: 89.53\n",
            "Iteration: 76100. Loss: 0.3870134949684143. Accuracy: 89.53\n",
            "Iteration: 76200. Loss: 0.08242948353290558. Accuracy: 89.63\n",
            "Iteration: 76300. Loss: 0.061083585023880005. Accuracy: 89.05\n",
            "Iteration: 76400. Loss: 0.13657119870185852. Accuracy: 89.08\n",
            "Iteration: 76500. Loss: 0.18139930069446564. Accuracy: 89.11\n",
            "Iteration: 76600. Loss: 0.18538761138916016. Accuracy: 89.12\n",
            "Iteration: 76700. Loss: 0.1320614218711853. Accuracy: 89.61\n",
            "Iteration: 76800. Loss: 0.2754538655281067. Accuracy: 89.12\n",
            "Epoch 42\n",
            "-------------------------------\n",
            "Iteration: 76900. Loss: 0.07539685070514679. Accuracy: 88.34\n",
            "Iteration: 77000. Loss: 0.3058966398239136. Accuracy: 89.46\n",
            "Iteration: 77100. Loss: 0.1269320249557495. Accuracy: 89.53\n",
            "Iteration: 77200. Loss: 0.09030327945947647. Accuracy: 89.5\n",
            "Iteration: 77300. Loss: 0.3699999749660492. Accuracy: 89.06\n",
            "Iteration: 77400. Loss: 0.23546864092350006. Accuracy: 89.06\n",
            "Iteration: 77500. Loss: 0.26768872141838074. Accuracy: 88.6\n",
            "Iteration: 77600. Loss: 0.34966716170310974. Accuracy: 88.84\n",
            "Iteration: 77700. Loss: 0.21882326900959015. Accuracy: 89.27\n",
            "Iteration: 77800. Loss: 0.2384607344865799. Accuracy: 89.31\n",
            "Iteration: 77900. Loss: 0.07966474443674088. Accuracy: 89.26\n",
            "Iteration: 78000. Loss: 0.26174870133399963. Accuracy: 89.31\n",
            "Iteration: 78100. Loss: 0.28577369451522827. Accuracy: 88.41\n",
            "Iteration: 78200. Loss: 0.037482716143131256. Accuracy: 89.1\n",
            "Iteration: 78300. Loss: 0.16429519653320312. Accuracy: 89.44\n",
            "Iteration: 78400. Loss: 0.06900482624769211. Accuracy: 89.55\n",
            "Iteration: 78500. Loss: 0.29797419905662537. Accuracy: 88.88\n",
            "Iteration: 78600. Loss: 0.35564419627189636. Accuracy: 89.07\n",
            "Iteration: 78700. Loss: 0.057345371693372726. Accuracy: 88.57\n",
            "Epoch 43\n",
            "-------------------------------\n",
            "Iteration: 78800. Loss: 0.43112048506736755. Accuracy: 89.25\n",
            "Iteration: 78900. Loss: 0.049771372228860855. Accuracy: 89.16\n",
            "Iteration: 79000. Loss: 0.23271138966083527. Accuracy: 89.08\n",
            "Iteration: 79100. Loss: 0.2099033147096634. Accuracy: 89.41\n",
            "Iteration: 79200. Loss: 0.1887567639350891. Accuracy: 89.1\n",
            "Iteration: 79300. Loss: 0.09708422422409058. Accuracy: 89.18\n",
            "Iteration: 79400. Loss: 0.21043311059474945. Accuracy: 88.99\n",
            "Iteration: 79500. Loss: 0.20221194624900818. Accuracy: 89.36\n",
            "Iteration: 79600. Loss: 0.1612314134836197. Accuracy: 89.53\n",
            "Iteration: 79700. Loss: 0.22348690032958984. Accuracy: 89.4\n",
            "Iteration: 79800. Loss: 0.16959623992443085. Accuracy: 89.38\n",
            "Iteration: 79900. Loss: 0.13401558995246887. Accuracy: 88.66\n",
            "Iteration: 80000. Loss: 0.16331064701080322. Accuracy: 89.34\n",
            "Iteration: 80100. Loss: 0.07534243166446686. Accuracy: 89.27\n",
            "Iteration: 80200. Loss: 0.2998947501182556. Accuracy: 89.69\n",
            "Iteration: 80300. Loss: 0.1849173903465271. Accuracy: 89.05\n",
            "Iteration: 80400. Loss: 0.43268346786499023. Accuracy: 89.42\n",
            "Iteration: 80500. Loss: 0.1066204085946083. Accuracy: 89.38\n",
            "Iteration: 80600. Loss: 0.10225020349025726. Accuracy: 89.18\n",
            "Epoch 44\n",
            "-------------------------------\n",
            "Iteration: 80700. Loss: 0.16883395612239838. Accuracy: 88.99\n",
            "Iteration: 80800. Loss: 0.17357012629508972. Accuracy: 89.3\n",
            "Iteration: 80900. Loss: 0.17120572924613953. Accuracy: 89.15\n",
            "Iteration: 81000. Loss: 0.11771737784147263. Accuracy: 89.48\n",
            "Iteration: 81100. Loss: 0.14268839359283447. Accuracy: 89.5\n",
            "Iteration: 81200. Loss: 0.2994688153266907. Accuracy: 88.9\n",
            "Iteration: 81300. Loss: 0.4836287498474121. Accuracy: 88.67\n",
            "Iteration: 81400. Loss: 0.07262149453163147. Accuracy: 89.44\n",
            "Iteration: 81500. Loss: 0.23900677263736725. Accuracy: 89.1\n",
            "Iteration: 81600. Loss: 0.17459917068481445. Accuracy: 89.22\n",
            "Iteration: 81700. Loss: 0.1180807575583458. Accuracy: 88.94\n",
            "Iteration: 81800. Loss: 0.17312395572662354. Accuracy: 88.75\n",
            "Iteration: 81900. Loss: 0.2330387681722641. Accuracy: 88.64\n",
            "Iteration: 82000. Loss: 0.19830304384231567. Accuracy: 89.29\n",
            "Iteration: 82100. Loss: 0.07830484956502914. Accuracy: 89.45\n",
            "Iteration: 82200. Loss: 0.11249512434005737. Accuracy: 89.43\n",
            "Iteration: 82300. Loss: 0.15341748297214508. Accuracy: 88.93\n",
            "Iteration: 82400. Loss: 0.11301127076148987. Accuracy: 89.16\n",
            "Epoch 45\n",
            "-------------------------------\n",
            "Iteration: 82500. Loss: 0.06775232404470444. Accuracy: 89.4\n",
            "Iteration: 82600. Loss: 0.08299566060304642. Accuracy: 89.21\n",
            "Iteration: 82700. Loss: 0.13429850339889526. Accuracy: 89.53\n",
            "Iteration: 82800. Loss: 0.16375426948070526. Accuracy: 89.09\n",
            "Iteration: 82900. Loss: 0.25763699412345886. Accuracy: 89.42\n",
            "Iteration: 83000. Loss: 0.16263681650161743. Accuracy: 89.61\n",
            "Iteration: 83100. Loss: 0.44396987557411194. Accuracy: 89.95\n",
            "Iteration: 83200. Loss: 0.15446628630161285. Accuracy: 89.4\n",
            "Iteration: 83300. Loss: 0.14173641800880432. Accuracy: 89.65\n",
            "Iteration: 83400. Loss: 0.17117458581924438. Accuracy: 89.66\n",
            "Iteration: 83500. Loss: 0.12927699089050293. Accuracy: 89.38\n",
            "Iteration: 83600. Loss: 0.165708988904953. Accuracy: 89.58\n",
            "Iteration: 83700. Loss: 0.2436067909002304. Accuracy: 88.99\n",
            "Iteration: 83800. Loss: 0.26571550965309143. Accuracy: 88.42\n",
            "Iteration: 83900. Loss: 0.23127280175685883. Accuracy: 89.3\n",
            "Iteration: 84000. Loss: 0.20969432592391968. Accuracy: 88.42\n",
            "Iteration: 84100. Loss: 0.11175710707902908. Accuracy: 88.66\n",
            "Iteration: 84200. Loss: 0.1714905947446823. Accuracy: 89.54\n",
            "Iteration: 84300. Loss: 0.1157662644982338. Accuracy: 88.88\n",
            "Epoch 46\n",
            "-------------------------------\n",
            "Iteration: 84400. Loss: 0.43077805638313293. Accuracy: 89.27\n",
            "Iteration: 84500. Loss: 0.11023594439029694. Accuracy: 89.31\n",
            "Iteration: 84600. Loss: 0.17541508376598358. Accuracy: 88.92\n",
            "Iteration: 84700. Loss: 0.0713789165019989. Accuracy: 89.52\n",
            "Iteration: 84800. Loss: 0.08471913635730743. Accuracy: 89.14\n",
            "Iteration: 84900. Loss: 0.15642781555652618. Accuracy: 89.37\n",
            "Iteration: 85000. Loss: 0.0833563581109047. Accuracy: 89.16\n",
            "Iteration: 85100. Loss: 0.08946991711854935. Accuracy: 89.72\n",
            "Iteration: 85200. Loss: 0.2521847188472748. Accuracy: 89.12\n",
            "Iteration: 85300. Loss: 0.3584103584289551. Accuracy: 89.23\n",
            "Iteration: 85400. Loss: 0.21590501070022583. Accuracy: 88.94\n",
            "Iteration: 85500. Loss: 0.22959963977336884. Accuracy: 89.26\n",
            "Iteration: 85600. Loss: 0.19973360002040863. Accuracy: 88.86\n",
            "Iteration: 85700. Loss: 0.06825117021799088. Accuracy: 89.38\n",
            "Iteration: 85800. Loss: 0.14221228659152985. Accuracy: 89.28\n",
            "Iteration: 85900. Loss: 0.09220080077648163. Accuracy: 88.9\n",
            "Iteration: 86000. Loss: 0.27300727367401123. Accuracy: 89.51\n",
            "Iteration: 86100. Loss: 0.07885583490133286. Accuracy: 89.71\n",
            "Iteration: 86200. Loss: 0.14495079219341278. Accuracy: 89.19\n",
            "Epoch 47\n",
            "-------------------------------\n",
            "Iteration: 86300. Loss: 0.22334040701389313. Accuracy: 89.17\n",
            "Iteration: 86400. Loss: 0.10028256475925446. Accuracy: 89.29\n",
            "Iteration: 86500. Loss: 0.06593136489391327. Accuracy: 89.73\n",
            "Iteration: 86600. Loss: 0.1749764084815979. Accuracy: 89.8\n",
            "Iteration: 86700. Loss: 0.0824190229177475. Accuracy: 89.33\n",
            "Iteration: 86800. Loss: 0.09117227792739868. Accuracy: 89.01\n",
            "Iteration: 86900. Loss: 0.019907210022211075. Accuracy: 89.15\n",
            "Iteration: 87000. Loss: 0.11065059155225754. Accuracy: 89.44\n",
            "Iteration: 87100. Loss: 0.2216702252626419. Accuracy: 89.43\n",
            "Iteration: 87200. Loss: 0.15823933482170105. Accuracy: 89.05\n",
            "Iteration: 87300. Loss: 0.1617576777935028. Accuracy: 89.44\n",
            "Iteration: 87400. Loss: 0.5263640880584717. Accuracy: 89.47\n",
            "Iteration: 87500. Loss: 0.149697408080101. Accuracy: 89.13\n",
            "Iteration: 87600. Loss: 0.1998310536146164. Accuracy: 89.16\n",
            "Iteration: 87700. Loss: 0.10358598083257675. Accuracy: 89.63\n",
            "Iteration: 87800. Loss: 0.09510741382837296. Accuracy: 89.23\n",
            "Iteration: 87900. Loss: 0.09773562848567963. Accuracy: 89.32\n",
            "Iteration: 88000. Loss: 0.07595362514257431. Accuracy: 89.35\n",
            "Iteration: 88100. Loss: 0.12028222531080246. Accuracy: 89.18\n",
            "Epoch 48\n",
            "-------------------------------\n",
            "Iteration: 88200. Loss: 0.08078940212726593. Accuracy: 88.61\n",
            "Iteration: 88300. Loss: 0.0752219408750534. Accuracy: 89.33\n",
            "Iteration: 88400. Loss: 0.174277201294899. Accuracy: 89.37\n",
            "Iteration: 88500. Loss: 0.18952225148677826. Accuracy: 89.58\n",
            "Iteration: 88600. Loss: 0.12678025662899017. Accuracy: 89.68\n",
            "Iteration: 88700. Loss: 0.03228830173611641. Accuracy: 89.04\n",
            "Iteration: 88800. Loss: 0.26677000522613525. Accuracy: 89.24\n",
            "Iteration: 88900. Loss: 0.0708116739988327. Accuracy: 89.68\n",
            "Iteration: 89000. Loss: 0.1459297239780426. Accuracy: 88.95\n",
            "Iteration: 89100. Loss: 0.14194250106811523. Accuracy: 89.37\n",
            "Iteration: 89200. Loss: 0.09708504378795624. Accuracy: 89.15\n",
            "Iteration: 89300. Loss: 0.20979568362236023. Accuracy: 89.7\n",
            "Iteration: 89400. Loss: 0.16526558995246887. Accuracy: 89.56\n",
            "Iteration: 89500. Loss: 0.15266312658786774. Accuracy: 89.18\n",
            "Iteration: 89600. Loss: 0.17354853451251984. Accuracy: 89.6\n",
            "Iteration: 89700. Loss: 0.11792300641536713. Accuracy: 89.7\n",
            "Iteration: 89800. Loss: 0.20830512046813965. Accuracy: 88.88\n",
            "Iteration: 89900. Loss: 0.1512434035539627. Accuracy: 89.55\n",
            "Epoch 49\n",
            "-------------------------------\n",
            "Iteration: 90000. Loss: 0.03790231794118881. Accuracy: 89.17\n",
            "Iteration: 90100. Loss: 0.12448570877313614. Accuracy: 89.36\n",
            "Iteration: 90200. Loss: 0.1285010725259781. Accuracy: 89.66\n",
            "Iteration: 90300. Loss: 0.1419626623392105. Accuracy: 89.4\n",
            "Iteration: 90400. Loss: 0.22146357595920563. Accuracy: 89.06\n",
            "Iteration: 90500. Loss: 0.10733920335769653. Accuracy: 89.19\n",
            "Iteration: 90600. Loss: 0.21545013785362244. Accuracy: 89.43\n",
            "Iteration: 90700. Loss: 0.10906663537025452. Accuracy: 88.79\n",
            "Iteration: 90800. Loss: 0.34094464778900146. Accuracy: 89.36\n",
            "Iteration: 90900. Loss: 0.15040279924869537. Accuracy: 89.0\n",
            "Iteration: 91000. Loss: 0.04660554975271225. Accuracy: 89.42\n",
            "Iteration: 91100. Loss: 0.20176565647125244. Accuracy: 89.19\n",
            "Iteration: 91200. Loss: 0.24078154563903809. Accuracy: 89.22\n",
            "Iteration: 91300. Loss: 0.3343735635280609. Accuracy: 89.67\n",
            "Iteration: 91400. Loss: 0.2017090916633606. Accuracy: 89.42\n",
            "Iteration: 91500. Loss: 0.17374572157859802. Accuracy: 89.69\n",
            "Iteration: 91600. Loss: 0.0806615799665451. Accuracy: 89.25\n",
            "Iteration: 91700. Loss: 0.040710050612688065. Accuracy: 89.65\n",
            "Iteration: 91800. Loss: 0.1874367594718933. Accuracy: 89.57\n",
            "Epoch 50\n",
            "-------------------------------\n",
            "Iteration: 91900. Loss: 0.09376394748687744. Accuracy: 89.07\n",
            "Iteration: 92000. Loss: 0.1859016865491867. Accuracy: 88.83\n",
            "Iteration: 92100. Loss: 0.1454809308052063. Accuracy: 89.49\n",
            "Iteration: 92200. Loss: 0.20810067653656006. Accuracy: 89.26\n",
            "Iteration: 92300. Loss: 0.14893370866775513. Accuracy: 89.48\n",
            "Iteration: 92400. Loss: 0.20940202474594116. Accuracy: 89.63\n",
            "Iteration: 92500. Loss: 0.3524544835090637. Accuracy: 89.19\n",
            "Iteration: 92600. Loss: 0.15768468379974365. Accuracy: 89.27\n",
            "Iteration: 92700. Loss: 0.14125533401966095. Accuracy: 89.54\n",
            "Iteration: 92800. Loss: 0.061198290437459946. Accuracy: 89.43\n",
            "Iteration: 92900. Loss: 0.09695999324321747. Accuracy: 89.51\n",
            "Iteration: 93000. Loss: 0.10089201480150223. Accuracy: 89.3\n",
            "Iteration: 93100. Loss: 0.30600669980049133. Accuracy: 89.32\n",
            "Iteration: 93200. Loss: 0.21300964057445526. Accuracy: 89.7\n",
            "Iteration: 93300. Loss: 0.08239670097827911. Accuracy: 89.32\n",
            "Iteration: 93400. Loss: 0.1516219973564148. Accuracy: 89.64\n",
            "Iteration: 93500. Loss: 0.19412574172019958. Accuracy: 89.02\n",
            "Iteration: 93600. Loss: 0.20435896515846252. Accuracy: 89.5\n",
            "Iteration: 93700. Loss: 0.2846931219100952. Accuracy: 89.46\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nw4E18dFtzhR"
      },
      "source": [
        "### Plot Loss vs Iteration graph for `Dataset-2`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "ys5OKKwwRe6I",
        "outputId": "e269cfa4-9538-4119-ae20-1ca80be769dc"
      },
      "source": [
        "iter_range=np.arange(0,93800,100)\n",
        "plt.xlabel('Iteration')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Iteration vs Loss graph for dataset-2')\n",
        "plt.plot(iter_range,iter_loss_ds2);"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RWog-iagRtDj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d35352d-f166-480d-8937-2ca217966224"
      },
      "source": [
        "print(model_ds2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DeepNeuralNetworkModel(\n",
            "  (linear_1): Linear(in_features=784, out_features=200, bias=True)\n",
            "  (act_1): Tanh()\n",
            "  (linear_2): Linear(in_features=200, out_features=200, bias=True)\n",
            "  (act_2): Tanh()\n",
            "  (linear_3): Linear(in_features=200, out_features=200, bias=True)\n",
            "  (act_3): Tanh()\n",
            "  (linear_4): Linear(in_features=200, out_features=200, bias=True)\n",
            "  (act_4): Tanh()\n",
            "  (linear_5): Linear(in_features=200, out_features=200, bias=True)\n",
            "  (act_5): Tanh()\n",
            "  (linear_6): Linear(in_features=200, out_features=200, bias=True)\n",
            "  (act_6): Tanh()\n",
            "  (linear_out): Linear(in_features=200, out_features=10, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T7hBDDsdvOyH"
      },
      "source": [
        "torch.save(model_ds2.state_dict(), '/content/drive/MyDrive/Soft Computing Lab/model_exp2_ds_2.pt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BETPtqXTMYch"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}